{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kitchen training - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T12:06:23.577425Z",
     "start_time": "2019-11-07T12:06:23.573439Z"
    }
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "OD_PATH = '/models/research/object_detection/'\n",
    "MAIN_PATH = '/happy-walrus/models/version_3/'\n",
    "IMG_PATH = MAIN_PATH + 'images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "- [Tensorflow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)\n",
    "- [Tensorflow Object Detection API tutorial](https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store all images and annotations in a single folder, zip the folder and store it in Google Drive under `safety/data/images/version_X` (replace the `X`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv {MAIN_PATH}images/version_3/* {MAIN_PATH}images\n",
    "!rm -fr {MAIN_PATH}images/version_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T12:06:30.407521Z",
     "start_time": "2019-11-07T12:06:29.516282Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1DUnO83WnDmxlgJ073X7uEAvBWWNaohc7\n",
      "To: /happy-walrus/models/version_3/version_3.zip\n",
      "580MB [00:05, 109MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files unzipped: 5771\n",
      "XML files: 2891\n",
      "JPG files: 2876\n"
     ]
    }
   ],
   "source": [
    "# Download images\n",
    "file_id = \"1DUnO83WnDmxlgJ073X7uEAvBWWNaohc7\"\n",
    "file_name = \"version_3.zip\"\n",
    "gdown.download(url=\"https://drive.google.com/uc?id=\" + file_id,\n",
    "               output=MAIN_PATH + file_name,\n",
    "               quiet=False)\n",
    "\n",
    "# Unzip images\n",
    "os.mkdir(IMG_PATH)\n",
    "!unzip -q {MAIN_PATH}{file_name} -d {IMG_PATH}\n",
    "!mv {IMG_PATH}version_3/* {IMG_PATH}\n",
    "!rmdir {IMG_PATH}version_3\n",
    "!rm version_3.zip\n",
    "files_unzipped = os.listdir(MAIN_PATH + 'images/')\n",
    "\n",
    "# Print results\n",
    "print('Files unzipped:', len(files_unzipped))\n",
    "print('XML files:', len([file for file in files_unzipped if re.match('.*\\.xml', file)]))\n",
    "print('JPG files:', len([file for file in files_unzipped if re.match('.*\\.jpg', file)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly split data into train and test:\n",
    "```\n",
    "|-images\n",
    "    |- train\n",
    "    |- test\n",
    "```\n",
    "where the last level folders will contain both the images and annotations (.xml) files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed files: 79\n",
      "Number of errors: 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Create train and test folders in images/\n",
    "os.mkdir(IMG_PATH + 'train')\n",
    "os.mkdir(IMG_PATH + 'test')\n",
    "\n",
    "# Get list of all files that have annotations and split into train and test\n",
    "jpg_files = [file[:-4] for file in os.listdir(IMG_PATH) if re.search('.*\\.jpg$', file)]\n",
    "files = [file[:-4] for file in os.listdir(IMG_PATH) if re.search('.*\\.xml$', file) and file[:-4] in jpg_files]\n",
    "files = [file for file in files if not re.search('open_oven', file)]\n",
    "files_train, files_test = train_test_split(files, train_size=0.9, test_size=0.1, random_state=2014)\n",
    "\n",
    "# Move images to train or test folders\n",
    "errors = []\n",
    "for file in files_train:\n",
    "    try:\n",
    "        shutil.move(IMG_PATH + file + '.xml', IMG_PATH + 'train/' + file + '.xml')\n",
    "        shutil.move(IMG_PATH + file + '.jpg', IMG_PATH + 'train/' + file + '.jpg')\n",
    "    except Exception as err:\n",
    "        errors.append([file, err])\n",
    "\n",
    "for file in files_test:\n",
    "    try:\n",
    "        shutil.move(IMG_PATH + file + '.xml', IMG_PATH + 'test/' + file + '.xml')\n",
    "        shutil.move(IMG_PATH + file + '.jpg', IMG_PATH + 'test/' + file + '.jpg')\n",
    "    except Exception as err:\n",
    "        errors.append([file, err])\n",
    "\n",
    "# Remove remaining images\n",
    "files_rm = [file for file in os.listdir(IMG_PATH) if re.search('.*\\.jpg|.*\\.xml', file)]\n",
    "for file in files_rm:\n",
    "    os.remove(IMG_PATH + file)\n",
    "        \n",
    "# Print errors\n",
    "print(\"Removed files:\", len(files_rm))\n",
    "print(\"Number of errors:\", len(errors))\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate training and test data to `./images/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted xml to csv.\n",
      "Successfully converted xml to csv.\n",
      "\n",
      "filename,width,height,class,xmin,ymin,xmax,ymax\n",
      "orange_kitchen.EH.033.jpg,1000,1000,stove,676,452,874,660\n",
      "orange_kitchen.EH.033.jpg,1000,1000,chair,538,604,800,981\n",
      "orange_kitchen.EH.033.jpg,1000,1000,chair,255,533,482,882\n",
      "orange_kitchen.EH.033.jpg,1000,1000,chair,385,504,555,772\n",
      "\n",
      "Unique classes: ['cabinet', 'chair', 'countertop', 'dishwasher', 'outlet', 'oven', 'sofa', 'stool', 'stove', 'utensil']\n",
      "\n",
      "Train images: 2540\n",
      "Train annotations: 18,935\n",
      "Annotations per class (training):\n",
      "countertop    4627\n",
      "cabinet       3496\n",
      "chair         2682\n",
      "outlet        2322\n",
      "stove         1994\n",
      "utensil       1455\n",
      "oven           958\n",
      "stool          702\n",
      "dishwasher     595\n",
      "sofa           104\n",
      "Name: class, dtype: int64\n",
      "\n",
      "Test images: 283\n",
      "Test annotations: 2,072\n",
      "\n",
      "Label id mapping:\n",
      "item{\n",
      "\tid: 1\n",
      "\tname: 'cabinet'\n",
      "}\n",
      "item{\n",
      "\tid: 2\n",
      "\tname: 'chair'\n",
      "}\n",
      "item{\n",
      "\tid: 3\n",
      "\tname: 'countertop'\n",
      "}\n",
      "item{\n",
      "\tid: 4\n",
      "\tname: 'dishwasher'\n",
      "}\n",
      "item{\n",
      "\tid: 5\n",
      "\tname: 'outlet'\n",
      "}\n",
      "item{\n",
      "\tid: 6\n",
      "\tname: 'oven'\n",
      "}\n",
      "item{\n",
      "\tid: 7\n",
      "\tname: 'sofa'\n",
      "}\n",
      "item{\n",
      "\tid: 8\n",
      "\tname: 'stool'\n",
      "}\n",
      "item{\n",
      "\tid: 9\n",
      "\tname: 'stove'\n",
      "}\n",
      "item{\n",
      "\tid: 10\n",
      "\tname: 'utensil'\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate training and test data\n",
    "!python {OD_PATH}xml_to_csv.py\n",
    "print(\"\")\n",
    "!head {IMG_PATH}/train_labels.csv -n 5\n",
    "\n",
    "# Filter ladders out, fix utensil(s)\n",
    "print(\"\")\n",
    "train_csv = pd.read_csv(IMG_PATH + 'train_labels.csv')\n",
    "train_csv = train_csv[train_csv['class'] != 'ladder']\n",
    "train_csv['class'] = train_csv['class'].map(lambda x: 'utensil' if x == 'utensils' else x)\n",
    "train_csv.to_csv(IMG_PATH + 'train_labels.csv')\n",
    "\n",
    "test_csv = pd.read_csv(IMG_PATH + 'test_labels.csv')\n",
    "test_csv = test_csv[test_csv['class'] != 'ladder']\n",
    "test_csv['class'] = test_csv['class'].map(lambda x: 'utensil' if x == 'utensils' else x)\n",
    "test_csv.to_csv(IMG_PATH + 'test_labels.csv')\n",
    "unique_classes = sorted(train_csv['class'].unique())\n",
    "\n",
    "# Print results\n",
    "print(\"Unique classes:\", unique_classes)\n",
    "print(\"\")\n",
    "print(\"Train images:\", train_csv['filename'].unique().shape[0])\n",
    "print(f\"Train annotations: {train_csv.shape[0]:,}\")\n",
    "print(\"Annotations per class (training):\")\n",
    "print(train_csv['class'].value_counts())\n",
    "print(\"\")\n",
    "print(\"Test images:\", test_csv['filename'].unique().shape[0])\n",
    "print(f\"Test annotations: {test_csv.shape[0]:,}\")\n",
    "print(\"\")\n",
    "\n",
    "# Generate label-id mapping\n",
    "class_mapping = []\n",
    "for count, item in enumerate(unique_classes):\n",
    "    class_mapping.append('item{')\n",
    "    class_mapping.append('\\tid: ' + str(count + 1))\n",
    "    class_mapping.append('\\tname: \\'' + item + '\\'')\n",
    "    class_mapping.append('}')\n",
    "with open(MAIN_PATH + 'training/labelmap.pbtxt', 'w') as f:\n",
    "    f.write('\\n'.join(class_mapping))\n",
    "print(\"Label id mapping:\")\n",
    "print('\\n'.join(class_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def class_text_to_int(row_label):\r\n",
      "    if row_label == 'cabinet':\r\n",
      "        return 1\r\n",
      "    elif row_label == 'chair':\r\n",
      "        return 2\r\n",
      "    elif row_label == 'countertop':\r\n",
      "        return 3\r\n",
      "    elif row_label == 'dishwasher':\r\n",
      "        return 4\r\n",
      "    elif row_label == 'outlet':\r\n",
      "        return 5\r\n",
      "    elif row_label == 'oven':\r\n",
      "        return 6\r\n",
      "    elif row_label == 'sofa':\r\n",
      "        return 7\r\n",
      "    elif row_label == 'stool':\r\n",
      "        return 8\r\n",
      "    elif row_label == 'stove':\r\n",
      "        return 9\r\n",
      "    elif row_label == 'utensil':\r\n",
      "        return 10 \r\n",
      "    else:\r\n",
      "        None\r\n"
     ]
    }
   ],
   "source": [
    "!head generate_tfrecord.py -n 53 | tail -n 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy `generate_tfrecord.py` to main folder and:\n",
    "1. replace `import tensorflow` with `import tensorflow.compat.v1`.\n",
    "2. Modify `class_test_to_int()` function with label-id mapping.\n",
    "3. Line 91: add `'image/object/difficult': dataset_util.int64_list_feature([0]*len(xmins)),`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecords: /happy-walrus/models/version_3/train.record\n",
      "/root/.local/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:802: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
      "  warnings.warn(str(msg))\n",
      "Successfully created the TFRecords: /happy-walrus/models/version_3/test.record\n",
      "\n",
      "-rw-r--r-- 1 root root  66M Nov 25 19:27 test.record\n",
      "-rw-r--r-- 1 root root 484M Nov 25 19:27 train.record\n"
     ]
    }
   ],
   "source": [
    "# Generate TF formatted data\n",
    "!python generate_tfrecord.py --csv_input={IMG_PATH}train_labels.csv --image_dir={IMG_PATH}train --output_path=train.record\n",
    "!python generate_tfrecord.py --csv_input={IMG_PATH}test_labels.csv --image_dir={IMG_PATH}test --output_path=test.record\n",
    "print(\"\")\n",
    "!ls -lh | grep .*\\.record$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model checkpoint (other models in Tensorflow object detection's [Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)). Models:\n",
    "- [faster rcnn inception v2 coco](http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz)\n",
    "    - Speed: 58\n",
    "    - mAP: 28\n",
    "- [faster rcnn resnet50 coco](http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz)\n",
    "    - Speed: 89\n",
    "    - mAP: 30\n",
    "- [faster rcnn resnet101 atrous coco](http://download.tensorflow.org/models/object_detection/mask_rcnn_resnet101_atrous_coco_2018_01_28.tar.gz)\n",
    "    - Speed: 470\n",
    "    - mAP: 33\n",
    "- [faster rcnn nas coco](http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_coco_2018_01_28.tar.gz)\n",
    "    - Speed: 1833\n",
    "    - mAP: 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-25 19:40:22--  http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.14.176, 2607:f8b0:4000:816::2010\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.14.176|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 149119618 (142M) [application/x-tar]\n",
      "Saving to: ‘faster_rcnn_inception_v2_coco_2018_01_28.tar.gz’\n",
      "\n",
      "faster_rcnn_incepti 100%[===================>] 142.21M  95.3MB/s    in 1.5s    \n",
      "\n",
      "2019-11-25 19:40:24 (95.3 MB/s) - ‘faster_rcnn_inception_v2_coco_2018_01_28.tar.gz’ saved [149119618/149119618]\n",
      "\n",
      "faster_rcnn_inception_v2_coco_2018_01_28/\n",
      "faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt.index\n",
      "faster_rcnn_inception_v2_coco_2018_01_28/checkpoint\n",
      "faster_rcnn_inception_v2_coco_2018_01_28/pipeline.config\n",
      "faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt.data-00000-of-00001\n",
      "faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt.meta\n",
      "faster_rcnn_inception_v2_coco_2018_01_28/saved_model/\n",
      "faster_rcnn_inception_v2_coco_2018_01_28/saved_model/saved_model.pb\n",
      "faster_rcnn_inception_v2_coco_2018_01_28/saved_model/variables/\n",
      "faster_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb\n"
     ]
    }
   ],
   "source": [
    "!wget \"http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\"\n",
    "!tar xvzf faster_rcnn_inception_v2_coco_2018_01_28.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Copy config file from `./samples/configs/` to `./training/`\n",
    "2. Adapt parameters in config file:\n",
    "    - `num_classes`\n",
    "    - model `type`\n",
    "    - `fine_tune_checkpoint`\n",
    "    - train_input_reader: `input_path`, `label_map_path`\n",
    "    - `num_examples`: images/test/\n",
    "    - eval_input_reader: `input_path`, `label_map_path`\n",
    "    - `data_augmentation_options`, see augmentations and arguments in [preprocessor module](https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: this overwrites existing config file (copy only if no config already created)\n",
    "!cp {OD_PATH}samples/configs/faster_rcnn_inception_v2_pets.config {MAIN_PATH}training/faster_rcnn_inception_v2_kitchens.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move train.py from `legacy/` to `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp {OD_PATH}legacy/train.py ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model\n",
    "- Make sure to delete all files in `training/` except `labelmap.pbtxt` and the config file.\n",
    "- Needs to be stopped manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:56: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:56: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:185: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use object_detection/model_main.py.\n",
      "W1125 19:49:25.273615 140154295584576 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use object_detection/model_main.py.\n",
      "WARNING:tensorflow:From train.py:91: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W1125 19:49:25.273912 140154295584576 module_wrapper.py:139] From train.py:91: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1125 19:49:25.274301 140154295584576 module_wrapper.py:139] From /models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:96: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
      "\n",
      "W1125 19:49:25.277863 140154295584576 module_wrapper.py:139] From train.py:96: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/legacy/trainer.py:266: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.create_global_step\n",
      "W1125 19:49:25.283241 140154295584576 deprecation.py:323] From /models/research/object_detection/legacy/trainer.py:266: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.create_global_step\n",
      "WARNING:tensorflow:From /models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "W1125 19:49:25.288394 140154295584576 module_wrapper.py:139] From /models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "W1125 19:49:25.288648 140154295584576 module_wrapper.py:139] From /models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "W1125 19:49:25.304901 140154295584576 module_wrapper.py:139] From /models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/builders/dataset_builder.py:71: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "W1125 19:49:25.306433 140154295584576 module_wrapper.py:139] From /models/research/object_detection/builders/dataset_builder.py:71: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1125 19:49:25.306582 140154295584576 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "W1125 19:49:25.315780 140154295584576 deprecation.py:323] From /models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W1125 19:49:25.315978 140154295584576 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1125 19:49:25.345357 140154295584576 deprecation.py:323] From /models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "W1125 19:49:26.118707 140154295584576 deprecation.py:323] From /models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "WARNING:tensorflow:From /models/research/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W1125 19:49:26.127565 140154295584576 module_wrapper.py:139] From /models/research/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /models/research/object_detection/utils/autoaugment_utils.py:1388: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1125 19:49:26.133549 140154295584576 module_wrapper.py:139] From /models/research/object_detection/utils/autoaugment_utils.py:1388: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/utils/autoaugment_utils.py:1212: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1125 19:49:26.305870 140154295584576 deprecation.py:323] From /models/research/object_detection/utils/autoaugment_utils.py:1212: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /models/research/object_detection/utils/autoaugment_utils.py:898: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1125 19:49:26.359118 140154295584576 deprecation.py:323] From /models/research/object_detection/utils/autoaugment_utils.py:898: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /models/research/object_detection/utils/autoaugment_utils.py:900: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1125 19:49:26.361047 140154295584576 deprecation.py:323] From /models/research/object_detection/utils/autoaugment_utils.py:900: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "W1125 19:49:28.151098 140154295584576 deprecation.py:323] From /models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W1125 19:49:28.155927 140154295584576 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W1125 19:49:28.157161 140154295584576 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /models/research/object_detection/core/prefetcher.py:51: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n",
      "\n",
      "W1125 19:49:28.163731 140154295584576 module_wrapper.py:139] From /models/research/object_detection/core/prefetcher.py:51: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W1125 19:49:28.167964 140154295584576 module_wrapper.py:139] From /models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/legacy/trainer.py:285: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W1125 19:49:28.171662 140154295584576 module_wrapper.py:139] From /models/research/object_detection/legacy/trainer.py:285: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/slim/deployment/model_deploy.py:191: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W1125 19:49:28.172106 140154295584576 module_wrapper.py:139] From /models/research/slim/deployment/model_deploy.py:191: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/slim/deployment/model_deploy.py:191: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "W1125 19:49:28.172287 140154295584576 module_wrapper.py:139] From /models/research/slim/deployment/model_deploy.py:191: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "W1125 19:49:28.239195 140154295584576 module_wrapper.py:139] From /models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:2784: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W1125 19:49:28.298563 140154295584576 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:2784: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "W1125 19:49:30.208634 140154295584576 module_wrapper.py:139] From /models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1125 19:49:30.217760 140154295584576 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1125 19:49:30.237497 140154295584576 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W1125 19:49:30.238021 140154295584576 module_wrapper.py:139] From /models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1125 19:49:30.238170 140154295584576 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1125 19:49:31.183404 140154295584576 module_wrapper.py:139] From /models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/core/minibatch_sampler.py:85: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "W1125 19:49:31.238831 140154295584576 module_wrapper.py:139] From /models/research/object_detection/core/minibatch_sampler.py:85: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W1125 19:49:31.531489 140154295584576 deprecation.py:506] From /models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:189: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W1125 19:49:31.552389 140154295584576 module_wrapper.py:139] From /models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:189: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W1125 19:49:32.274295 140154295584576 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1125 19:49:32.277647 140154295584576 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1125 19:49:32.301612 140154295584576 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
      "\n",
      "W1125 19:49:32.632649 140154295584576 module_wrapper.py:139] From /models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "W1125 19:49:32.634290 140154295584576 module_wrapper.py:139] From /models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/core/losses.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W1125 19:49:32.695081 140154295584576 deprecation.py:323] From /models/research/object_detection/core/losses.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/legacy/trainer.py:208: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
      "\n",
      "W1125 19:49:33.002695 140154295584576 module_wrapper.py:139] From /models/research/object_detection/legacy/trainer.py:208: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/builders/optimizer_builder.py:95: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "W1125 19:49:33.003567 140154295584576 module_wrapper.py:139] From /models/research/object_detection/builders/optimizer_builder.py:95: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "W1125 19:49:33.014959 140154295584576 module_wrapper.py:139] From /models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "WARNING:tensorflow:From /models/research/object_detection/legacy/trainer.py:322: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n",
      "\n",
      "W1125 19:49:35.119089 140154295584576 module_wrapper.py:139] From /models/research/object_detection/legacy/trainer.py:322: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/legacy/trainer.py:353: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "W1125 19:49:38.760345 140154295584576 module_wrapper.py:139] From /models/research/object_detection/legacy/trainer.py:353: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/legacy/trainer.py:355: The name tf.losses.get_losses is deprecated. Please use tf.compat.v1.losses.get_losses instead.\n",
      "\n",
      "W1125 19:49:39.159839 140154295584576 module_wrapper.py:139] From /models/research/object_detection/legacy/trainer.py:355: The name tf.losses.get_losses is deprecated. Please use tf.compat.v1.losses.get_losses instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/legacy/trainer.py:359: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.\n",
      "\n",
      "W1125 19:49:39.164806 140154295584576 module_wrapper.py:139] From /models/research/object_detection/legacy/trainer.py:359: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/legacy/trainer.py:368: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "W1125 19:49:39.168761 140154295584576 module_wrapper.py:139] From /models/research/object_detection/legacy/trainer.py:368: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/legacy/trainer.py:371: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1125 19:49:39.179886 140154295584576 module_wrapper.py:139] From /models/research/object_detection/legacy/trainer.py:371: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/legacy/trainer.py:376: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W1125 19:49:39.180160 140154295584576 module_wrapper.py:139] From /models/research/object_detection/legacy/trainer.py:376: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\r\n",
      "\r\n",
      "W1125 19:49:39.720507 140154295584576 module_wrapper.py:139] From /models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\r\n",
      "\r\n",
      "WARNING:tensorflow:From /models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2766: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Please switch to tf.train.get_or_create_global_step\r\n",
      "W1125 19:49:39.720846 140154295584576 deprecation.py:323] From /models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2766: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Please switch to tf.train.get_or_create_global_step\r\n",
      "WARNING:tensorflow:From /models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\r\n",
      "\r\n",
      "W1125 19:49:39.722709 140154295584576 module_wrapper.py:139] From /models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\r\n",
      "\r\n",
      "W1125 19:49:39.724901 140154295584576 variables_helper.py:157] Variable [Conv/biases/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.725063 140154295584576 variables_helper.py:157] Variable [Conv/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.725160 140154295584576 variables_helper.py:157] Variable [FirstStageBoxPredictor/BoxEncodingPredictor/biases/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.725245 140154295584576 variables_helper.py:157] Variable [FirstStageBoxPredictor/BoxEncodingPredictor/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.725327 140154295584576 variables_helper.py:157] Variable [FirstStageBoxPredictor/ClassPredictor/biases/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.725406 140154295584576 variables_helper.py:157] Variable [FirstStageBoxPredictor/ClassPredictor/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.725480 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.725554 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.725637 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/depthwise_weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.725714 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.725787 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.725860 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.725999 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.726078 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.726151 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.726234 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.726309 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.726384 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.726470 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.726544 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.726617 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.726696 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.726768 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.726847 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.726926 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.727000 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.727072 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.727153 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.727227 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.727300 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.727388 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.727460 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.727532 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.727611 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.727682 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.727754 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.727833 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.727906 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.727994 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.728073 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.728147 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.728219 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.728298 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.728371 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.728443 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.728529 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.728603 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.728675 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.728764 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.728839 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.728912 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.728992 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.729072 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.729144 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.729228 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.729301 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.729373 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.729455 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.729528 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.729600 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.729690 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.729762 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.729836 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.729945 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.730023 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.730096 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.730176 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.730249 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.730322 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.730403 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.730477 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.730550 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1125 19:49:39.730630 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.730705 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.730777 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.730858 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.730931 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.731004 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.731085 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.731159 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.731231 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.731313 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.731385 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.731457 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.731538 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.731610 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.731682 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.731763 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.731835 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.731907 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.731987 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.732060 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.732132 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.732213 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.732287 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.732359 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.732442 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.732514 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.732587 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.732667 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.732740 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.732811 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.732894 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.732966 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.733038 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.733123 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.733197 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.733269 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.733361 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.733448 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.733522 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.733604 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.733677 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.733750 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.733831 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.733942 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.734029 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.734121 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.734204 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.734285 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.734379 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.734461 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.734539 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.734625 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.734703 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.734780 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.734864 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.734941 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.735010 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.735094 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.735171 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.735247 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.735333 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.735409 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.735485 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.735570 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.735648 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.735723 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.735806 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.735882 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.735958 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.736041 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.736116 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.736191 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.736275 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.736351 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.736425 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.736509 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.736584 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.736659 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.736743 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.736819 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.736894 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.736978 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.737054 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.737129 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.737216 140154295584576 variables_helper.py:157] Variable [FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.737294 140154295584576 variables_helper.py:154] Variable [SecondStageBoxPredictor/BoxEncodingPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[360]], model variable shape: [[40]]. This variable will not be initialized from the checkpoint.\r\n",
      "W1125 19:49:39.737369 140154295584576 variables_helper.py:157] Variable [SecondStageBoxPredictor/BoxEncodingPredictor/biases/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.737449 140154295584576 variables_helper.py:154] Variable [SecondStageBoxPredictor/BoxEncodingPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1024, 360]], model variable shape: [[1024, 40]]. This variable will not be initialized from the checkpoint.\r\n",
      "W1125 19:49:39.737520 140154295584576 variables_helper.py:157] Variable [SecondStageBoxPredictor/BoxEncodingPredictor/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.737598 140154295584576 variables_helper.py:154] Variable [SecondStageBoxPredictor/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[91]], model variable shape: [[11]]. This variable will not be initialized from the checkpoint.\r\n",
      "W1125 19:49:39.737668 140154295584576 variables_helper.py:157] Variable [SecondStageBoxPredictor/ClassPredictor/biases/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.737748 140154295584576 variables_helper.py:154] Variable [SecondStageBoxPredictor/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1024, 91]], model variable shape: [[1024, 11]]. This variable will not be initialized from the checkpoint.\r\n",
      "W1125 19:49:39.737818 140154295584576 variables_helper.py:157] Variable [SecondStageBoxPredictor/ClassPredictor/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.737926 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.738008 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.738095 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.738171 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.738247 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.738326 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.738401 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.738478 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.738564 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.738641 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.738724 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.738812 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.738888 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.738964 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.739050 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.739127 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.739203 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.739291 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.739367 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.739443 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.739530 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.739606 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.739682 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.739768 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.739844 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.739921 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.740007 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.740083 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.740158 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.740244 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.740319 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.740395 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.740481 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.740557 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.740632 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.740717 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.740794 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.740870 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.740957 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.741034 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.741110 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.741197 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.741273 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.741348 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.741436 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.741513 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.741588 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.741675 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.741744 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.741818 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.742179 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.742262 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.742339 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.742426 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.742502 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm/beta/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.742578 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm/gamma/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.742664 140154295584576 variables_helper.py:157] Variable [SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights/Momentum] is not available in checkpoint\r\n",
      "W1125 19:49:39.742735 140154295584576 variables_helper.py:157] Variable [global_step] is not available in checkpoint\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "W1125 19:49:40.699921 140154295584576 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "2019-11-25 19:49:41.818402: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-11-25 19:49:41.835979: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100060000 Hz\n",
      "2019-11-25 19:49:41.836863: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xf652860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2019-11-25 19:49:41.836900: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2019-11-25 19:49:41.839139: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2019-11-25 19:49:41.839171: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2019-11-25 19:49:41.839211: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (34c587f1c563): /proc/driver/nvidia/version does not exist\n",
      "INFO:tensorflow:Restoring parameters from /happy-walrus/models/version_3/training/model.ckpt-0\n",
      "I1125 19:49:41.841924 140154295584576 saver.py:1284] Restoring parameters from /happy-walrus/models/version_3/training/model.ckpt-0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "W1125 19:49:43.795184 140154295584576 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I1125 19:49:43.796751 140154295584576 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I1125 19:49:44.433748 140154295584576 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Starting Session.\n",
      "I1125 19:49:53.437154 140154295584576 learning.py:754] Starting Session.\n",
      "INFO:tensorflow:Saving checkpoint to path /happy-walrus/models/version_3/training/model.ckpt\n",
      "I1125 19:49:53.927232 140149849569024 supervisor.py:1117] Saving checkpoint to path /happy-walrus/models/version_3/training/model.ckpt\n",
      "INFO:tensorflow:Starting Queues.\n",
      "I1125 19:49:53.949610 140154295584576 learning.py:768] Starting Queues.\n",
      "INFO:tensorflow:Recording summary at step 0.\n",
      "I1125 19:50:00.487232 140149832783616 supervisor.py:1050] Recording summary at step 0.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "I1125 19:50:07.191049 140149841176320 supervisor.py:1099] global_step/sec: 0\n",
      "INFO:tensorflow:global step 1: loss = 4.5047 (20.084 sec/step)\n",
      "I1125 19:50:14.454794 140154295584576 learning.py:507] global step 1: loss = 4.5047 (20.084 sec/step)\n",
      "INFO:tensorflow:global step 2: loss = 4.4620 (1.606 sec/step)\n",
      "I1125 19:50:16.481528 140154295584576 learning.py:507] global step 2: loss = 4.4620 (1.606 sec/step)\n",
      "INFO:tensorflow:global step 3: loss = 3.5126 (1.478 sec/step)\n",
      "I1125 19:50:17.961225 140154295584576 learning.py:507] global step 3: loss = 3.5126 (1.478 sec/step)\n",
      "INFO:tensorflow:global step 4: loss = 3.6928 (1.424 sec/step)\n",
      "I1125 19:50:19.386440 140154295584576 learning.py:507] global step 4: loss = 3.6928 (1.424 sec/step)\n",
      "INFO:tensorflow:global step 5: loss = 4.3192 (1.512 sec/step)\n",
      "I1125 19:50:20.905365 140154295584576 learning.py:507] global step 5: loss = 4.3192 (1.512 sec/step)\n",
      "INFO:tensorflow:global step 6: loss = 3.1746 (2.609 sec/step)\n",
      "I1125 19:50:23.515841 140154295584576 learning.py:507] global step 6: loss = 3.1746 (2.609 sec/step)\n",
      "INFO:tensorflow:global step 7: loss = 3.2615 (1.590 sec/step)\n",
      "I1125 19:50:25.107134 140154295584576 learning.py:507] global step 7: loss = 3.2615 (1.590 sec/step)\n",
      "INFO:tensorflow:global step 8: loss = 4.3224 (1.567 sec/step)\n",
      "I1125 19:50:26.674910 140154295584576 learning.py:507] global step 8: loss = 4.3224 (1.567 sec/step)\n",
      "INFO:tensorflow:global step 9: loss = 2.2141 (1.635 sec/step)\n",
      "I1125 19:50:28.311491 140154295584576 learning.py:507] global step 9: loss = 2.2141 (1.635 sec/step)\n",
      "INFO:tensorflow:global step 10: loss = 3.7989 (1.402 sec/step)\n",
      "I1125 19:50:29.715134 140154295584576 learning.py:507] global step 10: loss = 3.7989 (1.402 sec/step)\n",
      "INFO:tensorflow:global step 11: loss = 2.8634 (1.446 sec/step)\n",
      "I1125 19:50:31.162727 140154295584576 learning.py:507] global step 11: loss = 2.8634 (1.446 sec/step)\n",
      "INFO:tensorflow:global step 12: loss = 2.6159 (1.101 sec/step)\n",
      "I1125 19:50:32.265225 140154295584576 learning.py:507] global step 12: loss = 2.6159 (1.101 sec/step)\n",
      "INFO:tensorflow:global step 13: loss = 2.3212 (1.369 sec/step)\n",
      "I1125 19:50:33.635599 140154295584576 learning.py:507] global step 13: loss = 2.3212 (1.369 sec/step)\n",
      "INFO:tensorflow:global step 14: loss = 1.3890 (1.625 sec/step)\n",
      "I1125 19:50:35.261396 140154295584576 learning.py:507] global step 14: loss = 1.3890 (1.625 sec/step)\n",
      "INFO:tensorflow:global step 15: loss = 1.2300 (1.096 sec/step)\n",
      "I1125 19:50:36.358526 140154295584576 learning.py:507] global step 15: loss = 1.2300 (1.096 sec/step)\n",
      "INFO:tensorflow:global step 16: loss = 0.9692 (1.600 sec/step)\n",
      "I1125 19:50:37.959901 140154295584576 learning.py:507] global step 16: loss = 0.9692 (1.600 sec/step)\n",
      "INFO:tensorflow:global step 17: loss = 2.5685 (1.496 sec/step)\n",
      "I1125 19:50:39.457090 140154295584576 learning.py:507] global step 17: loss = 2.5685 (1.496 sec/step)\n",
      "INFO:tensorflow:global step 18: loss = 2.8824 (1.719 sec/step)\n",
      "I1125 19:50:41.177042 140154295584576 learning.py:507] global step 18: loss = 2.8824 (1.719 sec/step)\n",
      "INFO:tensorflow:global step 19: loss = 1.7067 (2.429 sec/step)\n",
      "I1125 19:50:43.607278 140154295584576 learning.py:507] global step 19: loss = 1.7067 (2.429 sec/step)\n",
      "INFO:tensorflow:global step 20: loss = 2.8519 (1.644 sec/step)\n",
      "I1125 19:50:45.253091 140154295584576 learning.py:507] global step 20: loss = 2.8519 (1.644 sec/step)\n",
      "INFO:tensorflow:global step 21: loss = 1.2983 (1.499 sec/step)\n",
      "I1125 19:50:46.753123 140154295584576 learning.py:507] global step 21: loss = 1.2983 (1.499 sec/step)\n",
      "INFO:tensorflow:global step 22: loss = 2.7235 (1.536 sec/step)\n",
      "I1125 19:50:48.289812 140154295584576 learning.py:507] global step 22: loss = 2.7235 (1.536 sec/step)\n",
      "INFO:tensorflow:global step 23: loss = 0.3133 (1.560 sec/step)\n",
      "I1125 19:50:49.850572 140154295584576 learning.py:507] global step 23: loss = 0.3133 (1.560 sec/step)\n",
      "INFO:tensorflow:global step 24: loss = 2.2075 (1.505 sec/step)\n",
      "I1125 19:50:51.356336 140154295584576 learning.py:507] global step 24: loss = 2.2075 (1.505 sec/step)\n",
      "INFO:tensorflow:global step 25: loss = 1.4649 (1.394 sec/step)\n",
      "I1125 19:50:52.751873 140154295584576 learning.py:507] global step 25: loss = 1.4649 (1.394 sec/step)\n",
      "INFO:tensorflow:global step 26: loss = 0.4723 (1.377 sec/step)\n",
      "I1125 19:50:54.130170 140154295584576 learning.py:507] global step 26: loss = 0.4723 (1.377 sec/step)\n",
      "INFO:tensorflow:global step 27: loss = 3.0604 (1.380 sec/step)\n",
      "I1125 19:50:55.511113 140154295584576 learning.py:507] global step 27: loss = 3.0604 (1.380 sec/step)\n",
      "INFO:tensorflow:global step 28: loss = 0.5948 (1.439 sec/step)\n",
      "I1125 19:50:56.951681 140154295584576 learning.py:507] global step 28: loss = 0.5948 (1.439 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global step 29: loss = 2.9479 (1.519 sec/step)\n",
      "I1125 19:50:58.471572 140154295584576 learning.py:507] global step 29: loss = 2.9479 (1.519 sec/step)\n",
      "INFO:tensorflow:global step 30: loss = 0.7549 (1.460 sec/step)\n",
      "I1125 19:50:59.933271 140154295584576 learning.py:507] global step 30: loss = 0.7549 (1.460 sec/step)\n",
      "INFO:tensorflow:global step 31: loss = 1.5376 (1.658 sec/step)\n",
      "I1125 19:51:01.591981 140154295584576 learning.py:507] global step 31: loss = 1.5376 (1.658 sec/step)\n",
      "INFO:tensorflow:global step 32: loss = 2.2135 (1.443 sec/step)\n",
      "I1125 19:51:03.037569 140154295584576 learning.py:507] global step 32: loss = 2.2135 (1.443 sec/step)\n",
      "INFO:tensorflow:global step 33: loss = 1.1468 (2.109 sec/step)\n",
      "I1125 19:51:05.148118 140154295584576 learning.py:507] global step 33: loss = 1.1468 (2.109 sec/step)\n",
      "INFO:tensorflow:global step 34: loss = 2.5041 (1.595 sec/step)\n",
      "I1125 19:51:06.744058 140154295584576 learning.py:507] global step 34: loss = 2.5041 (1.595 sec/step)\n",
      "INFO:tensorflow:global step 35: loss = 0.1101 (1.514 sec/step)\n",
      "I1125 19:51:08.259427 140154295584576 learning.py:507] global step 35: loss = 0.1101 (1.514 sec/step)\n",
      "INFO:tensorflow:global step 36: loss = 1.2230 (1.378 sec/step)\n",
      "I1125 19:51:09.638820 140154295584576 learning.py:507] global step 36: loss = 1.2230 (1.378 sec/step)\n",
      "INFO:tensorflow:global step 37: loss = 1.1177 (1.541 sec/step)\n",
      "I1125 19:51:11.180567 140154295584576 learning.py:507] global step 37: loss = 1.1177 (1.541 sec/step)\n",
      "INFO:tensorflow:global step 38: loss = 2.1710 (1.147 sec/step)\n",
      "I1125 19:51:12.328784 140154295584576 learning.py:507] global step 38: loss = 2.1710 (1.147 sec/step)\n",
      "INFO:tensorflow:global step 39: loss = 0.8951 (1.536 sec/step)\n",
      "I1125 19:51:13.865847 140154295584576 learning.py:507] global step 39: loss = 0.8951 (1.536 sec/step)\n",
      "INFO:tensorflow:global step 40: loss = 2.2609 (1.420 sec/step)\n",
      "I1125 19:51:15.286626 140154295584576 learning.py:507] global step 40: loss = 2.2609 (1.420 sec/step)\n",
      "INFO:tensorflow:global step 41: loss = 2.2691 (1.580 sec/step)\n",
      "I1125 19:51:16.867628 140154295584576 learning.py:507] global step 41: loss = 2.2691 (1.580 sec/step)\n",
      "INFO:tensorflow:global step 42: loss = 2.1172 (1.169 sec/step)\n",
      "I1125 19:51:18.038031 140154295584576 learning.py:507] global step 42: loss = 2.1172 (1.169 sec/step)\n",
      "INFO:tensorflow:global step 43: loss = 1.9412 (1.516 sec/step)\n",
      "I1125 19:51:19.554886 140154295584576 learning.py:507] global step 43: loss = 1.9412 (1.516 sec/step)\n",
      "INFO:tensorflow:global step 44: loss = 2.1225 (1.329 sec/step)\n",
      "I1125 19:51:20.885087 140154295584576 learning.py:507] global step 44: loss = 2.1225 (1.329 sec/step)\n",
      "INFO:tensorflow:global step 45: loss = 0.3241 (1.395 sec/step)\n",
      "I1125 19:51:22.280977 140154295584576 learning.py:507] global step 45: loss = 0.3241 (1.395 sec/step)\n",
      "INFO:tensorflow:global step 46: loss = 1.6976 (1.471 sec/step)\n",
      "I1125 19:51:23.752710 140154295584576 learning.py:507] global step 46: loss = 1.6976 (1.471 sec/step)\n",
      "INFO:tensorflow:global step 47: loss = 1.1060 (1.508 sec/step)\n",
      "I1125 19:51:25.262250 140154295584576 learning.py:507] global step 47: loss = 1.1060 (1.508 sec/step)\n",
      "INFO:tensorflow:global step 48: loss = 0.7733 (1.522 sec/step)\n",
      "I1125 19:51:26.785245 140154295584576 learning.py:507] global step 48: loss = 0.7733 (1.522 sec/step)\n",
      "INFO:tensorflow:global step 49: loss = 1.1254 (1.404 sec/step)\n",
      "I1125 19:51:28.190426 140154295584576 learning.py:507] global step 49: loss = 1.1254 (1.404 sec/step)\n",
      "INFO:tensorflow:global step 50: loss = 0.5662 (1.520 sec/step)\n",
      "I1125 19:51:29.711226 140154295584576 learning.py:507] global step 50: loss = 0.5662 (1.520 sec/step)\n",
      "INFO:tensorflow:global step 51: loss = 0.7679 (1.714 sec/step)\n",
      "I1125 19:51:31.426138 140154295584576 learning.py:507] global step 51: loss = 0.7679 (1.714 sec/step)\n",
      "INFO:tensorflow:global step 52: loss = 1.1611 (2.201 sec/step)\n",
      "I1125 19:51:33.628000 140154295584576 learning.py:507] global step 52: loss = 1.1611 (2.201 sec/step)\n",
      "INFO:tensorflow:global step 53: loss = 1.6390 (1.117 sec/step)\n",
      "I1125 19:51:34.746371 140154295584576 learning.py:507] global step 53: loss = 1.6390 (1.117 sec/step)\n",
      "INFO:tensorflow:global step 54: loss = 1.1277 (1.538 sec/step)\n",
      "I1125 19:51:36.285964 140154295584576 learning.py:507] global step 54: loss = 1.1277 (1.538 sec/step)\n",
      "INFO:tensorflow:global step 55: loss = 1.8457 (1.414 sec/step)\n",
      "I1125 19:51:37.701684 140154295584576 learning.py:507] global step 55: loss = 1.8457 (1.414 sec/step)\n",
      "INFO:tensorflow:global step 56: loss = 1.3484 (1.490 sec/step)\n",
      "I1125 19:51:39.192707 140154295584576 learning.py:507] global step 56: loss = 1.3484 (1.490 sec/step)\n",
      "INFO:tensorflow:global step 57: loss = 2.2294 (1.420 sec/step)\n",
      "I1125 19:51:40.613497 140154295584576 learning.py:507] global step 57: loss = 2.2294 (1.420 sec/step)\n",
      "INFO:tensorflow:global step 58: loss = 1.7522 (1.422 sec/step)\n",
      "I1125 19:51:42.037128 140154295584576 learning.py:507] global step 58: loss = 1.7522 (1.422 sec/step)\n",
      "INFO:tensorflow:global step 59: loss = 1.7188 (1.220 sec/step)\n",
      "I1125 19:51:43.258507 140154295584576 learning.py:507] global step 59: loss = 1.7188 (1.220 sec/step)\n",
      "INFO:tensorflow:global step 60: loss = 1.3794 (1.128 sec/step)\n",
      "I1125 19:51:44.388063 140154295584576 learning.py:507] global step 60: loss = 1.3794 (1.128 sec/step)\n",
      "INFO:tensorflow:global step 61: loss = 0.3063 (1.489 sec/step)\n",
      "I1125 19:51:45.878478 140154295584576 learning.py:507] global step 61: loss = 0.3063 (1.489 sec/step)\n",
      "INFO:tensorflow:global step 62: loss = 2.0338 (1.576 sec/step)\n",
      "I1125 19:51:47.456218 140154295584576 learning.py:507] global step 62: loss = 2.0338 (1.576 sec/step)\n",
      "INFO:tensorflow:global step 63: loss = 0.9129 (1.655 sec/step)\n",
      "I1125 19:51:49.112020 140154295584576 learning.py:507] global step 63: loss = 0.9129 (1.655 sec/step)\n",
      "INFO:tensorflow:global step 64: loss = 0.6293 (1.356 sec/step)\n",
      "I1125 19:51:50.469081 140154295584576 learning.py:507] global step 64: loss = 0.6293 (1.356 sec/step)\n",
      "INFO:tensorflow:global step 65: loss = 2.3762 (1.698 sec/step)\n",
      "I1125 19:51:52.169349 140154295584576 learning.py:507] global step 65: loss = 2.3762 (1.698 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 65.\n",
      "I1125 19:51:54.333767 140149832783616 supervisor.py:1050] Recording summary at step 65.\n",
      "INFO:tensorflow:global step 66: loss = 2.0282 (2.318 sec/step)\n",
      "I1125 19:51:54.488931 140154295584576 learning.py:507] global step 66: loss = 2.0282 (2.318 sec/step)\n",
      "INFO:tensorflow:global step 67: loss = 0.5602 (1.492 sec/step)\n",
      "I1125 19:51:55.983253 140154295584576 learning.py:507] global step 67: loss = 0.5602 (1.492 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 0.6121\n",
      "I1125 19:51:56.650237 140149841176320 supervisor.py:1099] global_step/sec: 0.6121\n",
      "INFO:tensorflow:global step 68: loss = 1.8113 (1.551 sec/step)\n",
      "I1125 19:51:57.535736 140154295584576 learning.py:507] global step 68: loss = 1.8113 (1.551 sec/step)\n",
      "INFO:tensorflow:global step 69: loss = 0.5375 (1.234 sec/step)\n",
      "I1125 19:51:58.771115 140154295584576 learning.py:507] global step 69: loss = 0.5375 (1.234 sec/step)\n",
      "INFO:tensorflow:global step 70: loss = 1.9093 (1.627 sec/step)\n",
      "I1125 19:52:00.399498 140154295584576 learning.py:507] global step 70: loss = 1.9093 (1.627 sec/step)\n",
      "INFO:tensorflow:global step 71: loss = 1.1934 (1.579 sec/step)\n",
      "I1125 19:52:01.979496 140154295584576 learning.py:507] global step 71: loss = 1.1934 (1.579 sec/step)\n",
      "INFO:tensorflow:global step 72: loss = 0.5416 (1.419 sec/step)\n",
      "I1125 19:52:03.400174 140154295584576 learning.py:507] global step 72: loss = 0.5416 (1.419 sec/step)\n",
      "INFO:tensorflow:global step 73: loss = 0.2751 (1.454 sec/step)\n",
      "I1125 19:52:04.855611 140154295584576 learning.py:507] global step 73: loss = 0.2751 (1.454 sec/step)\n",
      "INFO:tensorflow:global step 74: loss = 1.5868 (1.545 sec/step)\n",
      "I1125 19:52:06.401927 140154295584576 learning.py:507] global step 74: loss = 1.5868 (1.545 sec/step)\n",
      "INFO:tensorflow:global step 75: loss = 2.2160 (1.574 sec/step)\n",
      "I1125 19:52:07.977339 140154295584576 learning.py:507] global step 75: loss = 2.2160 (1.574 sec/step)\n",
      "INFO:tensorflow:global step 76: loss = 1.1165 (1.449 sec/step)\n",
      "I1125 19:52:09.427511 140154295584576 learning.py:507] global step 76: loss = 1.1165 (1.449 sec/step)\n",
      "INFO:tensorflow:global step 77: loss = 1.1934 (1.532 sec/step)\n",
      "I1125 19:52:10.960412 140154295584576 learning.py:507] global step 77: loss = 1.1934 (1.532 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global step 78: loss = 1.6217 (1.671 sec/step)\n",
      "I1125 19:52:12.632369 140154295584576 learning.py:507] global step 78: loss = 1.6217 (1.671 sec/step)\n",
      "INFO:tensorflow:global step 79: loss = 0.3620 (1.492 sec/step)\n",
      "I1125 19:52:14.126034 140154295584576 learning.py:507] global step 79: loss = 0.3620 (1.492 sec/step)\n",
      "INFO:tensorflow:global step 80: loss = 1.0473 (1.666 sec/step)\n",
      "I1125 19:52:15.794077 140154295584576 learning.py:507] global step 80: loss = 1.0473 (1.666 sec/step)\n",
      "INFO:tensorflow:global step 81: loss = 1.8511 (1.764 sec/step)\n",
      "I1125 19:52:17.559450 140154295584576 learning.py:507] global step 81: loss = 1.8511 (1.764 sec/step)\n",
      "INFO:tensorflow:global step 82: loss = 2.1021 (1.370 sec/step)\n",
      "I1125 19:52:18.930917 140154295584576 learning.py:507] global step 82: loss = 2.1021 (1.370 sec/step)\n",
      "INFO:tensorflow:global step 83: loss = 1.5179 (1.243 sec/step)\n",
      "I1125 19:52:20.174968 140154295584576 learning.py:507] global step 83: loss = 1.5179 (1.243 sec/step)\n",
      "INFO:tensorflow:global step 84: loss = 2.0924 (1.297 sec/step)\n",
      "I1125 19:52:21.473611 140154295584576 learning.py:507] global step 84: loss = 2.0924 (1.297 sec/step)\n",
      "INFO:tensorflow:global step 85: loss = 1.7066 (1.542 sec/step)\n",
      "I1125 19:52:23.017317 140154295584576 learning.py:507] global step 85: loss = 1.7066 (1.542 sec/step)\n",
      "INFO:tensorflow:global step 86: loss = 0.7138 (1.397 sec/step)\n",
      "I1125 19:52:24.415032 140154295584576 learning.py:507] global step 86: loss = 0.7138 (1.397 sec/step)\n",
      "INFO:tensorflow:global step 87: loss = 1.1887 (1.474 sec/step)\n",
      "I1125 19:52:25.890397 140154295584576 learning.py:507] global step 87: loss = 1.1887 (1.474 sec/step)\n",
      "INFO:tensorflow:global step 88: loss = 0.6085 (1.432 sec/step)\n",
      "I1125 19:52:27.323261 140154295584576 learning.py:507] global step 88: loss = 0.6085 (1.432 sec/step)\n",
      "INFO:tensorflow:global step 89: loss = 1.4565 (1.394 sec/step)\n",
      "I1125 19:52:28.718308 140154295584576 learning.py:507] global step 89: loss = 1.4565 (1.394 sec/step)\n",
      "INFO:tensorflow:global step 90: loss = 1.7934 (1.702 sec/step)\n",
      "I1125 19:52:30.420961 140154295584576 learning.py:507] global step 90: loss = 1.7934 (1.702 sec/step)\n",
      "INFO:tensorflow:global step 91: loss = 2.1458 (1.543 sec/step)\n",
      "I1125 19:52:31.965140 140154295584576 learning.py:507] global step 91: loss = 2.1458 (1.543 sec/step)\n",
      "INFO:tensorflow:global step 92: loss = 2.0895 (1.517 sec/step)\n",
      "I1125 19:52:33.482896 140154295584576 learning.py:507] global step 92: loss = 2.0895 (1.517 sec/step)\n",
      "INFO:tensorflow:global step 93: loss = 2.1731 (1.533 sec/step)\n",
      "I1125 19:52:35.017274 140154295584576 learning.py:507] global step 93: loss = 2.1731 (1.533 sec/step)\n",
      "INFO:tensorflow:global step 94: loss = 1.3977 (1.542 sec/step)\n",
      "I1125 19:52:36.560062 140154295584576 learning.py:507] global step 94: loss = 1.3977 (1.542 sec/step)\n",
      "INFO:tensorflow:global step 95: loss = 0.5016 (1.273 sec/step)\n",
      "I1125 19:52:37.834545 140154295584576 learning.py:507] global step 95: loss = 0.5016 (1.273 sec/step)\n",
      "INFO:tensorflow:global step 96: loss = 0.3938 (1.484 sec/step)\n",
      "I1125 19:52:39.320814 140154295584576 learning.py:507] global step 96: loss = 0.3938 (1.484 sec/step)\n",
      "INFO:tensorflow:global step 97: loss = 1.4127 (2.100 sec/step)\n",
      "I1125 19:52:41.422441 140154295584576 learning.py:507] global step 97: loss = 1.4127 (2.100 sec/step)\n",
      "INFO:tensorflow:global step 98: loss = 1.1324 (1.265 sec/step)\n",
      "I1125 19:52:42.688293 140154295584576 learning.py:507] global step 98: loss = 1.1324 (1.265 sec/step)\n",
      "INFO:tensorflow:global step 99: loss = 2.0421 (1.106 sec/step)\n",
      "I1125 19:52:43.795446 140154295584576 learning.py:507] global step 99: loss = 2.0421 (1.106 sec/step)\n",
      "INFO:tensorflow:global step 100: loss = 1.4007 (1.597 sec/step)\n",
      "I1125 19:52:45.393122 140154295584576 learning.py:507] global step 100: loss = 1.4007 (1.597 sec/step)\n",
      "INFO:tensorflow:global step 101: loss = 0.5823 (1.446 sec/step)\n",
      "I1125 19:52:46.839859 140154295584576 learning.py:507] global step 101: loss = 0.5823 (1.446 sec/step)\n",
      "INFO:tensorflow:global step 102: loss = 2.2560 (1.519 sec/step)\n",
      "I1125 19:52:48.360165 140154295584576 learning.py:507] global step 102: loss = 2.2560 (1.519 sec/step)\n",
      "INFO:tensorflow:global step 103: loss = 1.8512 (1.456 sec/step)\n",
      "I1125 19:52:49.817288 140154295584576 learning.py:507] global step 103: loss = 1.8512 (1.456 sec/step)\n",
      "INFO:tensorflow:global step 104: loss = 0.4618 (1.432 sec/step)\n",
      "I1125 19:52:51.250431 140154295584576 learning.py:507] global step 104: loss = 0.4618 (1.432 sec/step)\n",
      "INFO:tensorflow:global step 105: loss = 2.2516 (1.482 sec/step)\n",
      "I1125 19:52:52.733703 140154295584576 learning.py:507] global step 105: loss = 2.2516 (1.482 sec/step)\n",
      "INFO:tensorflow:global step 106: loss = 0.1111 (1.406 sec/step)\n",
      "I1125 19:52:54.140782 140154295584576 learning.py:507] global step 106: loss = 0.1111 (1.406 sec/step)\n",
      "INFO:tensorflow:global step 107: loss = 0.5887 (1.518 sec/step)\n",
      "I1125 19:52:55.659897 140154295584576 learning.py:507] global step 107: loss = 0.5887 (1.518 sec/step)\n",
      "INFO:tensorflow:global step 108: loss = 0.4176 (1.457 sec/step)\n",
      "I1125 19:52:57.118330 140154295584576 learning.py:507] global step 108: loss = 0.4176 (1.457 sec/step)\n",
      "INFO:tensorflow:global step 109: loss = 1.8137 (1.557 sec/step)\n",
      "I1125 19:52:58.676098 140154295584576 learning.py:507] global step 109: loss = 1.8137 (1.557 sec/step)\n",
      "INFO:tensorflow:global step 110: loss = 0.8395 (1.479 sec/step)\n",
      "I1125 19:53:00.156381 140154295584576 learning.py:507] global step 110: loss = 0.8395 (1.479 sec/step)\n",
      "INFO:tensorflow:global step 111: loss = 1.0821 (1.607 sec/step)\n",
      "I1125 19:53:01.764537 140154295584576 learning.py:507] global step 111: loss = 1.0821 (1.607 sec/step)\n",
      "INFO:tensorflow:global step 112: loss = 0.9882 (1.676 sec/step)\n",
      "I1125 19:53:03.441478 140154295584576 learning.py:507] global step 112: loss = 0.9882 (1.676 sec/step)\n",
      "INFO:tensorflow:global step 113: loss = 2.2394 (2.193 sec/step)\n",
      "I1125 19:53:05.635474 140154295584576 learning.py:507] global step 113: loss = 2.2394 (2.193 sec/step)\n",
      "INFO:tensorflow:global step 114: loss = 1.8908 (1.405 sec/step)\n",
      "I1125 19:53:07.041596 140154295584576 learning.py:507] global step 114: loss = 1.8908 (1.405 sec/step)\n",
      "INFO:tensorflow:global step 115: loss = 1.4394 (1.580 sec/step)\n",
      "I1125 19:53:08.622818 140154295584576 learning.py:507] global step 115: loss = 1.4394 (1.580 sec/step)\n",
      "INFO:tensorflow:global step 116: loss = 1.5984 (1.589 sec/step)\n",
      "I1125 19:53:10.213091 140154295584576 learning.py:507] global step 116: loss = 1.5984 (1.589 sec/step)\n",
      "INFO:tensorflow:global step 117: loss = 1.0759 (1.388 sec/step)\n",
      "I1125 19:53:11.601866 140154295584576 learning.py:507] global step 117: loss = 1.0759 (1.388 sec/step)\n",
      "INFO:tensorflow:global step 118: loss = 0.9051 (1.491 sec/step)\n",
      "I1125 19:53:13.094394 140154295584576 learning.py:507] global step 118: loss = 0.9051 (1.491 sec/step)\n",
      "INFO:tensorflow:global step 119: loss = 2.5089 (1.532 sec/step)\n",
      "I1125 19:53:14.627695 140154295584576 learning.py:507] global step 119: loss = 2.5089 (1.532 sec/step)\n",
      "INFO:tensorflow:global step 120: loss = 0.6096 (1.369 sec/step)\n",
      "I1125 19:53:15.997514 140154295584576 learning.py:507] global step 120: loss = 0.6096 (1.369 sec/step)\n",
      "INFO:tensorflow:global step 121: loss = 1.9023 (1.490 sec/step)\n",
      "I1125 19:53:17.489514 140154295584576 learning.py:507] global step 121: loss = 1.9023 (1.490 sec/step)\n",
      "INFO:tensorflow:global step 122: loss = 1.9557 (1.567 sec/step)\n",
      "I1125 19:53:19.058293 140154295584576 learning.py:507] global step 122: loss = 1.9557 (1.567 sec/step)\n",
      "INFO:tensorflow:global step 123: loss = 1.4367 (1.470 sec/step)\n",
      "I1125 19:53:20.529373 140154295584576 learning.py:507] global step 123: loss = 1.4367 (1.470 sec/step)\n",
      "INFO:tensorflow:global step 124: loss = 1.6201 (1.214 sec/step)\n",
      "I1125 19:53:21.744991 140154295584576 learning.py:507] global step 124: loss = 1.6201 (1.214 sec/step)\n",
      "INFO:tensorflow:global step 125: loss = 0.9032 (1.704 sec/step)\n",
      "I1125 19:53:23.450348 140154295584576 learning.py:507] global step 125: loss = 0.9032 (1.704 sec/step)\n",
      "INFO:tensorflow:global step 126: loss = 0.4634 (1.604 sec/step)\n",
      "I1125 19:53:25.055371 140154295584576 learning.py:507] global step 126: loss = 0.4634 (1.604 sec/step)\n",
      "INFO:tensorflow:global step 127: loss = 0.6286 (1.551 sec/step)\n",
      "I1125 19:53:26.607633 140154295584576 learning.py:507] global step 127: loss = 0.6286 (1.551 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global step 128: loss = 0.3819 (1.601 sec/step)\n",
      "I1125 19:53:28.209797 140154295584576 learning.py:507] global step 128: loss = 0.3819 (1.601 sec/step)\n",
      "INFO:tensorflow:global step 129: loss = 0.1172 (1.821 sec/step)\n",
      "I1125 19:53:30.032531 140154295584576 learning.py:507] global step 129: loss = 0.1172 (1.821 sec/step)\n",
      "INFO:tensorflow:global step 130: loss = 1.0073 (1.523 sec/step)\n",
      "I1125 19:53:31.556737 140154295584576 learning.py:507] global step 130: loss = 1.0073 (1.523 sec/step)\n",
      "INFO:tensorflow:global step 131: loss = 0.1340 (1.636 sec/step)\n",
      "I1125 19:53:33.193937 140154295584576 learning.py:507] global step 131: loss = 0.1340 (1.636 sec/step)\n",
      "INFO:tensorflow:global step 132: loss = 1.0276 (1.372 sec/step)\n",
      "I1125 19:53:34.567382 140154295584576 learning.py:507] global step 132: loss = 1.0276 (1.372 sec/step)\n",
      "INFO:tensorflow:global step 133: loss = 1.1120 (1.411 sec/step)\n",
      "I1125 19:53:35.980001 140154295584576 learning.py:507] global step 133: loss = 1.1120 (1.411 sec/step)\n",
      "INFO:tensorflow:global step 134: loss = 1.8151 (1.065 sec/step)\n",
      "I1125 19:53:37.046267 140154295584576 learning.py:507] global step 134: loss = 1.8151 (1.065 sec/step)\n",
      "INFO:tensorflow:global step 135: loss = 1.4502 (1.506 sec/step)\n",
      "I1125 19:53:38.553500 140154295584576 learning.py:507] global step 135: loss = 1.4502 (1.506 sec/step)\n",
      "INFO:tensorflow:global step 136: loss = 0.9350 (1.389 sec/step)\n",
      "I1125 19:53:39.943734 140154295584576 learning.py:507] global step 136: loss = 0.9350 (1.389 sec/step)\n",
      "INFO:tensorflow:global step 137: loss = 1.4581 (1.574 sec/step)\n",
      "I1125 19:53:41.518630 140154295584576 learning.py:507] global step 137: loss = 1.4581 (1.574 sec/step)\n",
      "INFO:tensorflow:global step 138: loss = 0.3065 (1.551 sec/step)\n",
      "I1125 19:53:43.070602 140154295584576 learning.py:507] global step 138: loss = 0.3065 (1.551 sec/step)\n",
      "INFO:tensorflow:global step 139: loss = 1.7296 (1.494 sec/step)\n",
      "I1125 19:53:44.565443 140154295584576 learning.py:507] global step 139: loss = 1.7296 (1.494 sec/step)\n",
      "INFO:tensorflow:global step 140: loss = 1.8453 (1.591 sec/step)\n",
      "I1125 19:53:46.157310 140154295584576 learning.py:507] global step 140: loss = 1.8453 (1.591 sec/step)\n",
      "INFO:tensorflow:global step 141: loss = 0.6773 (1.369 sec/step)\n",
      "I1125 19:53:47.527738 140154295584576 learning.py:507] global step 141: loss = 0.6773 (1.369 sec/step)\n",
      "INFO:tensorflow:global step 142: loss = 0.8172 (1.539 sec/step)\n",
      "I1125 19:53:49.067696 140154295584576 learning.py:507] global step 142: loss = 0.8172 (1.539 sec/step)\n",
      "INFO:tensorflow:global step 143: loss = 1.2442 (1.035 sec/step)\n",
      "I1125 19:53:50.103714 140154295584576 learning.py:507] global step 143: loss = 1.2442 (1.035 sec/step)\n",
      "INFO:tensorflow:global step 144: loss = 0.5176 (1.548 sec/step)\n",
      "I1125 19:53:51.652449 140154295584576 learning.py:507] global step 144: loss = 0.5176 (1.548 sec/step)\n",
      "INFO:tensorflow:global step 145: loss = 1.1252 (2.332 sec/step)\n",
      "I1125 19:53:53.995356 140154295584576 learning.py:507] global step 145: loss = 1.1252 (2.332 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 145.\n",
      "I1125 19:53:54.385843 140149832783616 supervisor.py:1050] Recording summary at step 145.\n",
      "INFO:tensorflow:global step 146: loss = 1.9629 (1.677 sec/step)\n",
      "I1125 19:53:55.674493 140154295584576 learning.py:507] global step 146: loss = 1.9629 (1.677 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 0.658333\n",
      "I1125 19:53:56.650343 140149841176320 supervisor.py:1099] global_step/sec: 0.658333\n",
      "INFO:tensorflow:global step 147: loss = 2.2483 (1.137 sec/step)\n",
      "I1125 19:53:56.812638 140154295584576 learning.py:507] global step 147: loss = 2.2483 (1.137 sec/step)\n",
      "INFO:tensorflow:global step 148: loss = 1.3442 (1.672 sec/step)\n",
      "I1125 19:53:58.485187 140154295584576 learning.py:507] global step 148: loss = 1.3442 (1.672 sec/step)\n",
      "INFO:tensorflow:global step 149: loss = 0.3978 (1.504 sec/step)\n",
      "I1125 19:53:59.990551 140154295584576 learning.py:507] global step 149: loss = 0.3978 (1.504 sec/step)\n",
      "INFO:tensorflow:global step 150: loss = 0.1071 (1.543 sec/step)\n",
      "I1125 19:54:01.534910 140154295584576 learning.py:507] global step 150: loss = 0.1071 (1.543 sec/step)\n",
      "INFO:tensorflow:global step 151: loss = 1.8404 (1.598 sec/step)\n",
      "I1125 19:54:03.134414 140154295584576 learning.py:507] global step 151: loss = 1.8404 (1.598 sec/step)\n",
      "INFO:tensorflow:global step 152: loss = 1.4366 (1.405 sec/step)\n",
      "I1125 19:54:04.540093 140154295584576 learning.py:507] global step 152: loss = 1.4366 (1.405 sec/step)\n",
      "INFO:tensorflow:global step 153: loss = 1.3043 (1.946 sec/step)\n",
      "I1125 19:54:06.487428 140154295584576 learning.py:507] global step 153: loss = 1.3043 (1.946 sec/step)\n",
      "INFO:tensorflow:global step 154: loss = 0.2047 (1.216 sec/step)\n",
      "I1125 19:54:07.704926 140154295584576 learning.py:507] global step 154: loss = 0.2047 (1.216 sec/step)\n",
      "INFO:tensorflow:global step 155: loss = 0.3772 (1.293 sec/step)\n",
      "I1125 19:54:08.998648 140154295584576 learning.py:507] global step 155: loss = 0.3772 (1.293 sec/step)\n",
      "INFO:tensorflow:global step 156: loss = 0.5280 (1.514 sec/step)\n",
      "I1125 19:54:10.513227 140154295584576 learning.py:507] global step 156: loss = 0.5280 (1.514 sec/step)\n",
      "INFO:tensorflow:global step 157: loss = 1.1270 (1.647 sec/step)\n",
      "I1125 19:54:12.161322 140154295584576 learning.py:507] global step 157: loss = 1.1270 (1.647 sec/step)\n",
      "INFO:tensorflow:global step 158: loss = 1.4512 (1.813 sec/step)\n",
      "I1125 19:54:13.975342 140154295584576 learning.py:507] global step 158: loss = 1.4512 (1.813 sec/step)\n",
      "INFO:tensorflow:global step 159: loss = 1.3218 (2.154 sec/step)\n",
      "I1125 19:54:16.130174 140154295584576 learning.py:507] global step 159: loss = 1.3218 (2.154 sec/step)\n",
      "INFO:tensorflow:global step 160: loss = 0.7643 (1.417 sec/step)\n",
      "I1125 19:54:17.547767 140154295584576 learning.py:507] global step 160: loss = 0.7643 (1.417 sec/step)\n",
      "INFO:tensorflow:global step 161: loss = 1.7697 (1.397 sec/step)\n",
      "I1125 19:54:18.945608 140154295584576 learning.py:507] global step 161: loss = 1.7697 (1.397 sec/step)\n",
      "INFO:tensorflow:global step 162: loss = 1.9279 (1.289 sec/step)\n",
      "I1125 19:54:20.236198 140154295584576 learning.py:507] global step 162: loss = 1.9279 (1.289 sec/step)\n",
      "INFO:tensorflow:global step 163: loss = 0.8858 (1.045 sec/step)\n",
      "I1125 19:54:21.282026 140154295584576 learning.py:507] global step 163: loss = 0.8858 (1.045 sec/step)\n",
      "INFO:tensorflow:global step 164: loss = 0.8583 (1.132 sec/step)\n",
      "I1125 19:54:22.414558 140154295584576 learning.py:507] global step 164: loss = 0.8583 (1.132 sec/step)\n",
      "INFO:tensorflow:global step 165: loss = 0.4136 (1.146 sec/step)\n",
      "I1125 19:54:23.561739 140154295584576 learning.py:507] global step 165: loss = 0.4136 (1.146 sec/step)\n",
      "INFO:tensorflow:global step 166: loss = 0.7581 (1.338 sec/step)\n",
      "I1125 19:54:24.900603 140154295584576 learning.py:507] global step 166: loss = 0.7581 (1.338 sec/step)\n",
      "INFO:tensorflow:global step 167: loss = 1.3392 (1.439 sec/step)\n",
      "I1125 19:54:26.341090 140154295584576 learning.py:507] global step 167: loss = 1.3392 (1.439 sec/step)\n",
      "INFO:tensorflow:global step 168: loss = 0.9371 (1.394 sec/step)\n",
      "I1125 19:54:27.736181 140154295584576 learning.py:507] global step 168: loss = 0.9371 (1.394 sec/step)\n",
      "INFO:tensorflow:global step 169: loss = 3.0234 (1.522 sec/step)\n",
      "I1125 19:54:29.259576 140154295584576 learning.py:507] global step 169: loss = 3.0234 (1.522 sec/step)\n",
      "INFO:tensorflow:global step 170: loss = 1.3875 (1.566 sec/step)\n",
      "I1125 19:54:30.826474 140154295584576 learning.py:507] global step 170: loss = 1.3875 (1.566 sec/step)\n",
      "INFO:tensorflow:global step 171: loss = 1.2831 (1.481 sec/step)\n",
      "I1125 19:54:32.308781 140154295584576 learning.py:507] global step 171: loss = 1.2831 (1.481 sec/step)\n",
      "INFO:tensorflow:global step 172: loss = 1.5511 (1.082 sec/step)\n",
      "I1125 19:54:33.391703 140154295584576 learning.py:507] global step 172: loss = 1.5511 (1.082 sec/step)\n",
      "INFO:tensorflow:global step 173: loss = 2.1784 (1.523 sec/step)\n",
      "I1125 19:54:34.915690 140154295584576 learning.py:507] global step 173: loss = 2.1784 (1.523 sec/step)\n",
      "INFO:tensorflow:global step 174: loss = 1.8873 (1.143 sec/step)\n",
      "I1125 19:54:36.060037 140154295584576 learning.py:507] global step 174: loss = 1.8873 (1.143 sec/step)\n",
      "INFO:tensorflow:global step 175: loss = 1.2299 (1.655 sec/step)\n",
      "I1125 19:54:37.715754 140154295584576 learning.py:507] global step 175: loss = 1.2299 (1.655 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global step 176: loss = 0.2137 (1.689 sec/step)\n",
      "I1125 19:54:39.405676 140154295584576 learning.py:507] global step 176: loss = 0.2137 (1.689 sec/step)\n",
      "INFO:tensorflow:global step 177: loss = 1.5928 (2.185 sec/step)\n",
      "I1125 19:54:41.591954 140154295584576 learning.py:507] global step 177: loss = 1.5928 (2.185 sec/step)\n",
      "INFO:tensorflow:global step 178: loss = 1.8770 (1.394 sec/step)\n",
      "I1125 19:54:42.986616 140154295584576 learning.py:507] global step 178: loss = 1.8770 (1.394 sec/step)\n",
      "INFO:tensorflow:global step 179: loss = 0.6726 (1.463 sec/step)\n",
      "I1125 19:54:44.451011 140154295584576 learning.py:507] global step 179: loss = 0.6726 (1.463 sec/step)\n",
      "INFO:tensorflow:global step 180: loss = 0.3247 (1.440 sec/step)\n",
      "I1125 19:54:45.891794 140154295584576 learning.py:507] global step 180: loss = 0.3247 (1.440 sec/step)\n",
      "INFO:tensorflow:global step 181: loss = 1.7176 (1.095 sec/step)\n",
      "I1125 19:54:46.987662 140154295584576 learning.py:507] global step 181: loss = 1.7176 (1.095 sec/step)\n",
      "INFO:tensorflow:global step 182: loss = 2.4905 (1.599 sec/step)\n",
      "I1125 19:54:48.587883 140154295584576 learning.py:507] global step 182: loss = 2.4905 (1.599 sec/step)\n",
      "INFO:tensorflow:global step 183: loss = 1.7246 (1.410 sec/step)\n",
      "I1125 19:54:49.998933 140154295584576 learning.py:507] global step 183: loss = 1.7246 (1.410 sec/step)\n",
      "INFO:tensorflow:global step 184: loss = 0.5396 (2.123 sec/step)\n",
      "I1125 19:54:52.123374 140154295584576 learning.py:507] global step 184: loss = 0.5396 (2.123 sec/step)\n",
      "INFO:tensorflow:global step 185: loss = 0.4560 (1.340 sec/step)\n",
      "I1125 19:54:53.464247 140154295584576 learning.py:507] global step 185: loss = 0.4560 (1.340 sec/step)\n",
      "INFO:tensorflow:global step 186: loss = 0.2160 (1.649 sec/step)\n",
      "I1125 19:54:55.114817 140154295584576 learning.py:507] global step 186: loss = 0.2160 (1.649 sec/step)\n",
      "INFO:tensorflow:global step 187: loss = 1.9433 (1.101 sec/step)\n",
      "I1125 19:54:56.216544 140154295584576 learning.py:507] global step 187: loss = 1.9433 (1.101 sec/step)\n",
      "INFO:tensorflow:global step 188: loss = 0.4205 (1.180 sec/step)\n",
      "I1125 19:54:57.398175 140154295584576 learning.py:507] global step 188: loss = 0.4205 (1.180 sec/step)\n",
      "INFO:tensorflow:global step 189: loss = 1.2086 (1.450 sec/step)\n",
      "I1125 19:54:58.849811 140154295584576 learning.py:507] global step 189: loss = 1.2086 (1.450 sec/step)\n",
      "INFO:tensorflow:global step 190: loss = 1.4461 (1.706 sec/step)\n",
      "I1125 19:55:00.556964 140154295584576 learning.py:507] global step 190: loss = 1.4461 (1.706 sec/step)\n",
      "INFO:tensorflow:global step 191: loss = 1.0890 (2.784 sec/step)\n",
      "I1125 19:55:03.342830 140154295584576 learning.py:507] global step 191: loss = 1.0890 (2.784 sec/step)\n",
      "INFO:tensorflow:global step 192: loss = 1.2173 (1.434 sec/step)\n",
      "I1125 19:55:04.778448 140154295584576 learning.py:507] global step 192: loss = 1.2173 (1.434 sec/step)\n",
      "INFO:tensorflow:global step 193: loss = 0.4679 (1.542 sec/step)\n",
      "I1125 19:55:06.321500 140154295584576 learning.py:507] global step 193: loss = 0.4679 (1.542 sec/step)\n",
      "INFO:tensorflow:global step 194: loss = 1.1625 (1.518 sec/step)\n",
      "I1125 19:55:07.841112 140154295584576 learning.py:507] global step 194: loss = 1.1625 (1.518 sec/step)\n",
      "INFO:tensorflow:global step 195: loss = 2.4494 (1.625 sec/step)\n",
      "I1125 19:55:09.467235 140154295584576 learning.py:507] global step 195: loss = 2.4494 (1.625 sec/step)\n",
      "INFO:tensorflow:global step 196: loss = 1.6702 (1.575 sec/step)\n",
      "I1125 19:55:11.043526 140154295584576 learning.py:507] global step 196: loss = 1.6702 (1.575 sec/step)\n",
      "INFO:tensorflow:global step 197: loss = 2.1321 (1.052 sec/step)\n",
      "I1125 19:55:12.096248 140154295584576 learning.py:507] global step 197: loss = 2.1321 (1.052 sec/step)\n",
      "INFO:tensorflow:global step 198: loss = 0.9396 (1.501 sec/step)\n",
      "I1125 19:55:13.598304 140154295584576 learning.py:507] global step 198: loss = 0.9396 (1.501 sec/step)\n",
      "INFO:tensorflow:global step 199: loss = 1.9116 (1.490 sec/step)\n",
      "I1125 19:55:15.089477 140154295584576 learning.py:507] global step 199: loss = 1.9116 (1.490 sec/step)\n",
      "INFO:tensorflow:global step 200: loss = 1.2847 (1.521 sec/step)\n",
      "I1125 19:55:16.611796 140154295584576 learning.py:507] global step 200: loss = 1.2847 (1.521 sec/step)\n",
      "INFO:tensorflow:global step 201: loss = 1.2004 (1.514 sec/step)\n",
      "I1125 19:55:18.126959 140154295584576 learning.py:507] global step 201: loss = 1.2004 (1.514 sec/step)\n",
      "INFO:tensorflow:global step 202: loss = 1.9900 (1.594 sec/step)\n",
      "I1125 19:55:19.721996 140154295584576 learning.py:507] global step 202: loss = 1.9900 (1.594 sec/step)\n",
      "INFO:tensorflow:global step 203: loss = 1.7033 (1.461 sec/step)\n",
      "I1125 19:55:21.184007 140154295584576 learning.py:507] global step 203: loss = 1.7033 (1.461 sec/step)\n",
      "INFO:tensorflow:global step 204: loss = 1.8553 (1.535 sec/step)\n",
      "I1125 19:55:22.720441 140154295584576 learning.py:507] global step 204: loss = 1.8553 (1.535 sec/step)\n",
      "INFO:tensorflow:global step 205: loss = 1.5360 (1.694 sec/step)\n",
      "I1125 19:55:24.416582 140154295584576 learning.py:507] global step 205: loss = 1.5360 (1.694 sec/step)\n",
      "INFO:tensorflow:global step 206: loss = 1.3726 (2.405 sec/step)\n",
      "I1125 19:55:26.823837 140154295584576 learning.py:507] global step 206: loss = 1.3726 (2.405 sec/step)\n",
      "INFO:tensorflow:global step 207: loss = 1.9602 (1.400 sec/step)\n",
      "I1125 19:55:28.224775 140154295584576 learning.py:507] global step 207: loss = 1.9602 (1.400 sec/step)\n",
      "INFO:tensorflow:global step 208: loss = 1.0797 (1.064 sec/step)\n",
      "I1125 19:55:29.289388 140154295584576 learning.py:507] global step 208: loss = 1.0797 (1.064 sec/step)\n",
      "INFO:tensorflow:global step 209: loss = 1.4746 (1.455 sec/step)\n",
      "I1125 19:55:30.745812 140154295584576 learning.py:507] global step 209: loss = 1.4746 (1.455 sec/step)\n",
      "INFO:tensorflow:global step 210: loss = 2.1927 (1.511 sec/step)\n",
      "I1125 19:55:32.257721 140154295584576 learning.py:507] global step 210: loss = 2.1927 (1.511 sec/step)\n",
      "INFO:tensorflow:global step 211: loss = 0.7967 (1.366 sec/step)\n",
      "I1125 19:55:33.625284 140154295584576 learning.py:507] global step 211: loss = 0.7967 (1.366 sec/step)\n",
      "INFO:tensorflow:global step 212: loss = 1.5002 (1.189 sec/step)\n",
      "I1125 19:55:34.815676 140154295584576 learning.py:507] global step 212: loss = 1.5002 (1.189 sec/step)\n",
      "INFO:tensorflow:global step 213: loss = 1.6984 (1.399 sec/step)\n",
      "I1125 19:55:36.215341 140154295584576 learning.py:507] global step 213: loss = 1.6984 (1.399 sec/step)\n",
      "INFO:tensorflow:global step 214: loss = 1.2100 (1.381 sec/step)\n",
      "I1125 19:55:37.597854 140154295584576 learning.py:507] global step 214: loss = 1.2100 (1.381 sec/step)\n",
      "INFO:tensorflow:global step 215: loss = 0.4160 (1.233 sec/step)\n",
      "I1125 19:55:38.832077 140154295584576 learning.py:507] global step 215: loss = 0.4160 (1.233 sec/step)\n",
      "INFO:tensorflow:global step 216: loss = 1.0667 (1.680 sec/step)\n",
      "I1125 19:55:40.513608 140154295584576 learning.py:507] global step 216: loss = 1.0667 (1.680 sec/step)\n",
      "INFO:tensorflow:global step 217: loss = 2.0977 (1.451 sec/step)\n",
      "I1125 19:55:41.966405 140154295584576 learning.py:507] global step 217: loss = 2.0977 (1.451 sec/step)\n",
      "INFO:tensorflow:global step 218: loss = 0.8793 (1.136 sec/step)\n",
      "I1125 19:55:43.103996 140154295584576 learning.py:507] global step 218: loss = 0.8793 (1.136 sec/step)\n",
      "INFO:tensorflow:global step 219: loss = 0.8909 (1.574 sec/step)\n",
      "I1125 19:55:44.678953 140154295584576 learning.py:507] global step 219: loss = 0.8909 (1.574 sec/step)\n",
      "INFO:tensorflow:global step 220: loss = 1.6405 (1.541 sec/step)\n",
      "I1125 19:55:46.220893 140154295584576 learning.py:507] global step 220: loss = 1.6405 (1.541 sec/step)\n",
      "INFO:tensorflow:global step 221: loss = 0.4500 (2.500 sec/step)\n",
      "I1125 19:55:48.723498 140154295584576 learning.py:507] global step 221: loss = 0.4500 (2.500 sec/step)\n",
      "INFO:tensorflow:global step 222: loss = 0.9075 (1.604 sec/step)\n",
      "I1125 19:55:50.328973 140154295584576 learning.py:507] global step 222: loss = 0.9075 (1.604 sec/step)\n",
      "INFO:tensorflow:global step 223: loss = 1.5899 (1.293 sec/step)\n",
      "I1125 19:55:51.623224 140154295584576 learning.py:507] global step 223: loss = 1.5899 (1.293 sec/step)\n",
      "INFO:tensorflow:global step 224: loss = 1.5652 (1.482 sec/step)\n",
      "I1125 19:55:53.106728 140154295584576 learning.py:507] global step 224: loss = 1.5652 (1.482 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 224.\n",
      "I1125 19:55:54.295933 140149832783616 supervisor.py:1050] Recording summary at step 224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global step 225: loss = 0.7729 (1.697 sec/step)\n",
      "I1125 19:55:54.804820 140154295584576 learning.py:507] global step 225: loss = 0.7729 (1.697 sec/step)\n",
      "INFO:tensorflow:global step 226: loss = 0.9370 (1.391 sec/step)\n",
      "I1125 19:55:56.197068 140154295584576 learning.py:507] global step 226: loss = 0.9370 (1.391 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 0.666666\n",
      "I1125 19:55:56.650396 140149841176320 supervisor.py:1099] global_step/sec: 0.666666\n",
      "INFO:tensorflow:global step 227: loss = 1.1863 (1.406 sec/step)\n",
      "I1125 19:55:57.604444 140154295584576 learning.py:507] global step 227: loss = 1.1863 (1.406 sec/step)\n",
      "INFO:tensorflow:global step 228: loss = 0.3627 (1.224 sec/step)\n",
      "I1125 19:55:58.829142 140154295584576 learning.py:507] global step 228: loss = 0.3627 (1.224 sec/step)\n",
      "INFO:tensorflow:global step 229: loss = 1.5748 (1.418 sec/step)\n",
      "I1125 19:56:00.248546 140154295584576 learning.py:507] global step 229: loss = 1.5748 (1.418 sec/step)\n",
      "INFO:tensorflow:global step 230: loss = 1.2439 (1.468 sec/step)\n",
      "I1125 19:56:01.717311 140154295584576 learning.py:507] global step 230: loss = 1.2439 (1.468 sec/step)\n",
      "INFO:tensorflow:global step 231: loss = 0.9355 (1.541 sec/step)\n",
      "I1125 19:56:03.259476 140154295584576 learning.py:507] global step 231: loss = 0.9355 (1.541 sec/step)\n",
      "INFO:tensorflow:global step 232: loss = 0.9187 (1.519 sec/step)\n",
      "I1125 19:56:04.779144 140154295584576 learning.py:507] global step 232: loss = 0.9187 (1.519 sec/step)\n",
      "INFO:tensorflow:global step 233: loss = 1.1348 (1.416 sec/step)\n",
      "I1125 19:56:06.196602 140154295584576 learning.py:507] global step 233: loss = 1.1348 (1.416 sec/step)\n",
      "INFO:tensorflow:global step 234: loss = 0.9040 (1.331 sec/step)\n",
      "I1125 19:56:07.529021 140154295584576 learning.py:507] global step 234: loss = 0.9040 (1.331 sec/step)\n",
      "INFO:tensorflow:global step 235: loss = 2.3625 (2.446 sec/step)\n",
      "I1125 19:56:09.976484 140154295584576 learning.py:507] global step 235: loss = 2.3625 (2.446 sec/step)\n",
      "INFO:tensorflow:global step 236: loss = 0.4769 (1.456 sec/step)\n",
      "I1125 19:56:11.433939 140154295584576 learning.py:507] global step 236: loss = 0.4769 (1.456 sec/step)\n",
      "INFO:tensorflow:global step 237: loss = 2.0947 (1.539 sec/step)\n",
      "I1125 19:56:12.974416 140154295584576 learning.py:507] global step 237: loss = 2.0947 (1.539 sec/step)\n",
      "INFO:tensorflow:global step 238: loss = 0.4919 (1.246 sec/step)\n",
      "I1125 19:56:14.221835 140154295584576 learning.py:507] global step 238: loss = 0.4919 (1.246 sec/step)\n",
      "INFO:tensorflow:global step 239: loss = 2.0405 (1.547 sec/step)\n",
      "I1125 19:56:15.770207 140154295584576 learning.py:507] global step 239: loss = 2.0405 (1.547 sec/step)\n",
      "INFO:tensorflow:global step 240: loss = 0.8119 (1.305 sec/step)\n",
      "I1125 19:56:17.076257 140154295584576 learning.py:507] global step 240: loss = 0.8119 (1.305 sec/step)\n",
      "INFO:tensorflow:global step 241: loss = 1.4546 (1.489 sec/step)\n",
      "I1125 19:56:18.566830 140154295584576 learning.py:507] global step 241: loss = 1.4546 (1.489 sec/step)\n",
      "INFO:tensorflow:global step 242: loss = 0.7566 (1.381 sec/step)\n",
      "I1125 19:56:19.948992 140154295584576 learning.py:507] global step 242: loss = 0.7566 (1.381 sec/step)\n",
      "INFO:tensorflow:global step 244: loss = 0.1570 (1.382 sec/step)\n",
      "I1125 19:56:22.825446 140154295584576 learning.py:507] global step 244: loss = 0.1570 (1.382 sec/step)\n",
      "INFO:tensorflow:global step 245: loss = 0.7445 (1.473 sec/step)\n",
      "I1125 19:56:24.299987 140154295584576 learning.py:507] global step 245: loss = 0.7445 (1.473 sec/step)\n",
      "INFO:tensorflow:global step 246: loss = 0.6091 (1.087 sec/step)\n",
      "I1125 19:56:25.388705 140154295584576 learning.py:507] global step 246: loss = 0.6091 (1.087 sec/step)\n",
      "INFO:tensorflow:global step 247: loss = 0.6339 (1.058 sec/step)\n",
      "I1125 19:56:26.447864 140154295584576 learning.py:507] global step 247: loss = 0.6339 (1.058 sec/step)\n",
      "INFO:tensorflow:global step 248: loss = 0.6210 (1.431 sec/step)\n",
      "I1125 19:56:27.879705 140154295584576 learning.py:507] global step 248: loss = 0.6210 (1.431 sec/step)\n",
      "INFO:tensorflow:global step 249: loss = 0.6350 (1.516 sec/step)\n",
      "I1125 19:56:29.396685 140154295584576 learning.py:507] global step 249: loss = 0.6350 (1.516 sec/step)\n",
      "INFO:tensorflow:global step 250: loss = 0.3599 (1.405 sec/step)\n",
      "I1125 19:56:30.802646 140154295584576 learning.py:507] global step 250: loss = 0.3599 (1.405 sec/step)\n",
      "INFO:tensorflow:global step 251: loss = 0.1699 (1.162 sec/step)\n",
      "I1125 19:56:31.966375 140154295584576 learning.py:507] global step 251: loss = 0.1699 (1.162 sec/step)\n",
      "INFO:tensorflow:global step 252: loss = 1.6018 (1.153 sec/step)\n",
      "I1125 19:56:33.120265 140154295584576 learning.py:507] global step 252: loss = 1.6018 (1.153 sec/step)\n",
      "INFO:tensorflow:global step 253: loss = 0.6186 (2.289 sec/step)\n",
      "I1125 19:56:35.410920 140154295584576 learning.py:507] global step 253: loss = 0.6186 (2.289 sec/step)\n",
      "INFO:tensorflow:global step 254: loss = 1.1490 (1.575 sec/step)\n",
      "I1125 19:56:36.987021 140154295584576 learning.py:507] global step 254: loss = 1.1490 (1.575 sec/step)\n",
      "INFO:tensorflow:global step 255: loss = 0.9203 (1.555 sec/step)\n",
      "I1125 19:56:38.543371 140154295584576 learning.py:507] global step 255: loss = 0.9203 (1.555 sec/step)\n",
      "INFO:tensorflow:global step 256: loss = 1.8816 (1.522 sec/step)\n",
      "I1125 19:56:40.066468 140154295584576 learning.py:507] global step 256: loss = 1.8816 (1.522 sec/step)\n",
      "INFO:tensorflow:global step 257: loss = 1.1256 (1.428 sec/step)\n",
      "I1125 19:56:41.495565 140154295584576 learning.py:507] global step 257: loss = 1.1256 (1.428 sec/step)\n",
      "INFO:tensorflow:global step 258: loss = 0.1398 (1.283 sec/step)\n",
      "I1125 19:56:42.779390 140154295584576 learning.py:507] global step 258: loss = 0.1398 (1.283 sec/step)\n",
      "INFO:tensorflow:global step 259: loss = 1.5402 (1.561 sec/step)\n",
      "I1125 19:56:44.341074 140154295584576 learning.py:507] global step 259: loss = 1.5402 (1.561 sec/step)\n",
      "INFO:tensorflow:global step 260: loss = 0.7820 (1.464 sec/step)\n",
      "I1125 19:56:45.806577 140154295584576 learning.py:507] global step 260: loss = 0.7820 (1.464 sec/step)\n",
      "INFO:tensorflow:global step 261: loss = 0.2699 (1.434 sec/step)\n",
      "I1125 19:56:47.241461 140154295584576 learning.py:507] global step 261: loss = 0.2699 (1.434 sec/step)\n",
      "INFO:tensorflow:global step 262: loss = 0.5578 (1.573 sec/step)\n",
      "I1125 19:56:48.815386 140154295584576 learning.py:507] global step 262: loss = 0.5578 (1.573 sec/step)\n",
      "INFO:tensorflow:global step 263: loss = 2.1127 (1.680 sec/step)\n",
      "I1125 19:56:50.496046 140154295584576 learning.py:507] global step 263: loss = 2.1127 (1.680 sec/step)\n",
      "INFO:tensorflow:global step 264: loss = 1.2304 (1.530 sec/step)\n",
      "I1125 19:56:52.026966 140154295584576 learning.py:507] global step 264: loss = 1.2304 (1.530 sec/step)\n",
      "INFO:tensorflow:global step 265: loss = 2.0868 (1.322 sec/step)\n",
      "I1125 19:56:53.350306 140154295584576 learning.py:507] global step 265: loss = 2.0868 (1.322 sec/step)\n",
      "INFO:tensorflow:global step 266: loss = 1.7128 (1.439 sec/step)\n",
      "I1125 19:56:54.790698 140154295584576 learning.py:507] global step 266: loss = 1.7128 (1.439 sec/step)\n",
      "INFO:tensorflow:global step 267: loss = 1.1869 (1.760 sec/step)\n",
      "I1125 19:56:56.552510 140154295584576 learning.py:507] global step 267: loss = 1.1869 (1.760 sec/step)\n",
      "INFO:tensorflow:global step 268: loss = 1.3233 (1.863 sec/step)\n",
      "I1125 19:56:58.416991 140154295584576 learning.py:507] global step 268: loss = 1.3233 (1.863 sec/step)\n",
      "INFO:tensorflow:global step 269: loss = 0.8568 (1.342 sec/step)\n",
      "I1125 19:56:59.760001 140154295584576 learning.py:507] global step 269: loss = 0.8568 (1.342 sec/step)\n",
      "INFO:tensorflow:global step 270: loss = 0.4944 (1.480 sec/step)\n",
      "I1125 19:57:01.241381 140154295584576 learning.py:507] global step 270: loss = 0.4944 (1.480 sec/step)\n",
      "INFO:tensorflow:global step 271: loss = 1.2111 (1.173 sec/step)\n",
      "I1125 19:57:02.415028 140154295584576 learning.py:507] global step 271: loss = 1.2111 (1.173 sec/step)\n",
      "INFO:tensorflow:global step 272: loss = 1.7108 (1.672 sec/step)\n",
      "I1125 19:57:04.087633 140154295584576 learning.py:507] global step 272: loss = 1.7108 (1.672 sec/step)\n",
      "INFO:tensorflow:global step 273: loss = 2.1102 (1.430 sec/step)\n",
      "I1125 19:57:05.518517 140154295584576 learning.py:507] global step 273: loss = 2.1102 (1.430 sec/step)\n",
      "INFO:tensorflow:global step 274: loss = 2.3275 (1.571 sec/step)\n",
      "I1125 19:57:07.090333 140154295584576 learning.py:507] global step 274: loss = 2.3275 (1.571 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global step 275: loss = 1.6249 (1.553 sec/step)\n",
      "I1125 19:57:08.644639 140154295584576 learning.py:507] global step 275: loss = 1.6249 (1.553 sec/step)\n",
      "INFO:tensorflow:global step 276: loss = 0.8350 (1.400 sec/step)\n",
      "I1125 19:57:10.046029 140154295584576 learning.py:507] global step 276: loss = 0.8350 (1.400 sec/step)\n",
      "INFO:tensorflow:global step 277: loss = 2.2281 (1.481 sec/step)\n",
      "I1125 19:57:11.528057 140154295584576 learning.py:507] global step 277: loss = 2.2281 (1.481 sec/step)\n",
      "INFO:tensorflow:global step 278: loss = 2.0530 (1.510 sec/step)\n",
      "I1125 19:57:13.038709 140154295584576 learning.py:507] global step 278: loss = 2.0530 (1.510 sec/step)\n",
      "INFO:tensorflow:global step 279: loss = 1.8634 (1.727 sec/step)\n",
      "I1125 19:57:14.766848 140154295584576 learning.py:507] global step 279: loss = 1.8634 (1.727 sec/step)\n",
      "INFO:tensorflow:global step 280: loss = 0.7783 (1.195 sec/step)\n",
      "I1125 19:57:15.963360 140154295584576 learning.py:507] global step 280: loss = 0.7783 (1.195 sec/step)\n",
      "INFO:tensorflow:global step 281: loss = 0.5824 (2.423 sec/step)\n",
      "I1125 19:57:18.388374 140154295584576 learning.py:507] global step 281: loss = 0.5824 (2.423 sec/step)\n",
      "INFO:tensorflow:global step 282: loss = 1.9923 (1.466 sec/step)\n",
      "I1125 19:57:19.855978 140154295584576 learning.py:507] global step 282: loss = 1.9923 (1.466 sec/step)\n",
      "INFO:tensorflow:global step 283: loss = 2.1957 (1.401 sec/step)\n",
      "I1125 19:57:21.258219 140154295584576 learning.py:507] global step 283: loss = 2.1957 (1.401 sec/step)\n",
      "INFO:tensorflow:global step 284: loss = 0.7674 (1.480 sec/step)\n",
      "I1125 19:57:22.739541 140154295584576 learning.py:507] global step 284: loss = 0.7674 (1.480 sec/step)\n",
      "INFO:tensorflow:global step 285: loss = 0.3348 (1.553 sec/step)\n",
      "I1125 19:57:24.293350 140154295584576 learning.py:507] global step 285: loss = 0.3348 (1.553 sec/step)\n",
      "INFO:tensorflow:global step 286: loss = 0.7069 (1.552 sec/step)\n",
      "I1125 19:57:25.846681 140154295584576 learning.py:507] global step 286: loss = 0.7069 (1.552 sec/step)\n",
      "INFO:tensorflow:global step 287: loss = 0.5052 (1.506 sec/step)\n",
      "I1125 19:57:27.353872 140154295584576 learning.py:507] global step 287: loss = 0.5052 (1.506 sec/step)\n",
      "INFO:tensorflow:global step 288: loss = 0.5441 (1.281 sec/step)\n",
      "I1125 19:57:28.635856 140154295584576 learning.py:507] global step 288: loss = 0.5441 (1.281 sec/step)\n",
      "INFO:tensorflow:global step 289: loss = 1.9433 (1.472 sec/step)\n",
      "I1125 19:57:30.109289 140154295584576 learning.py:507] global step 289: loss = 1.9433 (1.472 sec/step)\n",
      "INFO:tensorflow:global step 290: loss = 1.7371 (1.425 sec/step)\n",
      "I1125 19:57:31.535226 140154295584576 learning.py:507] global step 290: loss = 1.7371 (1.425 sec/step)\n",
      "INFO:tensorflow:global step 291: loss = 1.2697 (1.440 sec/step)\n",
      "I1125 19:57:32.976629 140154295584576 learning.py:507] global step 291: loss = 1.2697 (1.440 sec/step)\n",
      "INFO:tensorflow:global step 292: loss = 1.8334 (1.399 sec/step)\n",
      "I1125 19:57:34.377031 140154295584576 learning.py:507] global step 292: loss = 1.8334 (1.399 sec/step)\n",
      "INFO:tensorflow:global step 293: loss = 0.3959 (1.741 sec/step)\n",
      "I1125 19:57:36.119673 140154295584576 learning.py:507] global step 293: loss = 0.3959 (1.741 sec/step)\n",
      "INFO:tensorflow:global step 294: loss = 0.5178 (1.512 sec/step)\n",
      "I1125 19:57:37.633001 140154295584576 learning.py:507] global step 294: loss = 0.5178 (1.512 sec/step)\n",
      "INFO:tensorflow:global step 295: loss = 1.0284 (1.539 sec/step)\n",
      "I1125 19:57:39.173027 140154295584576 learning.py:507] global step 295: loss = 1.0284 (1.539 sec/step)\n",
      "INFO:tensorflow:global step 296: loss = 0.9869 (1.491 sec/step)\n",
      "I1125 19:57:40.665766 140154295584576 learning.py:507] global step 296: loss = 0.9869 (1.491 sec/step)\n",
      "INFO:tensorflow:global step 297: loss = 1.4907 (2.413 sec/step)\n",
      "I1125 19:57:43.080129 140154295584576 learning.py:507] global step 297: loss = 1.4907 (2.413 sec/step)\n",
      "INFO:tensorflow:global step 298: loss = 0.5036 (1.180 sec/step)\n",
      "I1125 19:57:44.260945 140154295584576 learning.py:507] global step 298: loss = 0.5036 (1.180 sec/step)\n",
      "INFO:tensorflow:global step 299: loss = 1.6530 (1.527 sec/step)\n",
      "I1125 19:57:45.788885 140154295584576 learning.py:507] global step 299: loss = 1.6530 (1.527 sec/step)\n",
      "INFO:tensorflow:global step 300: loss = 0.9924 (1.622 sec/step)\n",
      "I1125 19:57:47.411898 140154295584576 learning.py:507] global step 300: loss = 0.9924 (1.622 sec/step)\n",
      "INFO:tensorflow:global step 301: loss = 0.3997 (1.574 sec/step)\n",
      "I1125 19:57:48.986562 140154295584576 learning.py:507] global step 301: loss = 0.3997 (1.574 sec/step)\n",
      "INFO:tensorflow:global step 302: loss = 1.2129 (1.565 sec/step)\n",
      "I1125 19:57:50.552651 140154295584576 learning.py:507] global step 302: loss = 1.2129 (1.565 sec/step)\n",
      "INFO:tensorflow:global step 303: loss = 0.7721 (1.561 sec/step)\n",
      "I1125 19:57:52.114904 140154295584576 learning.py:507] global step 303: loss = 0.7721 (1.561 sec/step)\n",
      "INFO:tensorflow:global step 304: loss = 1.4769 (1.593 sec/step)\n",
      "I1125 19:57:53.708957 140154295584576 learning.py:507] global step 304: loss = 1.4769 (1.593 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 304.\n",
      "I1125 19:57:54.380181 140149832783616 supervisor.py:1050] Recording summary at step 304.\n",
      "INFO:tensorflow:global step 305: loss = 0.4340 (1.681 sec/step)\n",
      "I1125 19:57:55.390633 140154295584576 learning.py:507] global step 305: loss = 0.4340 (1.681 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 0.658334\n",
      "I1125 19:57:56.650313 140149841176320 supervisor.py:1099] global_step/sec: 0.658334\n",
      "INFO:tensorflow:global step 306: loss = 0.9795 (1.472 sec/step)\n",
      "I1125 19:57:56.864022 140154295584576 learning.py:507] global step 306: loss = 0.9795 (1.472 sec/step)\n",
      "INFO:tensorflow:global step 307: loss = 0.3458 (1.579 sec/step)\n",
      "I1125 19:57:58.444155 140154295584576 learning.py:507] global step 307: loss = 0.3458 (1.579 sec/step)\n",
      "INFO:tensorflow:global step 308: loss = 0.5825 (1.624 sec/step)\n",
      "I1125 19:58:00.069383 140154295584576 learning.py:507] global step 308: loss = 0.5825 (1.624 sec/step)\n",
      "INFO:tensorflow:global step 309: loss = 0.1701 (1.582 sec/step)\n",
      "I1125 19:58:01.652163 140154295584576 learning.py:507] global step 309: loss = 0.1701 (1.582 sec/step)\n",
      "INFO:tensorflow:global step 310: loss = 1.0948 (2.094 sec/step)\n",
      "I1125 19:58:03.748562 140154295584576 learning.py:507] global step 310: loss = 1.0948 (2.094 sec/step)\n",
      "INFO:tensorflow:global step 311: loss = 0.6976 (2.043 sec/step)\n",
      "I1125 19:58:05.792641 140154295584576 learning.py:507] global step 311: loss = 0.6976 (2.043 sec/step)\n",
      "INFO:tensorflow:global step 312: loss = 1.2086 (1.380 sec/step)\n",
      "I1125 19:58:07.173536 140154295584576 learning.py:507] global step 312: loss = 1.2086 (1.380 sec/step)\n",
      "INFO:tensorflow:global step 313: loss = 0.5095 (1.718 sec/step)\n",
      "I1125 19:58:08.892535 140154295584576 learning.py:507] global step 313: loss = 0.5095 (1.718 sec/step)\n",
      "INFO:tensorflow:global step 314: loss = 1.9341 (1.546 sec/step)\n",
      "I1125 19:58:10.439229 140154295584576 learning.py:507] global step 314: loss = 1.9341 (1.546 sec/step)\n",
      "INFO:tensorflow:global step 315: loss = 0.9898 (1.587 sec/step)\n",
      "I1125 19:58:12.027109 140154295584576 learning.py:507] global step 315: loss = 0.9898 (1.587 sec/step)\n",
      "INFO:tensorflow:global step 316: loss = 0.8493 (1.570 sec/step)\n",
      "I1125 19:58:13.598213 140154295584576 learning.py:507] global step 316: loss = 0.8493 (1.570 sec/step)\n",
      "INFO:tensorflow:global step 317: loss = 1.3184 (1.201 sec/step)\n",
      "I1125 19:58:14.800078 140154295584576 learning.py:507] global step 317: loss = 1.3184 (1.201 sec/step)\n",
      "INFO:tensorflow:global step 318: loss = 0.6632 (1.262 sec/step)\n",
      "I1125 19:58:16.063515 140154295584576 learning.py:507] global step 318: loss = 0.6632 (1.262 sec/step)\n",
      "INFO:tensorflow:global step 319: loss = 0.5760 (1.680 sec/step)\n",
      "I1125 19:58:17.744851 140154295584576 learning.py:507] global step 319: loss = 0.5760 (1.680 sec/step)\n",
      "INFO:tensorflow:global step 320: loss = 1.8575 (1.446 sec/step)\n",
      "I1125 19:58:19.192306 140154295584576 learning.py:507] global step 320: loss = 1.8575 (1.446 sec/step)\n",
      "INFO:tensorflow:global step 321: loss = 0.6466 (1.555 sec/step)\n",
      "I1125 19:58:20.748995 140154295584576 learning.py:507] global step 321: loss = 0.6466 (1.555 sec/step)\n",
      "INFO:tensorflow:global step 322: loss = 0.7004 (1.591 sec/step)\n",
      "I1125 19:58:22.341479 140154295584576 learning.py:507] global step 322: loss = 0.7004 (1.591 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global step 323: loss = 1.1299 (1.459 sec/step)\n",
      "I1125 19:58:23.802090 140154295584576 learning.py:507] global step 323: loss = 1.1299 (1.459 sec/step)\n",
      "INFO:tensorflow:global step 324: loss = 1.6115 (1.557 sec/step)\n",
      "I1125 19:58:25.360671 140154295584576 learning.py:507] global step 324: loss = 1.6115 (1.557 sec/step)\n",
      "INFO:tensorflow:global step 325: loss = 1.0858 (1.155 sec/step)\n",
      "I1125 19:58:26.517200 140154295584576 learning.py:507] global step 325: loss = 1.0858 (1.155 sec/step)\n",
      "INFO:tensorflow:global step 326: loss = 2.1047 (1.623 sec/step)\n",
      "I1125 19:58:28.141596 140154295584576 learning.py:507] global step 326: loss = 2.1047 (1.623 sec/step)\n",
      "INFO:tensorflow:global step 327: loss = 0.4011 (1.147 sec/step)\n",
      "I1125 19:58:29.289452 140154295584576 learning.py:507] global step 327: loss = 0.4011 (1.147 sec/step)\n",
      "INFO:tensorflow:global step 328: loss = 1.3015 (1.834 sec/step)\n",
      "I1125 19:58:31.124675 140154295584576 learning.py:507] global step 328: loss = 1.3015 (1.834 sec/step)\n",
      "INFO:tensorflow:global step 329: loss = 1.5655 (2.531 sec/step)\n",
      "I1125 19:58:33.656994 140154295584576 learning.py:507] global step 329: loss = 1.5655 (2.531 sec/step)\n",
      "INFO:tensorflow:global step 330: loss = 0.1353 (1.344 sec/step)\n",
      "I1125 19:58:35.002327 140154295584576 learning.py:507] global step 330: loss = 0.1353 (1.344 sec/step)\n",
      "INFO:tensorflow:global step 331: loss = 1.3842 (1.454 sec/step)\n",
      "I1125 19:58:36.456899 140154295584576 learning.py:507] global step 331: loss = 1.3842 (1.454 sec/step)\n",
      "INFO:tensorflow:global step 332: loss = 0.4753 (1.162 sec/step)\n",
      "I1125 19:58:37.620371 140154295584576 learning.py:507] global step 332: loss = 0.4753 (1.162 sec/step)\n",
      "INFO:tensorflow:global step 333: loss = 1.6897 (1.568 sec/step)\n",
      "I1125 19:58:39.189754 140154295584576 learning.py:507] global step 333: loss = 1.6897 (1.568 sec/step)\n",
      "INFO:tensorflow:global step 334: loss = 0.9455 (1.585 sec/step)\n",
      "I1125 19:58:40.775482 140154295584576 learning.py:507] global step 334: loss = 0.9455 (1.585 sec/step)\n",
      "INFO:tensorflow:global step 335: loss = 0.8966 (1.461 sec/step)\n",
      "I1125 19:58:42.237927 140154295584576 learning.py:507] global step 335: loss = 0.8966 (1.461 sec/step)\n",
      "INFO:tensorflow:global step 336: loss = 1.5319 (1.612 sec/step)\n",
      "I1125 19:58:43.851100 140154295584576 learning.py:507] global step 336: loss = 1.5319 (1.612 sec/step)\n",
      "INFO:tensorflow:global step 337: loss = 0.9043 (1.584 sec/step)\n",
      "I1125 19:58:45.436595 140154295584576 learning.py:507] global step 337: loss = 0.9043 (1.584 sec/step)\n",
      "INFO:tensorflow:global step 338: loss = 2.6498 (1.435 sec/step)\n",
      "I1125 19:58:46.872698 140154295584576 learning.py:507] global step 338: loss = 2.6498 (1.435 sec/step)\n",
      "INFO:tensorflow:global step 339: loss = 1.4542 (1.626 sec/step)\n",
      "I1125 19:58:48.500179 140154295584576 learning.py:507] global step 339: loss = 1.4542 (1.626 sec/step)\n",
      "INFO:tensorflow:global step 340: loss = 0.9083 (1.636 sec/step)\n",
      "I1125 19:58:50.137551 140154295584576 learning.py:507] global step 340: loss = 0.9083 (1.636 sec/step)\n",
      "INFO:tensorflow:global step 341: loss = 0.6262 (1.526 sec/step)\n",
      "I1125 19:58:51.665853 140154295584576 learning.py:507] global step 341: loss = 0.6262 (1.526 sec/step)\n",
      "INFO:tensorflow:global step 342: loss = 1.7283 (1.800 sec/step)\n",
      "I1125 19:58:53.468549 140154295584576 learning.py:507] global step 342: loss = 1.7283 (1.800 sec/step)\n",
      "INFO:tensorflow:global step 343: loss = 0.8466 (2.292 sec/step)\n",
      "I1125 19:58:55.762652 140154295584576 learning.py:507] global step 343: loss = 0.8466 (2.292 sec/step)\n",
      "INFO:tensorflow:global step 344: loss = 0.3829 (1.208 sec/step)\n",
      "I1125 19:58:56.972205 140154295584576 learning.py:507] global step 344: loss = 0.3829 (1.208 sec/step)\n",
      "INFO:tensorflow:global step 345: loss = 1.8182 (1.648 sec/step)\n",
      "I1125 19:58:58.621505 140154295584576 learning.py:507] global step 345: loss = 1.8182 (1.648 sec/step)\n",
      "INFO:tensorflow:global step 346: loss = 1.4712 (1.634 sec/step)\n",
      "I1125 19:59:00.256250 140154295584576 learning.py:507] global step 346: loss = 1.4712 (1.634 sec/step)\n",
      "INFO:tensorflow:global step 347: loss = 0.6879 (1.412 sec/step)\n",
      "I1125 19:59:01.669367 140154295584576 learning.py:507] global step 347: loss = 0.6879 (1.412 sec/step)\n",
      "INFO:tensorflow:global step 348: loss = 2.0841 (1.635 sec/step)\n",
      "I1125 19:59:03.305103 140154295584576 learning.py:507] global step 348: loss = 2.0841 (1.635 sec/step)\n",
      "INFO:tensorflow:global step 349: loss = 1.6666 (1.562 sec/step)\n",
      "I1125 19:59:04.867664 140154295584576 learning.py:507] global step 349: loss = 1.6666 (1.562 sec/step)\n",
      "INFO:tensorflow:global step 350: loss = 0.5872 (1.568 sec/step)\n",
      "I1125 19:59:06.436695 140154295584576 learning.py:507] global step 350: loss = 0.5872 (1.568 sec/step)\n",
      "INFO:tensorflow:global step 351: loss = 0.3169 (1.523 sec/step)\n",
      "I1125 19:59:07.960545 140154295584576 learning.py:507] global step 351: loss = 0.3169 (1.523 sec/step)\n",
      "INFO:tensorflow:global step 352: loss = 0.5698 (1.342 sec/step)\n",
      "I1125 19:59:09.303461 140154295584576 learning.py:507] global step 352: loss = 0.5698 (1.342 sec/step)\n",
      "INFO:tensorflow:global step 353: loss = 0.4828 (1.389 sec/step)\n",
      "I1125 19:59:10.693682 140154295584576 learning.py:507] global step 353: loss = 0.4828 (1.389 sec/step)\n",
      "INFO:tensorflow:global step 354: loss = 1.4260 (1.609 sec/step)\n",
      "I1125 19:59:12.304045 140154295584576 learning.py:507] global step 354: loss = 1.4260 (1.609 sec/step)\n",
      "INFO:tensorflow:global step 355: loss = 2.1133 (2.084 sec/step)\n",
      "I1125 19:59:14.389418 140154295584576 learning.py:507] global step 355: loss = 2.1133 (2.084 sec/step)\n",
      "INFO:tensorflow:global step 356: loss = 0.8820 (1.786 sec/step)\n",
      "I1125 19:59:16.176448 140154295584576 learning.py:507] global step 356: loss = 0.8820 (1.786 sec/step)\n",
      "INFO:tensorflow:global step 357: loss = 1.2689 (1.600 sec/step)\n",
      "I1125 19:59:17.777730 140154295584576 learning.py:507] global step 357: loss = 1.2689 (1.600 sec/step)\n",
      "INFO:tensorflow:global step 358: loss = 1.4831 (1.537 sec/step)\n",
      "I1125 19:59:19.316051 140154295584576 learning.py:507] global step 358: loss = 1.4831 (1.537 sec/step)\n",
      "INFO:tensorflow:global step 359: loss = 1.4860 (1.617 sec/step)\n",
      "I1125 19:59:20.934183 140154295584576 learning.py:507] global step 359: loss = 1.4860 (1.617 sec/step)\n",
      "INFO:tensorflow:global step 360: loss = 1.6296 (1.572 sec/step)\n",
      "I1125 19:59:22.507623 140154295584576 learning.py:507] global step 360: loss = 1.6296 (1.572 sec/step)\n",
      "INFO:tensorflow:global step 361: loss = 1.3984 (1.578 sec/step)\n",
      "I1125 19:59:24.087053 140154295584576 learning.py:507] global step 361: loss = 1.3984 (1.578 sec/step)\n",
      "INFO:tensorflow:global step 362: loss = 1.3076 (1.492 sec/step)\n",
      "I1125 19:59:25.580325 140154295584576 learning.py:507] global step 362: loss = 1.3076 (1.492 sec/step)\n",
      "INFO:tensorflow:global step 363: loss = 0.7751 (1.518 sec/step)\n",
      "I1125 19:59:27.099301 140154295584576 learning.py:507] global step 363: loss = 0.7751 (1.518 sec/step)\n",
      "INFO:tensorflow:global step 364: loss = 1.6250 (1.363 sec/step)\n",
      "I1125 19:59:28.463651 140154295584576 learning.py:507] global step 364: loss = 1.6250 (1.363 sec/step)\n",
      "INFO:tensorflow:global step 365: loss = 0.3740 (1.337 sec/step)\n",
      "I1125 19:59:29.801880 140154295584576 learning.py:507] global step 365: loss = 0.3740 (1.337 sec/step)\n",
      "INFO:tensorflow:global step 366: loss = 1.2114 (1.710 sec/step)\n",
      "I1125 19:59:31.513222 140154295584576 learning.py:507] global step 366: loss = 1.2114 (1.710 sec/step)\n",
      "INFO:tensorflow:global step 367: loss = 1.7730 (1.475 sec/step)\n",
      "I1125 19:59:32.988980 140154295584576 learning.py:507] global step 367: loss = 1.7730 (1.475 sec/step)\n",
      "INFO:tensorflow:global step 368: loss = 0.6062 (1.550 sec/step)\n",
      "I1125 19:59:34.539746 140154295584576 learning.py:507] global step 368: loss = 0.6062 (1.550 sec/step)\n",
      "INFO:tensorflow:global step 369: loss = 1.6207 (1.573 sec/step)\n",
      "I1125 19:59:36.113507 140154295584576 learning.py:507] global step 369: loss = 1.6207 (1.573 sec/step)\n",
      "INFO:tensorflow:global step 370: loss = 1.6518 (1.911 sec/step)\n",
      "I1125 19:59:38.025796 140154295584576 learning.py:507] global step 370: loss = 1.6518 (1.911 sec/step)\n",
      "INFO:tensorflow:global step 371: loss = 0.3690 (1.798 sec/step)\n",
      "I1125 19:59:39.824664 140154295584576 learning.py:507] global step 371: loss = 0.3690 (1.798 sec/step)\n",
      "INFO:tensorflow:global step 372: loss = 0.6168 (3.445 sec/step)\n",
      "I1125 19:59:43.271114 140154295584576 learning.py:507] global step 372: loss = 0.6168 (3.445 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global step 373: loss = 1.3781 (1.567 sec/step)\n",
      "I1125 19:59:44.839333 140154295584576 learning.py:507] global step 373: loss = 1.3781 (1.567 sec/step)\n",
      "INFO:tensorflow:global step 374: loss = 0.2030 (1.435 sec/step)\n",
      "I1125 19:59:46.275659 140154295584576 learning.py:507] global step 374: loss = 0.2030 (1.435 sec/step)\n",
      "INFO:tensorflow:global step 375: loss = 0.7577 (1.125 sec/step)\n",
      "I1125 19:59:47.401316 140154295584576 learning.py:507] global step 375: loss = 0.7577 (1.125 sec/step)\n",
      "INFO:tensorflow:global step 376: loss = 0.8330 (1.430 sec/step)\n",
      "I1125 19:59:48.832473 140154295584576 learning.py:507] global step 376: loss = 0.8330 (1.430 sec/step)\n",
      "INFO:tensorflow:global step 377: loss = 1.7726 (1.740 sec/step)\n",
      "I1125 19:59:50.573354 140154295584576 learning.py:507] global step 377: loss = 1.7726 (1.740 sec/step)\n",
      "INFO:tensorflow:global step 378: loss = 0.2991 (1.793 sec/step)\n",
      "I1125 19:59:52.367855 140154295584576 learning.py:507] global step 378: loss = 0.2991 (1.793 sec/step)\n",
      "INFO:tensorflow:Saving checkpoint to path /happy-walrus/models/version_3/training/model.ckpt\n",
      "I1125 19:59:53.927433 140149849569024 supervisor.py:1117] Saving checkpoint to path /happy-walrus/models/version_3/training/model.ckpt\n",
      "INFO:tensorflow:global step 379: loss = 0.8470 (1.678 sec/step)\n",
      "I1125 19:59:54.047800 140154295584576 learning.py:507] global step 379: loss = 0.8470 (1.678 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 379.\n",
      "I1125 19:59:54.416125 140149832783616 supervisor.py:1050] Recording summary at step 379.\n",
      "INFO:tensorflow:global step 380: loss = 0.5624 (1.859 sec/step)\n",
      "I1125 19:59:55.909631 140154295584576 learning.py:507] global step 380: loss = 0.5624 (1.859 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 0.625\n",
      "I1125 19:59:56.650249 140149841176320 supervisor.py:1099] global_step/sec: 0.625\n",
      "INFO:tensorflow:global step 381: loss = 1.1611 (1.615 sec/step)\n",
      "I1125 19:59:57.526237 140154295584576 learning.py:507] global step 381: loss = 1.1611 (1.615 sec/step)\n",
      "INFO:tensorflow:global step 382: loss = 1.0591 (1.564 sec/step)\n",
      "I1125 19:59:59.090966 140154295584576 learning.py:507] global step 382: loss = 1.0591 (1.564 sec/step)\n",
      "INFO:tensorflow:global step 383: loss = 1.2055 (1.888 sec/step)\n",
      "I1125 20:00:00.980403 140154295584576 learning.py:507] global step 383: loss = 1.2055 (1.888 sec/step)\n",
      "INFO:tensorflow:global step 384: loss = 2.2386 (2.541 sec/step)\n",
      "I1125 20:00:03.523854 140154295584576 learning.py:507] global step 384: loss = 2.2386 (2.541 sec/step)\n",
      "INFO:tensorflow:global step 385: loss = 1.4908 (1.470 sec/step)\n",
      "I1125 20:00:04.994783 140154295584576 learning.py:507] global step 385: loss = 1.4908 (1.470 sec/step)\n",
      "INFO:tensorflow:global step 386: loss = 0.8047 (1.541 sec/step)\n",
      "I1125 20:00:06.537176 140154295584576 learning.py:507] global step 386: loss = 0.8047 (1.541 sec/step)\n",
      "INFO:tensorflow:global step 387: loss = 0.3811 (1.373 sec/step)\n",
      "I1125 20:00:07.911676 140154295584576 learning.py:507] global step 387: loss = 0.3811 (1.373 sec/step)\n",
      "INFO:tensorflow:global step 388: loss = 0.3604 (1.506 sec/step)\n",
      "I1125 20:00:09.418975 140154295584576 learning.py:507] global step 388: loss = 0.3604 (1.506 sec/step)\n",
      "INFO:tensorflow:global step 389: loss = 1.7216 (1.582 sec/step)\n",
      "I1125 20:00:11.002035 140154295584576 learning.py:507] global step 389: loss = 1.7216 (1.582 sec/step)\n",
      "INFO:tensorflow:global step 390: loss = 1.0087 (1.537 sec/step)\n",
      "I1125 20:00:12.540544 140154295584576 learning.py:507] global step 390: loss = 1.0087 (1.537 sec/step)\n",
      "INFO:tensorflow:global step 391: loss = 1.4363 (1.571 sec/step)\n",
      "I1125 20:00:14.112932 140154295584576 learning.py:507] global step 391: loss = 1.4363 (1.571 sec/step)\n",
      "INFO:tensorflow:global step 392: loss = 0.2290 (1.468 sec/step)\n",
      "I1125 20:00:15.581919 140154295584576 learning.py:507] global step 392: loss = 0.2290 (1.468 sec/step)\n",
      "INFO:tensorflow:global step 393: loss = 0.2579 (1.291 sec/step)\n",
      "I1125 20:00:16.873588 140154295584576 learning.py:507] global step 393: loss = 0.2579 (1.291 sec/step)\n",
      "INFO:tensorflow:global step 394: loss = 0.7845 (1.421 sec/step)\n",
      "I1125 20:00:18.296277 140154295584576 learning.py:507] global step 394: loss = 0.7845 (1.421 sec/step)\n",
      "INFO:tensorflow:global step 395: loss = 1.1797 (1.638 sec/step)\n",
      "I1125 20:00:19.935941 140154295584576 learning.py:507] global step 395: loss = 1.1797 (1.638 sec/step)\n",
      "INFO:tensorflow:global step 396: loss = 0.2384 (1.490 sec/step)\n",
      "I1125 20:00:21.426999 140154295584576 learning.py:507] global step 396: loss = 0.2384 (1.490 sec/step)\n",
      "INFO:tensorflow:global step 397: loss = 1.1940 (1.870 sec/step)\n",
      "I1125 20:00:23.297959 140154295584576 learning.py:507] global step 397: loss = 1.1940 (1.870 sec/step)\n",
      "INFO:tensorflow:global step 398: loss = 0.3883 (2.038 sec/step)\n",
      "I1125 20:00:25.337409 140154295584576 learning.py:507] global step 398: loss = 0.3883 (2.038 sec/step)\n",
      "INFO:tensorflow:global step 399: loss = 1.3494 (1.644 sec/step)\n",
      "I1125 20:00:26.982946 140154295584576 learning.py:507] global step 399: loss = 1.3494 (1.644 sec/step)\n",
      "INFO:tensorflow:global step 400: loss = 1.2325 (1.566 sec/step)\n",
      "I1125 20:00:28.549813 140154295584576 learning.py:507] global step 400: loss = 1.2325 (1.566 sec/step)\n",
      "INFO:tensorflow:global step 401: loss = 1.4543 (1.522 sec/step)\n",
      "I1125 20:00:30.073015 140154295584576 learning.py:507] global step 401: loss = 1.4543 (1.522 sec/step)\n",
      "INFO:tensorflow:global step 402: loss = 1.6718 (1.411 sec/step)\n",
      "I1125 20:00:31.485642 140154295584576 learning.py:507] global step 402: loss = 1.6718 (1.411 sec/step)\n",
      "INFO:tensorflow:global step 403: loss = 0.7607 (1.676 sec/step)\n",
      "I1125 20:00:33.163279 140154295584576 learning.py:507] global step 403: loss = 0.7607 (1.676 sec/step)\n",
      "INFO:tensorflow:global step 404: loss = 0.7465 (1.538 sec/step)\n",
      "I1125 20:00:34.702614 140154295584576 learning.py:507] global step 404: loss = 0.7465 (1.538 sec/step)\n",
      "INFO:tensorflow:global step 405: loss = 0.2125 (1.693 sec/step)\n",
      "I1125 20:00:36.396721 140154295584576 learning.py:507] global step 405: loss = 0.2125 (1.693 sec/step)\n",
      "INFO:tensorflow:global step 406: loss = 0.1541 (1.611 sec/step)\n",
      "I1125 20:00:38.008632 140154295584576 learning.py:507] global step 406: loss = 0.1541 (1.611 sec/step)\n",
      "INFO:tensorflow:global step 407: loss = 0.1912 (1.581 sec/step)\n",
      "I1125 20:00:39.590505 140154295584576 learning.py:507] global step 407: loss = 0.1912 (1.581 sec/step)\n",
      "INFO:tensorflow:global step 408: loss = 2.0405 (1.631 sec/step)\n",
      "I1125 20:00:41.222433 140154295584576 learning.py:507] global step 408: loss = 2.0405 (1.631 sec/step)\n",
      "INFO:tensorflow:global step 409: loss = 1.3765 (1.360 sec/step)\n",
      "I1125 20:00:42.583204 140154295584576 learning.py:507] global step 409: loss = 1.3765 (1.360 sec/step)\n",
      "INFO:tensorflow:global step 410: loss = 1.4875 (1.118 sec/step)\n",
      "I1125 20:00:43.702238 140154295584576 learning.py:507] global step 410: loss = 1.4875 (1.118 sec/step)\n",
      "INFO:tensorflow:global step 411: loss = 1.1496 (1.629 sec/step)\n",
      "I1125 20:00:45.334609 140154295584576 learning.py:507] global step 411: loss = 1.1496 (1.629 sec/step)\n",
      "INFO:tensorflow:global step 412: loss = 1.6008 (1.679 sec/step)\n",
      "I1125 20:00:47.016211 140154295584576 learning.py:507] global step 412: loss = 1.6008 (1.679 sec/step)\n",
      "INFO:tensorflow:global step 413: loss = 0.6723 (1.597 sec/step)\n",
      "I1125 20:00:48.614878 140154295584576 learning.py:507] global step 413: loss = 0.6723 (1.597 sec/step)\n",
      "INFO:tensorflow:global step 414: loss = 0.4882 (1.542 sec/step)\n",
      "I1125 20:00:50.158028 140154295584576 learning.py:507] global step 414: loss = 0.4882 (1.542 sec/step)\n",
      "INFO:tensorflow:global step 415: loss = 1.0128 (1.727 sec/step)\n",
      "I1125 20:00:51.886359 140154295584576 learning.py:507] global step 415: loss = 1.0128 (1.727 sec/step)\n",
      "INFO:tensorflow:global step 416: loss = 1.0451 (1.361 sec/step)\n",
      "I1125 20:00:53.248158 140154295584576 learning.py:507] global step 416: loss = 1.0451 (1.361 sec/step)\n",
      "INFO:tensorflow:global step 417: loss = 0.1139 (1.718 sec/step)\n",
      "I1125 20:00:54.967199 140154295584576 learning.py:507] global step 417: loss = 0.1139 (1.718 sec/step)\n",
      "INFO:tensorflow:global step 418: loss = 0.4573 (1.374 sec/step)\n",
      "I1125 20:00:56.342646 140154295584576 learning.py:507] global step 418: loss = 0.4573 (1.374 sec/step)\n",
      "INFO:tensorflow:global step 419: loss = 0.8626 (1.449 sec/step)\n",
      "I1125 20:00:57.793170 140154295584576 learning.py:507] global step 419: loss = 0.8626 (1.449 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global step 420: loss = 0.3568 (1.127 sec/step)\n",
      "I1125 20:00:58.920951 140154295584576 learning.py:507] global step 420: loss = 0.3568 (1.127 sec/step)\n",
      "INFO:tensorflow:global step 421: loss = 0.3606 (1.398 sec/step)\n",
      "I1125 20:01:00.319623 140154295584576 learning.py:507] global step 421: loss = 0.3606 (1.398 sec/step)\n",
      "INFO:tensorflow:global step 422: loss = 1.0941 (1.665 sec/step)\n",
      "I1125 20:01:01.985347 140154295584576 learning.py:507] global step 422: loss = 1.0941 (1.665 sec/step)\n",
      "INFO:tensorflow:global step 423: loss = 0.4484 (1.132 sec/step)\n",
      "I1125 20:01:03.118818 140154295584576 learning.py:507] global step 423: loss = 0.4484 (1.132 sec/step)\n",
      "INFO:tensorflow:global step 424: loss = 0.8572 (1.577 sec/step)\n",
      "I1125 20:01:04.696897 140154295584576 learning.py:507] global step 424: loss = 0.8572 (1.577 sec/step)\n",
      "INFO:tensorflow:global step 425: loss = 1.5488 (1.437 sec/step)\n",
      "I1125 20:01:06.135966 140154295584576 learning.py:507] global step 425: loss = 1.5488 (1.437 sec/step)\n",
      "INFO:tensorflow:global step 426: loss = 0.1677 (1.606 sec/step)\n",
      "I1125 20:01:07.743701 140154295584576 learning.py:507] global step 426: loss = 0.1677 (1.606 sec/step)\n",
      "INFO:tensorflow:global step 427: loss = 0.3225 (2.260 sec/step)\n",
      "I1125 20:01:10.004539 140154295584576 learning.py:507] global step 427: loss = 0.3225 (2.260 sec/step)\n",
      "INFO:tensorflow:global step 428: loss = 0.2937 (1.499 sec/step)\n",
      "I1125 20:01:11.505101 140154295584576 learning.py:507] global step 428: loss = 0.2937 (1.499 sec/step)\n",
      "INFO:tensorflow:global step 429: loss = 1.4115 (1.589 sec/step)\n",
      "I1125 20:01:13.095461 140154295584576 learning.py:507] global step 429: loss = 1.4115 (1.589 sec/step)\n",
      "INFO:tensorflow:global step 430: loss = 1.4583 (1.508 sec/step)\n",
      "I1125 20:01:14.604289 140154295584576 learning.py:507] global step 430: loss = 1.4583 (1.508 sec/step)\n",
      "INFO:tensorflow:global step 431: loss = 0.3472 (1.572 sec/step)\n",
      "I1125 20:01:16.177651 140154295584576 learning.py:507] global step 431: loss = 0.3472 (1.572 sec/step)\n",
      "INFO:tensorflow:global step 432: loss = 0.5261 (1.540 sec/step)\n",
      "I1125 20:01:17.718628 140154295584576 learning.py:507] global step 432: loss = 0.5261 (1.540 sec/step)\n",
      "INFO:tensorflow:global step 433: loss = 1.1047 (1.453 sec/step)\n",
      "I1125 20:01:19.172801 140154295584576 learning.py:507] global step 433: loss = 1.1047 (1.453 sec/step)\n",
      "INFO:tensorflow:global step 434: loss = 1.7665 (1.389 sec/step)\n",
      "I1125 20:01:20.563253 140154295584576 learning.py:507] global step 434: loss = 1.7665 (1.389 sec/step)\n",
      "INFO:tensorflow:global step 435: loss = 0.2283 (1.443 sec/step)\n",
      "I1125 20:01:22.007558 140154295584576 learning.py:507] global step 435: loss = 0.2283 (1.443 sec/step)\n",
      "INFO:tensorflow:global step 436: loss = 1.4060 (1.508 sec/step)\n",
      "I1125 20:01:23.516538 140154295584576 learning.py:507] global step 436: loss = 1.4060 (1.508 sec/step)\n",
      "INFO:tensorflow:global step 437: loss = 0.8821 (1.683 sec/step)\n",
      "I1125 20:01:25.201008 140154295584576 learning.py:507] global step 437: loss = 0.8821 (1.683 sec/step)\n",
      "INFO:tensorflow:global step 438: loss = 1.0565 (1.612 sec/step)\n",
      "I1125 20:01:26.813855 140154295584576 learning.py:507] global step 438: loss = 1.0565 (1.612 sec/step)\n",
      "INFO:tensorflow:global step 439: loss = 0.4319 (1.415 sec/step)\n",
      "I1125 20:01:28.230009 140154295584576 learning.py:507] global step 439: loss = 0.4319 (1.415 sec/step)\n",
      "INFO:tensorflow:global step 440: loss = 0.8701 (1.570 sec/step)\n",
      "I1125 20:01:29.801301 140154295584576 learning.py:507] global step 440: loss = 0.8701 (1.570 sec/step)\n",
      "INFO:tensorflow:global step 441: loss = 2.2654 (1.503 sec/step)\n",
      "I1125 20:01:31.304974 140154295584576 learning.py:507] global step 441: loss = 2.2654 (1.503 sec/step)\n",
      "INFO:tensorflow:global step 442: loss = 1.5587 (1.489 sec/step)\n",
      "I1125 20:01:32.795641 140154295584576 learning.py:507] global step 442: loss = 1.5587 (1.489 sec/step)\n",
      "INFO:tensorflow:global step 443: loss = 2.5394 (1.566 sec/step)\n",
      "I1125 20:01:34.362445 140154295584576 learning.py:507] global step 443: loss = 2.5394 (1.566 sec/step)\n",
      "INFO:tensorflow:global step 444: loss = 0.2099 (1.767 sec/step)\n",
      "I1125 20:01:36.130790 140154295584576 learning.py:507] global step 444: loss = 0.2099 (1.767 sec/step)\n",
      "INFO:tensorflow:global step 445: loss = 0.6060 (1.888 sec/step)\n",
      "I1125 20:01:38.019472 140154295584576 learning.py:507] global step 445: loss = 0.6060 (1.888 sec/step)\n",
      "INFO:tensorflow:global step 446: loss = 0.6240 (1.646 sec/step)\n",
      "I1125 20:01:39.666441 140154295584576 learning.py:507] global step 446: loss = 0.6240 (1.646 sec/step)\n",
      "INFO:tensorflow:global step 447: loss = 0.6301 (1.425 sec/step)\n",
      "I1125 20:01:41.092257 140154295584576 learning.py:507] global step 447: loss = 0.6301 (1.425 sec/step)\n",
      "INFO:tensorflow:global step 448: loss = 1.5691 (1.645 sec/step)\n",
      "I1125 20:01:42.738004 140154295584576 learning.py:507] global step 448: loss = 1.5691 (1.645 sec/step)\n",
      "INFO:tensorflow:global step 449: loss = 0.2334 (1.146 sec/step)\n",
      "I1125 20:01:43.885107 140154295584576 learning.py:507] global step 449: loss = 0.2334 (1.146 sec/step)\n",
      "INFO:tensorflow:global step 450: loss = 1.1088 (1.425 sec/step)\n",
      "I1125 20:01:45.311027 140154295584576 learning.py:507] global step 450: loss = 1.1088 (1.425 sec/step)\n",
      "INFO:tensorflow:global step 451: loss = 0.8436 (1.631 sec/step)\n",
      "I1125 20:01:46.942863 140154295584576 learning.py:507] global step 451: loss = 0.8436 (1.631 sec/step)\n",
      "INFO:tensorflow:global step 452: loss = 0.9978 (1.646 sec/step)\n",
      "I1125 20:01:48.589608 140154295584576 learning.py:507] global step 452: loss = 0.9978 (1.646 sec/step)\n",
      "INFO:tensorflow:global step 453: loss = 1.3816 (1.595 sec/step)\n",
      "I1125 20:01:50.186320 140154295584576 learning.py:507] global step 453: loss = 1.3816 (1.595 sec/step)\n",
      "INFO:tensorflow:global step 454: loss = 1.1796 (1.159 sec/step)\n",
      "I1125 20:01:51.346902 140154295584576 learning.py:507] global step 454: loss = 1.1796 (1.159 sec/step)\n",
      "INFO:tensorflow:global step 455: loss = 0.8973 (1.590 sec/step)\n",
      "I1125 20:01:52.937913 140154295584576 learning.py:507] global step 455: loss = 0.8973 (1.590 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 455.\n",
      "I1125 20:01:54.326726 140149832783616 supervisor.py:1050] Recording summary at step 455.\n",
      "INFO:tensorflow:global step 456: loss = 0.5961 (1.732 sec/step)\n",
      "I1125 20:01:54.670714 140154295584576 learning.py:507] global step 456: loss = 0.5961 (1.732 sec/step)\n",
      "INFO:tensorflow:global step 457: loss = 0.8179 (1.666 sec/step)\n",
      "I1125 20:01:56.338475 140154295584576 learning.py:507] global step 457: loss = 0.8179 (1.666 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 0.641667\n",
      "I1125 20:01:56.650246 140149841176320 supervisor.py:1099] global_step/sec: 0.641667\n",
      "INFO:tensorflow:global step 458: loss = 0.8447 (2.161 sec/step)\n",
      "I1125 20:01:58.501287 140154295584576 learning.py:507] global step 458: loss = 0.8447 (2.161 sec/step)\n",
      "INFO:tensorflow:global step 459: loss = 0.5690 (2.004 sec/step)\n",
      "I1125 20:02:00.506747 140154295584576 learning.py:507] global step 459: loss = 0.5690 (2.004 sec/step)\n",
      "INFO:tensorflow:global step 460: loss = 0.7834 (1.435 sec/step)\n",
      "I1125 20:02:01.943244 140154295584576 learning.py:507] global step 460: loss = 0.7834 (1.435 sec/step)\n",
      "INFO:tensorflow:global step 461: loss = 0.3275 (1.408 sec/step)\n",
      "I1125 20:02:03.352252 140154295584576 learning.py:507] global step 461: loss = 0.3275 (1.408 sec/step)\n",
      "INFO:tensorflow:global step 462: loss = 0.9345 (1.354 sec/step)\n",
      "I1125 20:02:04.706985 140154295584576 learning.py:507] global step 462: loss = 0.9345 (1.354 sec/step)\n",
      "INFO:tensorflow:global step 463: loss = 1.1005 (1.598 sec/step)\n",
      "I1125 20:02:06.306004 140154295584576 learning.py:507] global step 463: loss = 1.1005 (1.598 sec/step)\n",
      "INFO:tensorflow:global step 464: loss = 0.5844 (1.476 sec/step)\n",
      "I1125 20:02:07.782980 140154295584576 learning.py:507] global step 464: loss = 0.5844 (1.476 sec/step)\n",
      "INFO:tensorflow:global step 465: loss = 0.6684 (1.403 sec/step)\n",
      "I1125 20:02:09.187559 140154295584576 learning.py:507] global step 465: loss = 0.6684 (1.403 sec/step)\n",
      "INFO:tensorflow:global step 466: loss = 1.1978 (1.092 sec/step)\n",
      "I1125 20:02:10.281090 140154295584576 learning.py:507] global step 466: loss = 1.1978 (1.092 sec/step)\n",
      "INFO:tensorflow:global step 467: loss = 0.4298 (1.591 sec/step)\n",
      "I1125 20:02:11.872835 140154295584576 learning.py:507] global step 467: loss = 0.4298 (1.591 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global step 468: loss = 1.4298 (1.487 sec/step)\n",
      "I1125 20:02:13.361375 140154295584576 learning.py:507] global step 468: loss = 1.4298 (1.487 sec/step)\n",
      "INFO:tensorflow:global step 469: loss = 0.9727 (1.558 sec/step)\n",
      "I1125 20:02:14.920650 140154295584576 learning.py:507] global step 469: loss = 0.9727 (1.558 sec/step)\n",
      "INFO:tensorflow:global step 470: loss = 0.9647 (1.580 sec/step)\n",
      "I1125 20:02:16.502117 140154295584576 learning.py:507] global step 470: loss = 0.9647 (1.580 sec/step)\n",
      "INFO:tensorflow:global step 471: loss = 1.5228 (1.425 sec/step)\n",
      "I1125 20:02:17.928307 140154295584576 learning.py:507] global step 471: loss = 1.5228 (1.425 sec/step)\n",
      "INFO:tensorflow:global step 472: loss = 0.3914 (1.393 sec/step)\n",
      "I1125 20:02:19.322090 140154295584576 learning.py:507] global step 472: loss = 0.3914 (1.393 sec/step)\n",
      "INFO:tensorflow:global step 473: loss = 0.5601 (1.569 sec/step)\n",
      "I1125 20:02:20.892070 140154295584576 learning.py:507] global step 473: loss = 0.5601 (1.569 sec/step)\n",
      "INFO:tensorflow:global step 474: loss = 1.1229 (1.638 sec/step)\n",
      "I1125 20:02:22.531210 140154295584576 learning.py:507] global step 474: loss = 1.1229 (1.638 sec/step)\n",
      "INFO:tensorflow:global step 475: loss = 0.9037 (2.069 sec/step)\n",
      "I1125 20:02:24.601450 140154295584576 learning.py:507] global step 475: loss = 0.9037 (2.069 sec/step)\n",
      "INFO:tensorflow:global step 476: loss = 0.6108 (1.604 sec/step)\n",
      "I1125 20:02:26.206940 140154295584576 learning.py:507] global step 476: loss = 0.6108 (1.604 sec/step)\n",
      "INFO:tensorflow:global step 477: loss = 1.2924 (1.618 sec/step)\n",
      "I1125 20:02:27.826181 140154295584576 learning.py:507] global step 477: loss = 1.2924 (1.618 sec/step)\n",
      "INFO:tensorflow:global step 478: loss = 2.2243 (1.554 sec/step)\n",
      "I1125 20:02:29.381200 140154295584576 learning.py:507] global step 478: loss = 2.2243 (1.554 sec/step)\n",
      "INFO:tensorflow:global step 479: loss = 0.1972 (1.607 sec/step)\n",
      "I1125 20:02:30.989386 140154295584576 learning.py:507] global step 479: loss = 0.1972 (1.607 sec/step)\n",
      "INFO:tensorflow:global step 480: loss = 0.6759 (1.442 sec/step)\n",
      "I1125 20:02:32.432361 140154295584576 learning.py:507] global step 480: loss = 0.6759 (1.442 sec/step)\n",
      "INFO:tensorflow:global step 481: loss = 1.4886 (1.090 sec/step)\n",
      "I1125 20:02:33.523180 140154295584576 learning.py:507] global step 481: loss = 1.4886 (1.090 sec/step)\n",
      "INFO:tensorflow:global step 482: loss = 2.0115 (1.579 sec/step)\n",
      "I1125 20:02:35.103651 140154295584576 learning.py:507] global step 482: loss = 2.0115 (1.579 sec/step)\n",
      "INFO:tensorflow:global step 483: loss = 1.6827 (1.684 sec/step)\n",
      "I1125 20:02:36.789137 140154295584576 learning.py:507] global step 483: loss = 1.6827 (1.684 sec/step)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python train.py --logtostderr --train_dir={MAIN_PATH}training/ --pipeline_config_path={MAIN_PATH}training/faster_rcnn_inception_v2_auto_augmentations.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In command line, inside container, run `tensorboard --logdir=/happy-walrus/models/version_2/training`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 768236\r\n",
      "-rw-r--r-- 1 root root       517 Nov 15 11:19 checkpoint\r\n",
      "-rw-r--r-- 1 root root 232937451 Nov 15 11:21 events.out.tfevents.1573763961.d93712a46288\r\n",
      "-rw-r--r-- 1 root root      4427 Nov 13 21:41 faster_rcnn_inception_v2_kitchens.config\r\n",
      "-rw-r--r-- 1 root root  10469360 Nov 14 20:39 graph.pbtxt\r\n",
      "-rw-r--r-- 1 root root       178 Nov 14 20:26 labelmap.pbtxt\r\n",
      "-rw-r--r-- 1 root root       202 Nov 13 21:41 labelmap.pbtxt.bak\r\n",
      "-rw-r--r-- 1 root root 103173376 Nov 15 10:39 model.ckpt-45643.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root     25563 Nov 15 10:39 model.ckpt-45643.index\r\n",
      "-rw-r--r-- 1 root root   5441061 Nov 15 10:39 model.ckpt-45643.meta\r\n",
      "-rw-r--r-- 1 root root 103173376 Nov 15 10:49 model.ckpt-46185.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root     25563 Nov 15 10:49 model.ckpt-46185.index\r\n",
      "-rw-r--r-- 1 root root   5441061 Nov 15 10:49 model.ckpt-46185.meta\r\n",
      "-rw-r--r-- 1 root root 103173376 Nov 15 10:59 model.ckpt-46725.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root     25563 Nov 15 10:59 model.ckpt-46725.index\r\n",
      "-rw-r--r-- 1 root root   5441061 Nov 15 10:59 model.ckpt-46725.meta\r\n",
      "-rw-r--r-- 1 root root 103173376 Nov 15 11:09 model.ckpt-47267.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root     25563 Nov 15 11:09 model.ckpt-47267.index\r\n",
      "-rw-r--r-- 1 root root   5441061 Nov 15 11:09 model.ckpt-47267.meta\r\n",
      "-rw-r--r-- 1 root root 103173376 Nov 15 11:19 model.ckpt-47799.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root     25563 Nov 15 11:19 model.ckpt-47799.index\r\n",
      "-rw-r--r-- 1 root root   5441061 Nov 15 11:19 model.ckpt-47799.meta\r\n",
      "-rw-r--r-- 1 root root      4427 Nov 14 20:38 pipeline.config\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1104 16:28:48.156948 140301050382144 module_wrapper.py:139] From /models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:389: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W1104 16:28:48.168290 140301050382144 module_wrapper.py:139] From /models/research/object_detection/exporter.py:389: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1104 16:28:48.169805 140301050382144 module_wrapper.py:139] From /models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "W1104 16:28:48.254730 140301050382144 module_wrapper.py:139] From /models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:166: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W1104 16:28:48.322432 140301050382144 module_wrapper.py:139] From /models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:166: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:2784: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W1104 16:28:48.334235 140301050382144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:2784: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "W1104 16:28:50.465754 140301050382144 module_wrapper.py:139] From /models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1104 16:28:50.474844 140301050382144 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:556: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "W1104 16:28:50.475338 140301050382144 module_wrapper.py:139] From /models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:556: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1104 16:28:50.498707 140301050382144 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W1104 16:28:50.499562 140301050382144 module_wrapper.py:139] From /models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1104 16:28:50.499820 140301050382144 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /models/research/object_detection/core/box_list_ops.py:141: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1104 16:28:50.627849 140301050382144 deprecation.py:323] From /models/research/object_detection/core/box_list_ops.py:141: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W1104 16:28:51.424877 140301050382144 deprecation.py:506] From /models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:189: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W1104 16:28:51.450381 140301050382144 module_wrapper.py:139] From /models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:189: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W1104 16:28:52.262791 140301050382144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1104 16:28:52.269709 140301050382144 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1104 16:28:52.292346 140301050382144 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
      "W1104 16:28:53.343219 140301050382144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:268: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W1104 16:28:53.766587 140301050382144 module_wrapper.py:139] From /models/research/object_detection/exporter.py:268: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:370: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "W1104 16:28:53.766983 140301050382144 deprecation.py:323] From /models/research/object_detection/exporter.py:370: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:402: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1104 16:28:53.770792 140301050382144 module_wrapper.py:139] From /models/research/object_detection/exporter.py:402: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:526: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "W1104 16:28:53.771027 140301050382144 deprecation.py:323] From /models/research/object_detection/exporter.py:526: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "W1104 16:28:53.772196 140301050382144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "234 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "Incomplete shape.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              0\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   name\n",
      "-account_type_regexes       _trainable_variables\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     params\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Incomplete shape.\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "param: Number of parameters (in the Variable).\n",
      "\n",
      "Profile:\n",
      "node name | # parameters\n",
      "_TFProfRoot (--/12.85m params)\n",
      "  Conv (--/2.65m params)\n",
      "    Conv/biases (512, 512/512 params)\n",
      "    Conv/weights (3x3x576x512, 2.65m/2.65m params)\n",
      "  FirstStageBoxPredictor (--/36.94k params)\n",
      "    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n",
      "      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n",
      "      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n",
      "    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n",
      "      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n",
      "      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
      "  FirstStageFeatureExtractor (--/4.25m params)\n",
      "    FirstStageFeatureExtractor/InceptionV2 (--/4.25m params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7 (--/2.71k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm (--/0 params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/depthwise_weights (7x7x3x8, 1.18k/1.18k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights (1x1x24x64, 1.54k/1.54k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1 (--/4.10k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/BatchNorm (--/0 params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/weights (1x1x64x64, 4.10k/4.10k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3 (--/110.59k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/BatchNorm (--/0 params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights (3x3x64x192, 110.59k/110.59k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_3b (--/218.11k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0 (--/12.29k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1 (--/12.29k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1 (--/49.15k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1 (--/12.29k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3 (--/36.86k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x64, 36.86k/36.86k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2 (--/150.53k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1 (--/12.29k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3 (--/6.14k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1 (--/6.14k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights (1x1x192x32, 6.14k/6.14k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_3c (--/259.07k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0 (--/16.38k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1 (--/16.38k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1 (--/71.68k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1 (--/16.38k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2 (--/154.62k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1 (--/16.38k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3 (--/16.38k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1 (--/16.38k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_4a (--/384.00k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0 (--/225.28k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1 (--/40.96k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/weights (1x1x320x128, 40.96k/40.96k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3 (--/184.32k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1 (--/158.72k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1 (--/20.48k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/weights (1x1x320x64, 20.48k/20.48k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3 (--/82.94k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_4b (--/608.26k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0 (--/129.02k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1 (--/129.02k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights (1x1x576x224, 129.02k/129.02k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1 (--/92.16k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1 (--/36.86k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights (1x1x576x64, 36.86k/36.86k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2 (--/313.34k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3 (--/73.73k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_4c (--/663.55k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0 (--/110.59k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1 (--/110.59k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1 (--/165.89k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3 (--/110.59k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2 (--/313.34k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3 (--/73.73k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_4d (--/893.95k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0 (--/92.16k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1 (--/92.16k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1 (--/258.05k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3 (--/184.32k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2 (--/488.45k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1 (--/73.73k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3 (--/184.32k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3 (--/230.40k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/weights (3x3x160x160, 230.40k/230.40k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3 (--/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "      FirstStageFeatureExtractor/InceptionV2/Mixed_4e (--/1.11m params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0 (--/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1 (--/294.91k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3 (--/221.18k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2 (--/700.42k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1 (--/92.16k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3 (--/276.48k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights (3x3x160x192, 276.48k/276.48k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3 (--/331.78k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/weights (3x3x192x192, 331.78k/331.78k params)\n",
      "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3 (--/55.30k params)\n",
      "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "  SecondStageBoxPredictor (--/11.28k params)\n",
      "    SecondStageBoxPredictor/BoxEncodingPredictor (--/8.20k params)\n",
      "      SecondStageBoxPredictor/BoxEncodingPredictor/biases (8, 8/8 params)\n",
      "      SecondStageBoxPredictor/BoxEncodingPredictor/weights (1024x8, 8.19k/8.19k params)\n",
      "    SecondStageBoxPredictor/ClassPredictor (--/3.08k params)\n",
      "      SecondStageBoxPredictor/ClassPredictor/biases (3, 3/3 params)\n",
      "      SecondStageBoxPredictor/ClassPredictor/weights (1024x3, 3.07k/3.07k params)\n",
      "  SecondStageFeatureExtractor (--/5.89m params)\n",
      "    SecondStageFeatureExtractor/InceptionV2 (--/5.89m params)\n",
      "      SecondStageFeatureExtractor/InceptionV2/Mixed_5a (--/1.44m params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0 (--/294.91k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1 (--/73.73k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3 (--/221.18k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1 (--/1.14m params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1 (--/110.59k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3 (--/442.37k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/weights (3x3x192x256, 442.37k/442.37k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3 (--/589.82k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "      SecondStageFeatureExtractor/InceptionV2/Mixed_5b (--/2.18m params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0 (--/360.45k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1 (--/749.57k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2 (--/937.98k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1 (--/163.84k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x160, 163.84k/163.84k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3 (--/322.56k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights (3x3x160x224, 322.56k/322.56k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3 (--/131.07k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
      "      SecondStageFeatureExtractor/InceptionV2/Mixed_5c (--/2.28m params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0 (--/360.45k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1 (--/749.57k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2 (--/1.04m params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1 (--/196.61k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3 (--/387.07k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights (3x3x192x224, 387.07k/387.07k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
      "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3 (--/131.07k params)\n",
      "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
      "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "Incomplete shape.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Incomplete shape.\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/6.17k flops)\n",
      "  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_2 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_3 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_1 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_2 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_3 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_1 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
      "  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
      "  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
      "  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
      "  map_2/while/mul_3 (300/300 flops)\n",
      "  map_2/while/mul_2 (300/300 flops)\n",
      "  map_2/while/mul_1 (300/300 flops)\n",
      "  map_2/while/mul (300/300 flops)\n",
      "  GridAnchorGenerator/mul (12/12 flops)\n",
      "  GridAnchorGenerator/mul_1 (12/12 flops)\n",
      "  GridAnchorGenerator/mul_2 (12/12 flops)\n",
      "  GridAnchorGenerator/truediv (12/12 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
      "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
      "  mul (1/1 flops)\n",
      "  map_2/while/Less_1 (1/1 flops)\n",
      "  map_2/while/Less (1/1 flops)\n",
      "  map_1/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
      "  map_1/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
      "  map_1/while/Less_1 (1/1 flops)\n",
      "  map_1/while/Less (1/1 flops)\n",
      "  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
      "  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
      "  map/while/Less_1 (1/1 flops)\n",
      "  map/while/Less (1/1 flops)\n",
      "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
      "  SecondStagePostprocessor/map/while/Less_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/map/while/Less (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul_1 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv_1 (1/1 flops)\n",
      "  SecondStageDetectionFeaturesExtract/mul (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchGather/mul (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchGather/mul_2 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
      "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
      "  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n",
      "  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n",
      "  GridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
      "  GridAnchorGenerator/mul_7 (1/1 flops)\n",
      "  GridAnchorGenerator/mul_8 (1/1 flops)\n",
      "  GridAnchorGenerator/zeros/Less (1/1 flops)\n",
      "  Preprocessor/map/while/Less (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/Less (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/Minimum (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/mul (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/mul_1 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv_1 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/Minimum (1/1 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:419: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W1104 16:28:55.322115 140301050382144 module_wrapper.py:139] From /models/research/object_detection/exporter.py:419: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:332: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W1104 16:28:56.493039 140301050382144 module_wrapper.py:139] From /models/research/object_detection/exporter.py:332: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2019-11-04 16:28:56.493579: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2019-11-04 16:28:56.493635: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2019-11-04 16:28:56.493702: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (74a0ad80ad34): /proc/driver/nvidia/version does not exist\n",
      "2019-11-04 16:28:56.494113: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-11-04 16:28:56.502319: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2773865000 Hz\n",
      "2019-11-04 16:28:56.502674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7a6fe60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2019-11-04 16:28:56.502739: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-1295\n",
      "I1104 16:28:56.509631 140301050382144 saver.py:1284] Restoring parameters from training/model.ckpt-1295\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W1104 16:28:59.556322 140301050382144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-1295\n",
      "I1104 16:29:00.517723 140301050382144 saver.py:1284] Restoring parameters from training/model.ckpt-1295\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "W1104 16:29:02.459420 140301050382144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "W1104 16:29:02.460758 140301050382144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 356 variables.\n",
      "I1104 16:29:03.236331 140301050382144 graph_util_impl.py:334] Froze 356 variables.\n",
      "INFO:tensorflow:Converted 356 variables to const ops.\n",
      "I1104 16:29:03.358673 140301050382144 graph_util_impl.py:394] Converted 356 variables to const ops.\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:296: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
      "\n",
      "W1104 16:29:04.674844 140301050382144 module_wrapper.py:139] From /models/research/object_detection/exporter.py:296: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:299: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W1104 16:29:04.682117 140301050382144 deprecation.py:323] From /models/research/object_detection/exporter.py:299: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:305: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
      "\n",
      "W1104 16:29:04.683157 140301050382144 module_wrapper.py:139] From /models/research/object_detection/exporter.py:305: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:308: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
      "\n",
      "W1104 16:29:04.683566 140301050382144 module_wrapper.py:139] From /models/research/object_detection/exporter.py:308: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:313: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
      "\n",
      "W1104 16:29:04.684009 140301050382144 module_wrapper.py:139] From /models/research/object_detection/exporter.py:313: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\n",
      "W1104 16:29:04.684200 140301050382144 module_wrapper.py:139] From /models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\n",
      "INFO:tensorflow:No assets to save.\n",
      "I1104 16:29:04.684525 140301050382144 builder_impl.py:640] No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "I1104 16:29:04.684632 140301050382144 builder_impl.py:460] No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: inference_graph/saved_model/saved_model.pb\n",
      "I1104 16:29:05.666822 140301050382144 builder_impl.py:425] SavedModel written to: inference_graph/saved_model/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\r\n",
      "\r\n",
      "W1104 16:29:05.716187 140301050382144 module_wrapper.py:139] From /models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\r\n",
      "\r\n",
      "INFO:tensorflow:Writing pipeline config file to inference_graph/pipeline.config\r\n",
      "I1104 16:29:05.716538 140301050382144 config_util.py:190] Writing pipeline config file to inference_graph/pipeline.config\r\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ckpt_step = 1295\n",
    "python {OD_PATH}export_inference_graph.py --input_type image_tensor --pipeline_config_path training/faster_rcnn_inception_v2_kitchens.config --trained_checkpoint_prefix training/model.ckpt-{ckpt_step} --output_directory inference_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 101M\r\n",
      "-rwxr-xr-x 1 root root   77 Nov  4 16:28 checkpoint\r\n",
      "-rwxr-xr-x 1 root root  136 Nov  4 14:50 desktop.ini\r\n",
      "-rwxr-xr-x 1 root root  50M Nov  4 16:29 frozen_inference_graph.pb\r\n",
      "-rwxr-xr-x 1 root root  50M Nov  4 16:28 model.ckpt.data-00000-of-00001\r\n",
      "-rwxr-xr-x 1 root root  16K Nov  4 16:28 model.ckpt.index\r\n",
      "-rwxr-xr-x 1 root root 1.8M Nov  4 16:28 model.ckpt.meta\r\n",
      "-rwxr-xr-x 1 root root 3.1K Nov  4 16:29 pipeline.config\r\n",
      "drwxrwxrwx 2 root root    0 Nov  4 16:29 saved_model\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh inference_graph/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download model and store it in Google Drive for use in next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T12:06:30.407521Z",
     "start_time": "2019-11-07T12:06:29.516282Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1JVFhXqaayxWOIhuQdzmjIMBAHrAhLcEQ\n",
      "To: /happy-walrus/models/version_2/inference_graph.zip\n",
      "144MB [00:01, 74.9MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Download images\n",
    "model_id = \"1JVFhXqaayxWOIhuQdzmjIMBAHrAhLcEQ\"\n",
    "model_name = \"inference_graph.zip\"\n",
    "gdown.download(url=\"https://drive.google.com/uc?id=\" + model_id,\n",
    "               output=MAIN_PATH + model_name,\n",
    "               quiet=False)\n",
    "\n",
    "# Unzip images\n",
    "!unzip -q {MAIN_PATH}{model_name} -d {MAIN_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To `Object_detection_image.py`:\n",
    "1. add before last line `cv2.imwrite('/path/to/save/boxed_image.JPG', image)` and comment last line out.\n",
    "1. `NUM_CLASSES`\n",
    "1. `IMAGE_NAME`\n",
    "1. Replace `from utils` with `from object_detection.utils`\n",
    "1. Modify so it draws boxes in all images in `images/test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Image Object Detection Using Tensorflow-trained Classifier #########\r\n",
      "#\r\n",
      "# Author: Evan Juras\r\n",
      "# Date: 1/15/18\r\n",
      "# Description: \r\n",
      "# This program uses a TensorFlow-trained neural network to perform object detection.\r\n",
      "# It loads the classifier and uses it to perform object detection on an image.\r\n",
      "# It draws boxes, scores, and labels around the objects of interest in the image.\r\n",
      "\r\n",
      "## Some of the code is copied from Google's example at\r\n",
      "## https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\r\n",
      "\r\n",
      "## and some is copied from Dat Tran's example at\r\n",
      "## https://github.com/datitran/object_detector_app/blob/master/object_detection_app.py\r\n",
      "\r\n",
      "## but I changed it to make it more understandable to me.\r\n",
      "\r\n",
      "# Import packages\r\n",
      "import os\r\n",
      "import cv2\r\n",
      "import numpy as np\r\n",
      "import tensorflow as tf\r\n",
      "import sys\r\n",
      "\r\n",
      "# This is needed since the notebook is stored in the object_detection folder.\r\n",
      "sys.path.append(\"..\")\r\n",
      "\r\n",
      "# Import utilites\r\n",
      "from object_detection.utils import label_map_util\r\n",
      "from object_detection.utils import visualization_utils as vis_util\r\n",
      "\r\n",
      "# Name of the directory containing the object detection module we're using\r\n",
      "MODEL_NAME = 'inference_graph'\r\n",
      "IMAGE = 'ADE_train_00000615.jpg'\r\n",
      "IMAGE_NAME = 'images/test/' + IMAGE\r\n",
      "\r\n",
      "# Grab path to current working directory\r\n",
      "CWD_PATH = os.getcwd()\r\n",
      "\r\n",
      "# Path to frozen detection graph .pb file, which contains the model that is used\r\n",
      "# for object detection.\r\n",
      "PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,'frozen_inference_graph.pb')\r\n",
      "\r\n",
      "# Path to label map file\r\n",
      "PATH_TO_LABELS = os.path.join(CWD_PATH,'training','labelmap.pbtxt')\r\n",
      "\r\n",
      "# Path to image\r\n",
      "PATH_TO_IMAGE = os.path.join(CWD_PATH,IMAGE_NAME)\r\n",
      "\r\n",
      "# Number of classes the object detector can identify\r\n",
      "NUM_CLASSES = 6\r\n",
      "\r\n",
      "# Load the label map.\r\n",
      "# Label maps map indices to category names, so that when our convolution\r\n",
      "# network predicts `5`, we know that this corresponds to `king`.\r\n",
      "# Here we use internal utility functions, but anything that returns a\r\n",
      "# dictionary mapping integers to appropriate string labels would be fine\r\n",
      "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\r\n",
      "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\r\n",
      "category_index = label_map_util.create_category_index(categories)\r\n",
      "\r\n",
      "# Load the Tensorflow model into memory.\r\n",
      "detection_graph = tf.Graph()\r\n",
      "with detection_graph.as_default():\r\n",
      "    od_graph_def = tf.GraphDef()\r\n",
      "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\r\n",
      "        serialized_graph = fid.read()\r\n",
      "        od_graph_def.ParseFromString(serialized_graph)\r\n",
      "        tf.import_graph_def(od_graph_def, name='')\r\n",
      "\r\n",
      "    sess = tf.Session(graph=detection_graph)\r\n",
      "\r\n",
      "# Define input and output tensors (i.e. data) for the object detection classifier\r\n",
      "\r\n",
      "# Input tensor is the image\r\n",
      "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\r\n",
      "\r\n",
      "# Output tensors are the detection boxes, scores, and classes\r\n",
      "# Each box represents a part of the image where a particular object was detected\r\n",
      "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\r\n",
      "\r\n",
      "# Each score represents level of confidence for each of the objects.\r\n",
      "# The score is shown on the result image, together with the class label.\r\n",
      "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\r\n",
      "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\r\n",
      "\r\n",
      "# Number of objects detected\r\n",
      "num_detections = detection_graph.get_tensor_by_name('num_detections:0')\r\n",
      "\r\n",
      "test_image_path = '/happy-walrus/models/version_2/images/test/'\r\n",
      "for image_name in os.listdir(test_image_path):\r\n",
      "    # Load image using OpenCV and\r\n",
      "    # expand image dimensions to have shape: [1, None, None, 3]\r\n",
      "    # i.e. a single-column array, where each item in the column has the pixel RGB value\r\n",
      "    image = cv2.imread(test_image_path + image_name)\r\n",
      "    image_expanded = np.expand_dims(image, axis=0)\r\n",
      "\r\n",
      "    # Perform the actual detection by running the model with the image as input\r\n",
      "    (boxes, scores, classes, num) = sess.run(\r\n",
      "        [detection_boxes, detection_scores, detection_classes, num_detections],\r\n",
      "        feed_dict={image_tensor: image_expanded})\r\n",
      "\r\n",
      "    # Draw the results of the detection (aka 'visulaize the results')\r\n",
      "    vis_util.visualize_boxes_and_labels_on_image_array(\r\n",
      "        image,\r\n",
      "        np.squeeze(boxes),\r\n",
      "        np.squeeze(classes).astype(np.int32),\r\n",
      "        np.squeeze(scores),\r\n",
      "        category_index,\r\n",
      "        use_normalized_coordinates=True,\r\n",
      "        line_thickness=8,\r\n",
      "        min_score_thresh=0.60)\r\n",
      "\r\n",
      "    cv2.imwrite('/happy-walrus/models/version_2/evaluation/bboxes/' + image_name[:-4] + '_bbox.jpg', image)\r\n",
      "\r\n",
      "# All the results have been drawn on image. Now display the image.\r\n",
      "#print(\"Write successful to \" + IMAGE[:-4] + '_pred.jpg')\r\n",
      "#cv2.imshow('Object detector', image)\r\n",
      "\r\n",
      "# Press any key to close the image\r\n",
      "# cv2.waitKey(0)\r\n",
      "\r\n",
      "# Clean up\r\n",
      "# cv2.destroyAllWindows()\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir {MAIN_PATH}evaluation\n",
    "!mkdir {MAIN_PATH}evaluation/bboxes\n",
    "!cat Object_detection_image.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `NoneType` related error, reinstall opencv with `apt install opencv-python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /models/research/object_detection/utils/label_map_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From Object_detection_image.py:66: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From Object_detection_image.py:72: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2019-11-15 15:32:20.262223: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2019-11-15 15:32:20.262274: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2019-11-15 15:32:20.262312: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (34c587f1c563): /proc/driver/nvidia/version does not exist\n",
      "2019-11-15 15:32:20.262643: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-11-15 15:32:20.271954: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100060000 Hz\n",
      "2019-11-15 15:32:20.273008: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eb06e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2019-11-15 15:32:20.273100: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "/happy-walrus/models/version_2/images/test/grey_kitchen.NM.045.jpg\n",
      "/happy-walrus/models/version_2/images/test/European_kitchen.NM.024.jpg\n",
      "/happy-walrus/models/version_2/images/test/purple_kitchen.EH.017.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010176.jpg\n",
      "/happy-walrus/models/version_2/images/test/blue_kitchen.NM.069.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010390.jpg\n",
      "/happy-walrus/models/version_2/images/test/big_kitchen.NM.032.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.006.jpg\n",
      "/happy-walrus/models/version_2/images/test/Indian_kitchen.NM.035.jpg\n",
      "/happy-walrus/models/version_2/images/test/Indian_kitchen.NM.042.jpg\n",
      "/happy-walrus/models/version_2/images/test/hot_stove.NM.010.jpg\n",
      "/happy-walrus/models/version_2/images/test/clean_kitchen.NM.020.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_clean_kitchen.EH.051.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_messy_kitchen.EH.005.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010587.jpg\n",
      "/happy-walrus/models/version_2/images/test/boiling_water.NM.009.jpg\n",
      "/happy-walrus/models/version_2/images/test/white_kitchen.EH.045.jpg\n",
      "/happy-walrus/models/version_2/images/test/old_kitchen.EH.046.jpg\n",
      "/happy-walrus/models/version_2/images/test/grey_kitchen.NM.005.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010178.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010349.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_cluttered_kitchen.EH.002.jpg\n",
      "/happy-walrus/models/version_2/images/test/gray_kitchen.NM.039.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.039.jpg\n",
      "/happy-walrus/models/version_2/images/test/cluttered_kitchen.NM.008.jpg\n",
      "/happy-walrus/models/version_2/images/test/blue_kitchen.NM.085.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_corners.NM.036.jpg\n",
      "/happy-walrus/models/version_2/images/test/blue_kitchen.NM.067.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_cluttered_kitchen.EH.059.jpg\n",
      "/happy-walrus/models/version_2/images/test/Indian_kitchen.NM.039.jpg\n",
      "/happy-walrus/models/version_2/images/test/small_kitchen.EH.053.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010372.jpg\n",
      "/happy-walrus/models/version_2/images/test/big_kitchen.NM.045.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010389.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.010.jpg\n",
      "/happy-walrus/models/version_2/images/test/American_kitchen.NM.058.jpg\n",
      "/happy-walrus/models/version_2/images/test/hot_stovetop.NM.006.jpg\n",
      "/happy-walrus/models/version_2/images/test/gray_kitchen.NM.069.jpg\n",
      "/happy-walrus/models/version_2/images/test/small_kitchen.EH.037.jpg\n",
      "/happy-walrus/models/version_2/images/test/South_American_kitchen.EH.011.jpg\n",
      "/happy-walrus/models/version_2/images/test/black_kitchen.NM.007.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_apartment.NM.083.jpg\n",
      "/happy-walrus/models/version_2/images/test/clean_kitchen.NM.040.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_messy_kitchen.EH.025.jpg\n",
      "/happy-walrus/models/version_2/images/test/grey_kitchen.NM.071.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010318.jpg\n",
      "/happy-walrus/models/version_2/images/test/old_kitchen.EH.023.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.002.jpg\n",
      "/happy-walrus/models/version_2/images/test/European_kitchen.NM.002.jpg\n",
      "/happy-walrus/models/version_2/images/test/grey_kitchen.NM.028.jpg\n",
      "/happy-walrus/models/version_2/images/test/tiny_kitchen.EH.055.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.048.jpg\n",
      "/happy-walrus/models/version_2/images/test/messy_kitchen.EH.011.jpg\n",
      "/happy-walrus/models/version_2/images/test/cluttered_kitchen.NM.017.jpg\n",
      "/happy-walrus/models/version_2/images/test/European_kitchen.NM.027.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_clean_kitchen.EH.043.jpg\n",
      "/happy-walrus/models/version_2/images/test/boiling_water.NM.002.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010302.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_odd_angle.EH.049.jpg\n",
      "/happy-walrus/models/version_2/images/test/cooking_with_family.NM.018.jpg\n",
      "/happy-walrus/models/version_2/images/test/orange_kitchen.EH.076.jpg\n",
      "/happy-walrus/models/version_2/images/test/tiny_kitchen.EH.081.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.040.jpg\n",
      "/happy-walrus/models/version_2/images/test/grey_kitchen.NM.035.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_messy_kitchen.EH.023.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010407.jpg\n",
      "/happy-walrus/models/version_2/images/test/black_kitchen.NM.023.jpg\n",
      "/happy-walrus/models/version_2/images/test/small_kitchen.EH.024.jpg\n",
      "/happy-walrus/models/version_2/images/test/cluttered_kitchen.NM.030.jpg\n",
      "/happy-walrus/models/version_2/images/test/clean_kitchen.NM.061.jpg\n",
      "/happy-walrus/models/version_2/images/test/blue_kitchen.NM.038.jpg\n",
      "/happy-walrus/models/version_2/images/test/American_kitchen.NM.030.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010720.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010401.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010671.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010553.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.008.jpg\n",
      "/happy-walrus/models/version_2/images/test/cluttered_kitchen.NM.038.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010485.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010497.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010675.jpg\n",
      "/happy-walrus/models/version_2/images/test/purple_kitchen.EH.001.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00000633.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.015.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_corners.NM.029.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_apartment.NM.055.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010703.jpg\n",
      "/happy-walrus/models/version_2/images/test/blue_kitchen.NM.049.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010440.jpg\n",
      "/happy-walrus/models/version_2/images/test/European_kitchen.NM.032.jpg\n",
      "/happy-walrus/models/version_2/images/test/Indian_kitchen.NM.021.jpg\n",
      "/happy-walrus/models/version_2/images/test/grey_kitchen.NM.023.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010432.jpg\n",
      "/happy-walrus/models/version_2/images/test/old_kitchen.EH.020.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_clean_kitchen.EH.004.jpg\n",
      "/happy-walrus/models/version_2/images/test/white_kitchen.EH.040.jpg\n",
      "/happy-walrus/models/version_2/images/test/cluttered_kitchen.NM.040.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/happy-walrus/models/version_2/images/test/ADE_train_00010155.jpg\n",
      "/happy-walrus/models/version_2/images/test/orange_kitchen.EH.055.jpg\n",
      "/happy-walrus/models/version_2/images/test/South_American_kitchen.EH.006.jpg\n",
      "/happy-walrus/models/version_2/images/test/black_kitchen.NM.058.jpg\n",
      "/happy-walrus/models/version_2/images/test/boiling_water.NM.001.jpg\n",
      "/happy-walrus/models/version_2/images/test/Indian_kitchen.NM.007.jpg\n",
      "/happy-walrus/models/version_2/images/test/clean_kitchen.NM.056.jpg\n",
      "/happy-walrus/models/version_2/images/test/old_kitchen.EH.036.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_apartment.NM.004.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_messy_kitchen.EH.011.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010280.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.003.jpg\n",
      "/happy-walrus/models/version_2/images/test/blue_kitchen.NM.063.jpg\n",
      "/happy-walrus/models/version_2/images/test/old_kitchen.EH.004.jpg\n",
      "/happy-walrus/models/version_2/images/test/messy_kitchen.EH.014.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.027.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010472.jpg\n",
      "/happy-walrus/models/version_2/images/test/messy_kitchen.EH.018.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010216.jpg\n",
      "/happy-walrus/models/version_2/images/test/white_kitchen.EH.071.jpg\n",
      "/happy-walrus/models/version_2/images/test/Indian_kitchen.NM.022.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010723.jpg\n",
      "/happy-walrus/models/version_2/images/test/gray_kitchen.NM.024.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.086.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010695.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.066.jpg\n",
      "/happy-walrus/models/version_2/images/test/white_kitchen.EH.077.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010166.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_clean_kitchen.EH.015.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_unsafe.EH.034.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010449.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_unsafe.EH.002.jpg\n",
      "/happy-walrus/models/version_2/images/test/cluttered_kitchen.NM.014.jpg\n",
      "/happy-walrus/models/version_2/images/test/gray_kitchen.NM.068.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_clean_kitchen.EH.029.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_apartment.NM.079.jpg\n",
      "/happy-walrus/models/version_2/images/test/hot_stove.NM.008.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010438.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_cluttered_kitchen.EH.003.jpg\n",
      "/happy-walrus/models/version_2/images/test/blue_kitchen.NM.089.jpg\n",
      "/happy-walrus/models/version_2/images/test/linoleum_kitchen.EH.021.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010550.jpg\n",
      "/happy-walrus/models/version_2/images/test/green_kitchen.NM.045.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010223.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_clean_kitchen.EH.040.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010167.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010399.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.035.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010656.jpg\n",
      "/happy-walrus/models/version_2/images/test/cluttered_kitchen.NM.034.jpg\n",
      "/happy-walrus/models/version_2/images/test/grey_kitchen.NM.050.jpg\n",
      "/happy-walrus/models/version_2/images/test/big_kitchen.NM.060.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_cluttered_kitchen.EH.048.jpg\n",
      "/happy-walrus/models/version_2/images/test/blue_kitchen.NM.045.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010165.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010359.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_messy_kitchen.EH.047.jpg\n",
      "/happy-walrus/models/version_2/images/test/boiling_water.NM.011.jpg\n",
      "/happy-walrus/models/version_2/images/test/old_kitchen.EH.065.jpg\n",
      "/happy-walrus/models/version_2/images/test/linoleum_kitchen.EH.005.jpg\n",
      "/happy-walrus/models/version_2/images/test/linoleum_kitchen.EH.065.jpg\n",
      "/happy-walrus/models/version_2/images/test/white_kitchen.EH.044.jpg\n",
      "/happy-walrus/models/version_2/images/test/orange_kitchen.EH.013.jpg\n",
      "/happy-walrus/models/version_2/images/test/black_kitchen.NM.069.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010701.jpg\n",
      "/happy-walrus/models/version_2/images/test/grey_kitchen.NM.019.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010325.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010586.jpg\n",
      "/happy-walrus/models/version_2/images/test/grey_kitchen.NM.042.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010164.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010524.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.025.jpg\n",
      "/happy-walrus/models/version_2/images/test/gray_kitchen.NM.057.jpg\n",
      "/happy-walrus/models/version_2/images/test/white_kitchen.EH.009.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010554.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010163.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_apartment.NM.081.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010746.jpg\n",
      "/happy-walrus/models/version_2/images/test/American_kitchen.NM.011.jpg\n",
      "/happy-walrus/models/version_2/images/test/old_kitchen.EH.030.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010371.jpg\n",
      "/happy-walrus/models/version_2/images/test/orange_kitchen.EH.064.jpg\n",
      "/happy-walrus/models/version_2/images/test/European_kitchen.NM.066.jpg\n",
      "/happy-walrus/models/version_2/images/test/orange_kitchen.EH.063.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.068.jpg\n",
      "/happy-walrus/models/version_2/images/test/orange_kitchen.EH.066.jpg\n",
      "/happy-walrus/models/version_2/images/test/purple_kitchen.EH.008.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.031.jpg\n",
      "/happy-walrus/models/version_2/images/test/purple_kitchen.EH.012.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_danger.NM.002.jpg\n",
      "/happy-walrus/models/version_2/images/test/red_kitchen.EH.010.jpg\n",
      "/happy-walrus/models/version_2/images/test/clean_kitchen.NM.046.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_cluttered_kitchen.EH.010.jpg\n",
      "/happy-walrus/models/version_2/images/test/linoleum_kitchen.EH.018.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_odd_angle.EH.013.jpg\n",
      "/happy-walrus/models/version_2/images/test/hot_stovetop.NM.015.jpg\n",
      "/happy-walrus/models/version_2/images/test/black_kitchen.NM.029.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_messy_kitchen.EH.048.jpg\n",
      "/happy-walrus/models/version_2/images/test/American_kitchen.NM.046.jpg\n",
      "/happy-walrus/models/version_2/images/test/green_kitchen.NM.049.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010612.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010744.jpg\n",
      "/happy-walrus/models/version_2/images/test/big_kitchen.NM.011.jpg\n",
      "/happy-walrus/models/version_2/images/test/linoleum_kitchen.EH.043.jpg\n",
      "/happy-walrus/models/version_2/images/test/messy_kitchen.EH.046.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_corners.NM.023.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_cluttered_kitchen.EH.013.jpg\n",
      "/happy-walrus/models/version_2/images/test/messy_kitchen.EH.048.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_odd_angle.EH.022.jpg\n",
      "/happy-walrus/models/version_2/images/test/gray_kitchen.NM.005.jpg\n",
      "/happy-walrus/models/version_2/images/test/clean_kitchen.NM.030.jpg\n",
      "/happy-walrus/models/version_2/images/test/American_kitchen.NM.039.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_odd_angle.EH.066.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.057.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_corners.NM.069.jpg\n",
      "/happy-walrus/models/version_2/images/test/clean_kitchen.NM.011.jpg\n",
      "/happy-walrus/models/version_2/images/test/European_kitchen.NM.004.jpg\n",
      "/happy-walrus/models/version_2/images/test/red_kitchen.EH.038.jpg\n",
      "/happy-walrus/models/version_2/images/test/black_kitchen.NM.021.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/happy-walrus/models/version_2/images/test/kitchen_apartment.NM.070.jpg\n",
      "/happy-walrus/models/version_2/images/test/purple_kitchen.EH.009.jpg\n",
      "/happy-walrus/models/version_2/images/test/green_kitchen.NM.012.jpg\n",
      "/happy-walrus/models/version_2/images/test/red_kitchen.EH.015.jpg\n",
      "/happy-walrus/models/version_2/images/test/small_kitchen.EH.060.jpg\n",
      "/happy-walrus/models/version_2/images/test/green_kitchen.NM.029.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010242.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_danger.NM.021.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_cluttered_kitchen.EH.066.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010281.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00000615.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010513.jpg\n",
      "/happy-walrus/models/version_2/images/test/clean_kitchen.NM.062.jpg\n",
      "/happy-walrus/models/version_2/images/test/linoleum_kitchen.EH.056.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010291.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_corners.NM.057.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010638.jpg\n",
      "/happy-walrus/models/version_2/images/test/kitchen_apartment.NM.006.jpg\n",
      "/happy-walrus/models/version_2/images/test/American_kitchen.NM.010.jpg\n",
      "/happy-walrus/models/version_2/images/test/American_kitchen.NM.001.jpg\n",
      "/happy-walrus/models/version_2/images/test/white_kitchen.EH.089.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010283.jpg\n",
      "/happy-walrus/models/version_2/images/test/linoleum_kitchen.EH.045.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010669.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010456.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010654.jpg\n",
      "/happy-walrus/models/version_2/images/test/purple_kitchen.EH.046.jpg\n",
      "/happy-walrus/models/version_2/images/test/black_kitchen.NM.048.jpg\n",
      "/happy-walrus/models/version_2/images/test/cluttered_kitchen.NM.031.jpg\n",
      "/happy-walrus/models/version_2/images/test/blue_kitchen.NM.084.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010560.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010507.jpg\n",
      "/happy-walrus/models/version_2/images/test/large_kitchen.EH.067.jpg\n",
      "/happy-walrus/models/version_2/images/test/blue_kitchen.NM.052.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00000624.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010535.jpg\n",
      "/happy-walrus/models/version_2/images/test/pintrest_clean_kitchen.EH.041.jpg\n",
      "/happy-walrus/models/version_2/images/test/white_kitchen.EH.057.jpg\n",
      "/happy-walrus/models/version_2/images/test/purple_kitchen.EH.037.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010662.jpg\n",
      "/happy-walrus/models/version_2/images/test/tiny_kitchen.EH.074.jpg\n",
      "/happy-walrus/models/version_2/images/test/orange_kitchen.EH.035.jpg\n",
      "/happy-walrus/models/version_2/images/test/black_kitchen.NM.004.jpg\n",
      "/happy-walrus/models/version_2/images/test/ADE_train_00010233.jpg\n"
     ]
    }
   ],
   "source": [
    "!python Object_detection_image.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -rq {MAIN_PATH}evaluation/bboxes.zip {MAIN_PATH}evaluation/bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make inferences on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:96: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:57: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W1118 13:50:23.764707 139830553470784 module_wrapper.py:139] From /models/research/object_detection/inference/infer_detections.py:57: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:57: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W1118 13:50:23.764940 139830553470784 module_wrapper.py:139] From /models/research/object_detection/inference/infer_detections.py:57: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W1118 13:50:23.765128 139830553470784 module_wrapper.py:139] From /models/research/object_detection/inference/infer_detections.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2019-11-18 13:50:23.772627: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2019-11-18 13:50:23.773696: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2019-11-18 13:50:23.773756: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (34c587f1c563): /proc/driver/nvidia/version does not exist\n",
      "2019-11-18 13:50:23.775624: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-11-18 13:50:23.811597: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100060000 Hz\n",
      "2019-11-18 13:50:23.813423: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x41e5d10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2019-11-18 13:50:23.813463: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:68: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W1118 13:50:23.819413 139830553470784 module_wrapper.py:139] From /models/research/object_detection/inference/infer_detections.py:68: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Reading input from 1 files\n",
      "I1118 13:50:23.819670 139830553470784 infer_detections.py:68] Reading input from 1 files\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/detection_inference.py:35: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W1118 13:50:23.820460 139830553470784 deprecation.py:323] From /models/research/object_detection/inference/detection_inference.py:35: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W1118 13:50:23.831863 139830553470784 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "W1118 13:50:23.832153 139830553470784 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:112: RefVariable.count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "W1118 13:50:23.835536 139830553470784 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:112: RefVariable.count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py:2522: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "W1118 13:50:23.835732 139830553470784 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py:2522: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W1118 13:50:23.838823 139830553470784 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W1118 13:50:23.839978 139830553470784 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/detection_inference.py:37: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "W1118 13:50:23.844439 139830553470784 deprecation.py:323] From /models/research/object_detection/inference/detection_inference.py:37: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/detection_inference.py:39: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "W1118 13:50:23.845769 139830553470784 module_wrapper.py:139] From /models/research/object_detection/inference/detection_inference.py:39: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/detection_inference.py:43: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "W1118 13:50:23.845969 139830553470784 module_wrapper.py:139] From /models/research/object_detection/inference/detection_inference.py:43: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading graph and building model...\n",
      "I1118 13:50:23.904574 139830553470784 infer_detections.py:71] Reading graph and building model...\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/detection_inference.py:68: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1118 13:50:23.904937 139830553470784 module_wrapper.py:139] From /models/research/object_detection/inference/detection_inference.py:68: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/detection_inference.py:70: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "W1118 13:50:24.173730 139830553470784 module_wrapper.py:139] From /models/research/object_detection/inference/detection_inference.py:70: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/detection_inference.py:76: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1118 13:50:24.933823 139830553470784 module_wrapper.py:139] From /models/research/object_detection/inference/detection_inference.py:76: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "INFO:tensorflow:Running inference and writing output to /happy-walrus/models/version_2/evaluation/test_detections.tfrecord-00000-of-00001\n",
      "I1118 13:50:24.956939 139830553470784 infer_detections.py:77] Running inference and writing output to /happy-walrus/models/version_2/evaluation/test_detections.tfrecord-00000-of-00001\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:78: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "W1118 13:50:24.957295 139830553470784 module_wrapper.py:139] From /models/research/object_detection/inference/infer_detections.py:78: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:79: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W1118 13:50:25.142910 139830553470784 deprecation.py:323] From /models/research/object_detection/inference/infer_detections.py:79: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:80: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W1118 13:50:25.143958 139830553470784 module_wrapper.py:139] From /models/research/object_detection/inference/infer_detections.py:80: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:84: The name tf.logging.log_every_n is deprecated. Please use tf.compat.v1.logging.log_every_n instead.\n",
      "\n",
      "W1118 13:50:25.145396 139830553470784 module_wrapper.py:139] From /models/research/object_detection/inference/infer_detections.py:84: The name tf.logging.log_every_n is deprecated. Please use tf.compat.v1.logging.log_every_n instead.\n",
      "\n",
      "INFO:tensorflow:Processed 0 images...\n",
      "I1118 13:50:25.145572 139830553470784 infer_detections.py:85] Processed 0 images...\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/detection_inference.py:117: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1118 13:50:25.145796 139830553470784 module_wrapper.py:139] From /models/research/object_detection/inference/detection_inference.py:117: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "INFO:tensorflow:Processed 10 images...\n",
      "I1118 13:50:30.137920 139830553470784 infer_detections.py:85] Processed 10 images...\n",
      "INFO:tensorflow:Processed 20 images...\n",
      "I1118 13:50:33.531545 139830553470784 infer_detections.py:85] Processed 20 images...\n",
      "INFO:tensorflow:Processed 30 images...\n",
      "I1118 13:50:37.803325 139830553470784 infer_detections.py:85] Processed 30 images...\n",
      "INFO:tensorflow:Processed 40 images...\n",
      "I1118 13:50:41.588816 139830553470784 infer_detections.py:85] Processed 40 images...\n",
      "INFO:tensorflow:Processed 50 images...\n",
      "I1118 13:50:44.899022 139830553470784 infer_detections.py:85] Processed 50 images...\n",
      "INFO:tensorflow:Processed 60 images...\n",
      "I1118 13:50:48.156816 139830553470784 infer_detections.py:85] Processed 60 images...\n",
      "INFO:tensorflow:Processed 70 images...\n",
      "I1118 13:50:51.659800 139830553470784 infer_detections.py:85] Processed 70 images...\n",
      "INFO:tensorflow:Processed 80 images...\n",
      "I1118 13:50:56.167850 139830553470784 infer_detections.py:85] Processed 80 images...\n",
      "INFO:tensorflow:Processed 90 images...\n",
      "I1118 13:50:59.737706 139830553470784 infer_detections.py:85] Processed 90 images...\n",
      "INFO:tensorflow:Processed 100 images...\n",
      "I1118 13:51:03.350040 139830553470784 infer_detections.py:85] Processed 100 images...\n",
      "INFO:tensorflow:Processed 110 images...\n",
      "I1118 13:51:07.041298 139830553470784 infer_detections.py:85] Processed 110 images...\n",
      "INFO:tensorflow:Processed 120 images...\n",
      "I1118 13:51:10.573014 139830553470784 infer_detections.py:85] Processed 120 images...\n",
      "INFO:tensorflow:Processed 130 images...\n",
      "I1118 13:51:14.112915 139830553470784 infer_detections.py:85] Processed 130 images...\n",
      "INFO:tensorflow:Processed 140 images...\n",
      "I1118 13:51:18.155474 139830553470784 infer_detections.py:85] Processed 140 images...\n",
      "INFO:tensorflow:Processed 150 images...\n",
      "I1118 13:51:22.243628 139830553470784 infer_detections.py:85] Processed 150 images...\n",
      "INFO:tensorflow:Processed 160 images...\n",
      "I1118 13:51:25.687313 139830553470784 infer_detections.py:85] Processed 160 images...\n",
      "INFO:tensorflow:Processed 170 images...\n",
      "I1118 13:51:29.185622 139830553470784 infer_detections.py:85] Processed 170 images...\n",
      "INFO:tensorflow:Processed 180 images...\n",
      "I1118 13:51:32.713480 139830553470784 infer_detections.py:85] Processed 180 images...\n",
      "INFO:tensorflow:Processed 190 images...\n",
      "I1118 13:51:36.179323 139830553470784 infer_detections.py:85] Processed 190 images...\n",
      "INFO:tensorflow:Processed 200 images...\n",
      "I1118 13:51:39.997983 139830553470784 infer_detections.py:85] Processed 200 images...\n",
      "INFO:tensorflow:Processed 210 images...\n",
      "I1118 13:51:44.049988 139830553470784 infer_detections.py:85] Processed 210 images...\n",
      "INFO:tensorflow:Processed 220 images...\n",
      "I1118 13:51:47.821661 139830553470784 infer_detections.py:85] Processed 220 images...\n",
      "INFO:tensorflow:Processed 230 images...\n",
      "I1118 13:51:51.344117 139830553470784 infer_detections.py:85] Processed 230 images...\n",
      "INFO:tensorflow:Processed 240 images...\n",
      "I1118 13:51:54.966508 139830553470784 infer_detections.py:85] Processed 240 images...\n",
      "INFO:tensorflow:Finished processing records\n",
      "I1118 13:51:55.362439 139830553470784 infer_detections.py:92] Finished processing records\n"
     ]
    }
   ],
   "source": [
    "!python {OD_PATH}inference/infer_detections.py \\\n",
    "  --input_tfrecord_paths={MAIN_PATH}test.record \\\n",
    "  --output_tfrecord_path={MAIN_PATH}evaluation/test_detections.tfrecord-00000-of-00001 \\\n",
    "  --inference_graph=inference_graph/frozen_inference_graph.pb \\\n",
    "  --discard_image_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate performance metrics.\n",
    "\n",
    "There are two documented bugs, solved implementing [this solution](https://github.com/tensorflow/models/issues/3252#issuecomment-363669586) and [this one](https://github.com/tensorflow/models/issues/5924#issuecomment-455081147)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:46: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:46: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:172: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/utils/config_util.py:236: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1118 14:24:09.172274 140053258450752 module_wrapper.py:139] From /models/research/object_detection/utils/config_util.py:236: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:105: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W1118 14:24:09.174613 140053258450752 module_wrapper.py:139] From /models/research/object_detection/metrics/offline_eval_map_corloc.py:105: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Processing file: /happy-walrus/models/version_2/evaluation/test_detections.tfrecord-00000-of-00001\n",
      "I1118 14:24:09.174754 140053258450752 offline_eval_map_corloc.py:105] Processing file: /happy-walrus/models/version_2/evaluation/test_detections.tfrecord-00000-of-00001\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:107: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "W1118 14:24:09.174928 140053258450752 deprecation.py:323] From /models/research/object_detection/metrics/offline_eval_map_corloc.py:107: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:111: The name tf.logging.log_every_n is deprecated. Please use tf.compat.v1.logging.log_every_n instead.\n",
      "\n",
      "W1118 14:24:09.186391 140053258450752 module_wrapper.py:139] From /models/research/object_detection/metrics/offline_eval_map_corloc.py:111: The name tf.logging.log_every_n is deprecated. Please use tf.compat.v1.logging.log_every_n instead.\n",
      "\n",
      "INFO:tensorflow:Processed 0 images...\n",
      "I1118 14:24:09.186633 140053258450752 offline_eval_map_corloc.py:112] Processed 0 images...\n",
      "W1118 14:24:10.415138 140053258450752 object_detection_evaluation.py:1279] The following classes have no ground truth examples: 2\n",
      "I1118 14:24:10.479942 140053258450752 object_detection_evaluation.py:1311] average_precision: 0.654881\n",
      "I1118 14:24:10.535117 140053258450752 object_detection_evaluation.py:1311] average_precision: 0.650271\n",
      "I1118 14:24:10.566178 140053258450752 object_detection_evaluation.py:1311] average_precision: 0.134850\n",
      "I1118 14:24:10.604791 140053258450752 object_detection_evaluation.py:1311] average_precision: 0.633716\n",
      "I1118 14:24:10.652964 140053258450752 object_detection_evaluation.py:1311] average_precision: 0.647660\n",
      "/models/research/object_detection/utils/metrics.py:145: RuntimeWarning: invalid value encountered in true_divide\n",
      "  num_images_correctly_detected_per_class / num_gt_imgs_per_class)\n",
      "INFO:tensorflow:Writing metrics.\n",
      "I1118 14:24:10.655718 140053258450752 offline_eval_map_corloc.py:142] Writing metrics.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "NUM_SHARDS=1  # Set to NUM_GPUS if using the parallel evaluation script\n",
    "MAIN_PATH='/happy-walrus/models/version_2/'\n",
    "OD_PATH='/models/research/object_detection/'\n",
    "EVAL_PATH=${MAIN_PATH}evaluation/eval_metrics/\n",
    "# Choose metrics set from:\n",
    "#   - coco_detection_metrics (multiple IoUs)\n",
    "#   - pascal_voc_detection_metrics (per-class)\n",
    "METRICS_SET='pascal_voc_detection_metrics'\n",
    "mkdir -p ${EVAL_PATH}\n",
    "\n",
    "echo \"\n",
    "label_map_path: '/happy-walrus/models/version_2/training/labelmap.pbtxt'\n",
    "tf_record_input_reader: { input_path: '${MAIN_PATH}evaluation/test_detections.tfrecord-00000-of-00001' }\n",
    "\" > ${EVAL_PATH}test_input_config.pbtxt\n",
    "\n",
    "echo \"\n",
    "metrics_set: '${METRICS_SET}'\n",
    "\" > ${EVAL_PATH}test_eval_config.pbtxt\n",
    "\n",
    "python ${OD_PATH}metrics/offline_eval_map_corloc.py \\\n",
    "  --eval_dir=${EVAL_PATH} \\\n",
    "  --eval_config_path=${EVAL_PATH}test_eval_config.pbtxt \\\n",
    "  --input_config_path=${EVAL_PATH}test_input_config.pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DetectionBoxes_Precision/mAP          0.31392875975852935 \r\n",
      "DetectionBoxes_Precision/mAP@.50IOU   0.5431423014254178  \r\n",
      "DetectionBoxes_Precision/mAP@.75IOU   0.3087452707782113  \r\n",
      "DetectionBoxes_Precision/mAP (small)  0.31392875975852935 \r\n",
      "DetectionBoxes_Precision/mAP (medium) -1.0                \r\n",
      "DetectionBoxes_Precision/mAP (large)  -1.0                \r\n",
      "DetectionBoxes_Recall/AR@1            0.27402896013998307 \r\n",
      "DetectionBoxes_Recall/AR@10           0.48290137295288305 \r\n",
      "DetectionBoxes_Recall/AR@100          0.517659932752087   \r\n",
      "DetectionBoxes_Recall/AR@100 (small)  0.517659932752087   \r\n",
      "DetectionBoxes_Recall/AR@100 (medium) -1.0                \r\n",
      "DetectionBoxes_Recall/AR@100 (large)  -1.0                \r\n"
     ]
    }
   ],
   "source": [
    "# coco_detection_metrics\n",
    "!csvtool readable ${MAIN_PATH_PATH}evaluation/eval_metrics/metrics.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PascalBoxes_Precision/mAP@0.5IOU                   0.5442753965441911  \r\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/chair  0.6548812202456822  \r\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/ladder nan                 \r\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/oven   0.6502705901868502  \r\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/sofa   0.13484967233324116 \r\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/stool  0.6337156623730517  \r\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/stove  0.6476598375821305  \r\n"
     ]
    }
   ],
   "source": [
    "# pascal_voc_detection_metrics\n",
    "!csvtool readable ${MAIN_PATH_PATH}evaluation/eval_metrics/metrics.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [State of the Art Object Detection - Medium](https://medium.com/@lessw/state-of-the-art-object-detection-use-these-top-3-data-augmentations-and-google-brains-optimal-57ac6d8d1de5)\n",
    "- [Learning Data Augmentation Strategies for Object Detection](https://arxiv.org/abs/1906.11172v1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
