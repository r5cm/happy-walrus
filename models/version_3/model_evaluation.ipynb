{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kitchen training - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T23:07:01.942493Z",
     "start_time": "2019-11-29T23:07:01.936518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autoaugm_inceptionv2'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "OD_PATH = '/models/research/object_detection/'\n",
    "MAIN_PATH = '/happy-walrus/models/version_3/'\n",
    "IMG_PATH = MAIN_PATH + 'images/'\n",
    "models = [('autoaugm_inceptionv2', '1gG7Dqc8JaMRFHP3AqNjolQvAmo3r2zU9'),\n",
    "          ('autoaugm_resnet101', '1mOFlc9bKvSxnvw6mLycw0zCZtcTXYNka'),\n",
    "          ('autoaugm_inception_resnet_v2_atrous_coco', '1iHtbPNe0RoC3xikPcl8fPYAPT24Dkedo'),\n",
    "          ('autoaugm_inception_resnet_v2_atrous_oidv4', '1FcdeeS0NIV5rp7u74g2Q2kRMyya69gC6'),\n",
    "          ('autoaugm_nas', \"1ATOn9BSG5yuQLMWXxAG7yFEStCQ3Zqlk\"),\n",
    "          ('custaugm_resnet101', '1M47cRP4MM8bcN-M-PXgtErwEv-o_2dfR'),\n",
    "          ('custaugm_inceptionv2', '1ASKFSkd7x4TvVtG1K6FvliK3hxOh_9-m'),\n",
    "          ('custaugm_inception_resnet_v2_atrous_coco', \"\"),\n",
    "          ('hflip_resnet101', '1zRwvrrvo5y1Smig929NqtnHSWcjZuN_1'),\n",
    "          ('noaugm_resnet101', '1IYQ039nMl4JiAiVAxfuvghgpm079rbdL')]\n",
    "model = 0\n",
    "MODEL_NAME = models[model][0]\n",
    "TRAIN_PATH = MAIN_PATH + 'training/' + MODEL_NAME\n",
    "EVAL_PATH = MAIN_PATH + 'evaluation/' + MODEL_NAME\n",
    "GRAPH_PATH = MAIN_PATH + 'inference_graph/' + MODEL_NAME\n",
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/happy-walrus/models/version_3/training/autoaugm_inceptionv2'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1M47cRP4MM8bcN-M-PXgtErwEv-o_2dfR\n",
      "To: /happy-walrus/models/version_3/training/custaugm_resnet101.zip\n",
      "2.09GB [00:35, 59.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2482012\r\n",
      "-rw-r--r-- 1 root root       637 Nov 28 22:45 checkpoint\r\n",
      "-rw-r--r-- 1 root root      4423 Nov 28 13:58 custaugm_resnet101.config\r\n",
      "-rw-r--r-- 1 root root 287547946 Nov 28 22:45 events.out.tfevents.1574949597.a7092b78c30e\r\n",
      "-rw-r--r-- 1 root root  15509908 Nov 28 13:59 graph.pbtxt\r\n",
      "-rw-r--r-- 1 root root 439256032 Nov 28 22:09 model.ckpt-186589.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root     40513 Nov 28 22:09 model.ckpt-186589.index\r\n",
      "-rw-r--r-- 1 root root   8392927 Nov 28 22:09 model.ckpt-186589.meta\r\n",
      "-rw-r--r-- 1 root root 439256032 Nov 28 22:19 model.ckpt-190389.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root     40513 Nov 28 22:19 model.ckpt-190389.index\r\n",
      "-rw-r--r-- 1 root root   8392927 Nov 28 22:19 model.ckpt-190389.meta\r\n",
      "-rw-r--r-- 1 root root 439256032 Nov 28 22:29 model.ckpt-194193.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root     40513 Nov 28 22:29 model.ckpt-194193.index\r\n",
      "-rw-r--r-- 1 root root   8392927 Nov 28 22:29 model.ckpt-194193.meta\r\n",
      "-rw-r--r-- 1 root root 439256032 Nov 28 22:39 model.ckpt-197993.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root     40513 Nov 28 22:39 model.ckpt-197993.index\r\n",
      "-rw-r--r-- 1 root root   8392927 Nov 28 22:39 model.ckpt-197993.meta\r\n",
      "-rw-r--r-- 1 root root 439256032 Nov 28 22:45 model.ckpt-200000.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root     40513 Nov 28 22:45 model.ckpt-200000.index\r\n",
      "-rw-r--r-- 1 root root   8392927 Nov 28 22:45 model.ckpt-200000.meta\r\n",
      "-rw-r--r-- 1 root root      4423 Nov 28 13:59 pipeline.config\r\n"
     ]
    }
   ],
   "source": [
    "idx = models[model][1]\n",
    "output = TRAIN_PATH + '.zip'\n",
    "gdown.download(url=\"https://drive.google.com/uc?id=\" + idx,\n",
    "               output=output,\n",
    "               quiet=False)\n",
    "!unzip -o -q {output} -d {MAIN_PATH}training\n",
    "!ls -l {TRAIN_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/happy-walrus/models/version_3/inference_graph/custaugm_resnet101'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRAPH_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-30T00:24:08.468Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1204 19:11:15.987506 139831682508608 module_wrapper.py:139] From /models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:389: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W1204 19:11:15.996249 139831682508608 module_wrapper.py:139] From /models/research/object_detection/exporter.py:389: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1204 19:11:15.996796 139831682508608 module_wrapper.py:139] From /models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "W1204 19:11:16.056044 139831682508608 module_wrapper.py:139] From /models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:166: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W1204 19:11:16.121246 139831682508608 module_wrapper.py:139] From /models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:166: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1204 19:11:16.132828 139831682508608 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W1204 19:11:16.135815 139831682508608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "W1204 19:11:20.350662 139831682508608 module_wrapper.py:139] From /models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1204 19:11:20.359806 139831682508608 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:556: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "W1204 19:11:20.360244 139831682508608 module_wrapper.py:139] From /models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:556: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1204 19:11:20.379088 139831682508608 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W1204 19:11:20.379618 139831682508608 module_wrapper.py:139] From /models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I1204 19:11:20.379771 139831682508608 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /models/research/object_detection/core/box_list_ops.py:141: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1204 19:11:20.453316 139831682508608 deprecation.py:323] From /models/research/object_detection/core/box_list_ops.py:141: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W1204 19:11:21.203206 139831682508608 deprecation.py:506] From /models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:189: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W1204 19:11:21.227987 139831682508608 module_wrapper.py:139] From /models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:189: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1204 19:11:21.228457 139831682508608 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W1204 19:11:21.606455 139831682508608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1204 19:11:21.613568 139831682508608 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1204 19:11:21.640095 139831682508608 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
      "W1204 19:11:22.942110 139831682508608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "I1204 19:11:23.105907 139831682508608 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:268: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W1204 19:11:23.270038 139831682508608 module_wrapper.py:139] From /models/research/object_detection/exporter.py:268: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:370: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "W1204 19:11:23.270376 139831682508608 deprecation.py:323] From /models/research/object_detection/exporter.py:370: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:402: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1204 19:11:23.274861 139831682508608 module_wrapper.py:139] From /models/research/object_detection/exporter.py:402: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:526: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "W1204 19:11:23.275071 139831682508608 deprecation.py:323] From /models/research/object_detection/exporter.py:526: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "W1204 19:11:23.276726 139831682508608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "272 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "Incomplete shape.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              0\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   name\n",
      "-account_type_regexes       _trainable_variables\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     params\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Incomplete shape.\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "param: Number of parameters (in the Variable).\n",
      "\n",
      "Profile:\n",
      "node name | # parameters\n",
      "_TFProfRoot (--/62.20m params)\n",
      "  Conv (--/4.72m params)\n",
      "    Conv/biases (512, 512/512 params)\n",
      "    Conv/weights (3x3x1024x512, 4.72m/4.72m params)\n",
      "  FirstStageBoxPredictor (--/36.94k params)\n",
      "    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n",
      "      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n",
      "      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n",
      "    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n",
      "      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n",
      "      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
      "  FirstStageFeatureExtractor (--/42.39m params)\n",
      "    FirstStageFeatureExtractor/resnet_v1_101 (--/42.39m params)\n",
      "      FirstStageFeatureExtractor/resnet_v1_101/block1 (--/212.99k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1 (--/73.73k params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1 (--/73.73k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1 (--/4.10k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/weights (1x1x64x64, 4.10k/4.10k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2 (--/36.86k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3 (--/16.38k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut (--/16.38k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/weights (1x1x64x256, 16.38k/16.38k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2 (--/69.63k params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1 (--/69.63k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1 (--/16.38k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2 (--/36.86k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3 (--/16.38k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3 (--/69.63k params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1 (--/69.63k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1 (--/16.38k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2 (--/36.86k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3 (--/16.38k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n",
      "      FirstStageFeatureExtractor/resnet_v1_101/block2 (--/1.21m params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1 (--/376.83k params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1 (--/376.83k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1 (--/32.77k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/weights (1x1x256x128, 32.77k/32.77k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2 (--/147.46k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3 (--/65.54k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut (--/131.07k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/weights (1x1x256x512, 131.07k/131.07k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2 (--/278.53k params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1 (--/278.53k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1 (--/65.54k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2 (--/147.46k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3 (--/65.54k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3 (--/278.53k params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1 (--/278.53k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1 (--/65.54k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2 (--/147.46k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3 (--/65.54k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4 (--/278.53k params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1 (--/278.53k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1 (--/65.54k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2 (--/147.46k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3 (--/65.54k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
      "      FirstStageFeatureExtractor/resnet_v1_101/block3 (--/26.02m params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1 (--/1.51m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1 (--/1.51m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1 (--/131.07k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/weights (1x1x512x256, 131.07k/131.07k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut (--/524.29k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/weights (1x1x512x1024, 524.29k/524.29k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9 (--/1.11m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1 (--/1.11m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2 (--/589.82k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3 (--/262.14k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
      "      FirstStageFeatureExtractor/resnet_v1_101/block4 (--/14.94m params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1 (--/6.03m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1 (--/6.03m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1 (--/524.29k params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights (1x1x1024x512, 524.29k/524.29k params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2 (--/2.36m params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3 (--/1.05m params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut (--/2.10m params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights (1x1x1024x2048, 2.10m/2.10m params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2 (--/4.46m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1 (--/4.46m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1 (--/1.05m params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2 (--/2.36m params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3 (--/1.05m params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3 (--/4.46m params)\n",
      "          FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1 (--/4.46m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1 (--/1.05m params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2 (--/2.36m params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
      "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3 (--/1.05m params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
      "      FirstStageFeatureExtractor/resnet_v1_101/conv1 (--/9.41k params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/conv1/BatchNorm (--/0 params)\n",
      "        FirstStageFeatureExtractor/resnet_v1_101/conv1/weights (7x7x3x64, 9.41k/9.41k params)\n",
      "  SecondStageBoxPredictor (--/104.50k params)\n",
      "    SecondStageBoxPredictor/BoxEncodingPredictor (--/81.96k params)\n",
      "      SecondStageBoxPredictor/BoxEncodingPredictor/biases (40, 40/40 params)\n",
      "      SecondStageBoxPredictor/BoxEncodingPredictor/weights (2048x40, 81.92k/81.92k params)\n",
      "    SecondStageBoxPredictor/ClassPredictor (--/22.54k params)\n",
      "      SecondStageBoxPredictor/ClassPredictor/biases (11, 11/11 params)\n",
      "      SecondStageBoxPredictor/ClassPredictor/weights (2048x11, 22.53k/22.53k params)\n",
      "  SecondStageFeatureExtractor (--/14.94m params)\n",
      "    SecondStageFeatureExtractor/resnet_v1_101 (--/14.94m params)\n",
      "      SecondStageFeatureExtractor/resnet_v1_101/block4 (--/14.94m params)\n",
      "        SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1 (--/6.03m params)\n",
      "          SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1 (--/6.03m params)\n",
      "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1 (--/524.29k params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights (1x1x1024x512, 524.29k/524.29k params)\n",
      "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2 (--/2.36m params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
      "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3 (--/1.05m params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
      "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut (--/2.10m params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights (1x1x1024x2048, 2.10m/2.10m params)\n",
      "        SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2 (--/4.46m params)\n",
      "          SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1 (--/4.46m params)\n",
      "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1 (--/1.05m params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
      "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2 (--/2.36m params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
      "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3 (--/1.05m params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
      "        SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3 (--/4.46m params)\n",
      "          SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1 (--/4.46m params)\n",
      "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1 (--/1.05m params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
      "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2 (--/2.36m params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
      "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3 (--/1.05m params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
      "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "Incomplete shape.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Incomplete shape.\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/6.20k flops)\n",
      "  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_3 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_2 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_1 (300/300 flops)\n",
      "  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
      "  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
      "  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_2 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_3 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_1 (300/300 flops)\n",
      "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum (300/300 flops)\n",
      "  map_2/while/mul_3 (300/300 flops)\n",
      "  map_2/while/mul (300/300 flops)\n",
      "  map_2/while/mul_1 (300/300 flops)\n",
      "  map_2/while/mul_2 (300/300 flops)\n",
      "  GridAnchorGenerator/mul (12/12 flops)\n",
      "  GridAnchorGenerator/truediv (12/12 flops)\n",
      "  GridAnchorGenerator/mul_1 (12/12 flops)\n",
      "  GridAnchorGenerator/mul_2 (12/12 flops)\n",
      "  FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/required_space_to_batch_paddings/sub (2/2 flops)\n",
      "  FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/required_space_to_batch_paddings/sub (2/2 flops)\n",
      "  FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/required_space_to_batch_paddings/sub (2/2 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_12 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_13 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_14 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_15 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_16 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_17 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_18 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_19 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_8 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_9 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
      "  mul (1/1 flops)\n",
      "  map_2/while/Less_1 (1/1 flops)\n",
      "  map_2/while/Less (1/1 flops)\n",
      "  map_1/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
      "  map_1/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
      "  map_1/while/Less_1 (1/1 flops)\n",
      "  map_1/while/Less (1/1 flops)\n",
      "  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
      "  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
      "  map/while/Less_1 (1/1 flops)\n",
      "  map/while/Less (1/1 flops)\n",
      "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
      "  SecondStagePostprocessor/map/while/Less_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/map/while/Less (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
      "  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n",
      "  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n",
      "  GridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
      "  GridAnchorGenerator/mul_7 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
      "  GridAnchorGenerator/mul_8 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_5 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_10 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_6 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_7 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_8 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_9 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
      "  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_10 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/Minimum (1/1 flops)\n",
      "  GridAnchorGenerator/zeros/Less (1/1 flops)\n",
      "  Preprocessor/map/while/Less (1/1 flops)\n",
      "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/Less (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/Minimum (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/mul (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/mul_1 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv_1 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_11 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul_1 (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv (1/1 flops)\n",
      "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv_1 (1/1 flops)\n",
      "  SecondStageDetectionFeaturesExtract/mul (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchGather/mul (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchGather/mul_2 (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
      "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:419: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W1204 19:11:26.134160 139831682508608 module_wrapper.py:139] From /models/research/object_detection/exporter.py:419: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:332: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W1204 19:11:28.062931 139831682508608 module_wrapper.py:139] From /models/research/object_detection/exporter.py:332: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2019-12-04 19:11:28.063528: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2019-12-04 19:11:28.063575: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2019-12-04 19:11:28.063611: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (5df86dfc3c25): /proc/driver/nvidia/version does not exist\n",
      "2019-12-04 19:11:28.063922: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-04 19:11:28.073972: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100060000 Hz\n",
      "2019-12-04 19:11:28.074964: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x995a500 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2019-12-04 19:11:28.075003: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "INFO:tensorflow:Restoring parameters from /happy-walrus/models/version_3/training/custaugm_resnet101/model.ckpt-200000\n",
      "I1204 19:11:28.079627 139831682508608 saver.py:1284] Restoring parameters from /happy-walrus/models/version_3/training/custaugm_resnet101/model.ckpt-200000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W1204 19:11:31.350493 139831682508608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /happy-walrus/models/version_3/training/custaugm_resnet101/model.ckpt-200000\n",
      "I1204 19:11:32.891867 139831682508608 saver.py:1284] Restoring parameters from /happy-walrus/models/version_3/training/custaugm_resnet101/model.ckpt-200000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "W1204 19:11:34.974846 139831682508608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "W1204 19:11:34.975144 139831682508608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 530 variables.\n",
      "I1204 19:11:35.988533 139831682508608 graph_util_impl.py:334] Froze 530 variables.\n",
      "INFO:tensorflow:Converted 530 variables to const ops.\n",
      "I1204 19:11:36.359253 139831682508608 graph_util_impl.py:394] Converted 530 variables to const ops.\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:296: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
      "\n",
      "W1204 19:11:38.408155 139831682508608 module_wrapper.py:139] From /models/research/object_detection/exporter.py:296: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:299: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W1204 19:11:38.408708 139831682508608 deprecation.py:323] From /models/research/object_detection/exporter.py:299: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:305: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
      "\n",
      "W1204 19:11:38.409350 139831682508608 module_wrapper.py:139] From /models/research/object_detection/exporter.py:305: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:308: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
      "\n",
      "W1204 19:11:38.409587 139831682508608 module_wrapper.py:139] From /models/research/object_detection/exporter.py:308: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:313: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
      "\n",
      "W1204 19:11:38.409903 139831682508608 module_wrapper.py:139] From /models/research/object_detection/exporter.py:313: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\n",
      "W1204 19:11:38.410082 139831682508608 module_wrapper.py:139] From /models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\n",
      "INFO:tensorflow:No assets to save.\n",
      "I1204 19:11:38.410431 139831682508608 builder_impl.py:640] No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "I1204 19:11:38.410548 139831682508608 builder_impl.py:460] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: /happy-walrus/models/version_3/inference_graph/custaugm_resnet101/saved_model/saved_model.pb\n",
      "I1204 19:11:39.789202 139831682508608 builder_impl.py:425] SavedModel written to: /happy-walrus/models/version_3/inference_graph/custaugm_resnet101/saved_model/saved_model.pb\n",
      "WARNING:tensorflow:From /models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1204 19:11:39.854399 139831682508608 module_wrapper.py:139] From /models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "INFO:tensorflow:Writing pipeline config file to /happy-walrus/models/version_3/inference_graph/custaugm_resnet101/pipeline.config\n",
      "I1204 19:11:39.854672 139831682508608 config_util.py:190] Writing pipeline config file to /happy-walrus/models/version_3/inference_graph/custaugm_resnet101/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "checkpoint = 200000\n",
    "!python {OD_PATH}export_inference_graph.py \\\n",
    "    --input_type image_tensor \\\n",
    "    --pipeline_config_path {TRAIN_PATH}/{MODEL_NAME}.config \\\n",
    "    --trained_checkpoint_prefix {TRAIN_PATH}/model.ckpt-{checkpoint} \\\n",
    "    --output_directory {GRAPH_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download model and store it in Google Drive for use in next section (not necessary if model is already in disk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_name = GRAPH_PATH + MODEL_NAME[:-1] + '.zip'\n",
    "!zip -qr {zip_name} {GRAPH_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download model (only if model is not on disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T12:06:30.407521Z",
     "start_time": "2019-11-07T12:06:29.516282Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1JVFhXqaayxWOIhuQdzmjIMBAHrAhLcEQ\n",
      "To: /happy-walrus/models/version_2/inference_graph.zip\n",
      "144MB [00:01, 74.9MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Download model\n",
    "model_id = \"1JVFhXqaayxWOIhuQdzmjIMBAHrAhLcEQ\"\n",
    "model_name = \"inference_graph.zip\"\n",
    "gdown.download(url=\"https://drive.google.com/uc?id=\" + model_id,\n",
    "               output=MAIN_PATH + model_name,\n",
    "               quiet=False)\n",
    "\n",
    "# Unzip model\n",
    "!unzip -q {MAIN_PATH}{model_name} -d {MAIN_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To `Object_detection_image.py`:\n",
    "- Update `MODEL_NAME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custaugm_resnet101'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/happy-walrus/models/version_3/evaluation/custaugm_resnet101’: File exists\n",
      "mkdir: cannot create directory ‘/happy-walrus/models/version_3/evaluation/custaugm_resnet101/bboxes’: File exists\n",
      "######## Image Object Detection Using Tensorflow-trained Classifier #########\n",
      "#\n",
      "# Author: Evan Juras\n",
      "# Date: 1/15/18\n",
      "# Description: \n",
      "# This program uses a TensorFlow-trained neural network to perform object detection.\n",
      "# It loads the classifier and uses it to perform object detection on an image.\n",
      "# It draws boxes, scores, and labels around the objects of interest in the image.\n",
      "\n",
      "## Some of the code is copied from Google's example at\n",
      "## https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\n",
      "\n",
      "## and some is copied from Dat Tran's example at\n",
      "## https://github.com/datitran/object_detector_app/blob/master/object_detection_app.py\n",
      "\n",
      "## but I changed it to make it more understandable to me.\n",
      "\n",
      "# Import packages\n",
      "import os\n",
      "import cv2\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "import sys\n",
      "import re\n",
      "\n",
      "# This is needed since the notebook is stored in the object_detection folder.\n",
      "sys.path.append(\"..\")\n",
      "\n",
      "# Import utilites\n",
      "from object_detection.utils import label_map_util\n",
      "from object_detection.utils import visualization_utils as vis_util\n",
      "\n",
      "# Name of the directory containing the object detection module we're using\n",
      "MODEL_NAME = 'autoaugm_nas'\n",
      "MODEL_PATH = 'inference_graph/' + MODEL_NAME\n",
      "\n",
      "# Grab path to current working directory\n",
      "CWD_PATH = os.getcwd()\n",
      "\n",
      "# Path to frozen detection graph .pb file, which contains the model that is used\n",
      "# for object detection.\n",
      "PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_PATH,'frozen_inference_graph.pb')\n",
      "\n",
      "# Path to label map file\n",
      "PATH_TO_LABELS = os.path.join(CWD_PATH,'training','labelmap.pbtxt')\n",
      "\n",
      "# Path to image\n",
      "#PATH_TO_IMAGE = os.path.join(CWD_PATH,IMAGE_NAME)\n",
      "\n",
      "# Number of classes the object detector can identify\n",
      "NUM_CLASSES = 10 \n",
      "\n",
      "# Load the label map.  # Label maps map indices to category names, so that when our convolution # network predicts `5`, we know that this corresponds to `king`.  # Here we use internal utility functions, but anything that returns a\n",
      "# dictionary mapping integers to appropriate string labels would be fine\n",
      "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
      "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
      "category_index = label_map_util.create_category_index(categories)\n",
      "\n",
      "# Load the Tensorflow model into memory.\n",
      "detection_graph = tf.Graph()\n",
      "with detection_graph.as_default():\n",
      "    od_graph_def = tf.GraphDef()\n",
      "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
      "        serialized_graph = fid.read()\n",
      "        od_graph_def.ParseFromString(serialized_graph)\n",
      "        tf.import_graph_def(od_graph_def, name='')\n",
      "\n",
      "    sess = tf.Session(graph=detection_graph)\n",
      "\n",
      "# Define input and output tensors (i.e. data) for the object detection classifier\n",
      "\n",
      "# Input tensor is the image\n",
      "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
      "\n",
      "# Output tensors are the detection boxes, scores, and classes\n",
      "# Each box represents a part of the image where a particular object was detected\n",
      "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
      "\n",
      "# Each score represents level of confidence for each of the objects.\n",
      "# The score is shown on the result image, together with the class label.\n",
      "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
      "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
      "\n",
      "# Number of objects detected\n",
      "num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
      "\n",
      "test_image_path = '/happy-walrus/models/version_3/images/test/'\n",
      "list_images = [file for file in os.listdir(test_image_path) if re.search('\\.jpg', file)]\n",
      "for image_name in list_images:\n",
      "    # Load image using OpenCV and\n",
      "    # expand image dimensions to have shape: [1, None, None, 3]\n",
      "    # i.e. a single-column array, where each item in the column has the pixel RGB value\n",
      "    image = cv2.imread(test_image_path + image_name)\n",
      "    image_expanded = np.expand_dims(image, axis=0)\n",
      "    print(test_image_path + image_name)\n",
      "\n",
      "    # Perform the actual detection by running the model with the image as input\n",
      "    (boxes, scores, classes, num) = sess.run(\n",
      "        [detection_boxes, detection_scores, detection_classes, num_detections],\n",
      "        feed_dict={image_tensor: image_expanded})\n",
      "\n",
      "    # Draw the results of the detection (aka 'visulaize the results')\n",
      "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
      "        image,\n",
      "        np.squeeze(boxes),\n",
      "        np.squeeze(classes).astype(np.int32),\n",
      "        np.squeeze(scores),\n",
      "        category_index,\n",
      "        use_normalized_coordinates=True,\n",
      "        line_thickness=8,\n",
      "        min_score_thresh=0.60)\n",
      "\n",
      "    cv2.imwrite('/happy-walrus/models/version_3/evaluation/' + MODEL_NAME + '/bboxes/' + image_name[:-4] + '_bbox.jpg', image)\n",
      "\n",
      "# All the results have been drawn on image. Now display the image.\n",
      "#print(\"Write successful to \" + IMAGE[:-4] + '_pred.jpg')\n",
      "#cv2.imshow('Object detector', image)\n",
      "\n",
      "# Press any key to close the image\n",
      "# cv2.waitKey(0)\n",
      "\n",
      "# Clean up\n",
      "# cv2.destroyAllWindows()\n"
     ]
    }
   ],
   "source": [
    "!mkdir {EVAL_PATH}\n",
    "!mkdir {EVAL_PATH}/bboxes\n",
    "!cat {MAIN_PATH}Object_detection_image.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference:\n",
    "- If `NoneType` related error, reinstall opencv with `apt install opencv-python`.\n",
    "- Change save path to model specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /models/research/object_detection/utils/label_map_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /happy-walrus/models/version_3/Object_detection_image.py:62: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From /happy-walrus/models/version_3/Object_detection_image.py:68: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2019-11-30 21:15:14.490048: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2019-11-30 21:15:14.490105: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2019-11-30 21:15:14.490141: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (5df86dfc3c25): /proc/driver/nvidia/version does not exist\n",
      "2019-11-30 21:15:14.490502: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-11-30 21:15:14.502005: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100060000 Hz\n",
      "2019-11-30 21:15:14.502852: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x965c480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2019-11-30 21:15:14.502888: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "/happy-walrus/models/version_3/images/test/white_kitchen.EH.021.jpg\n",
      "2019-11-30 21:15:20.740875: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 137779584 exceeds 10% of system memory.\n",
      "2019-11-30 21:15:20.802642: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 138240000 exceeds 10% of system memory.\n",
      "2019-11-30 21:15:20.947590: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 137779584 exceeds 10% of system memory.\n",
      "2019-11-30 21:15:23.659605: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 2330496000 exceeds 10% of system memory.\n",
      "2019-11-30 21:15:24.838563: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 2330496000 exceeds 10% of system memory.\n",
      "/happy-walrus/models/version_3/images/test/ADE_val_00000474.jpg\n",
      "/happy-walrus/models/version_3/images/test/ADE_val_00001482.jpg\n",
      "/happy-walrus/models/version_3/images/test/ADE_train_00010273.jpg\n",
      "/happy-walrus/models/version_3/images/test/kitchen_apartment.NM.075.jpg\n",
      "/happy-walrus/models/version_3/images/test/large_kitchen.EH.041.jpg\n",
      "/happy-walrus/models/version_3/images/test/ADE_train_00010631.jpg\n",
      "/happy-walrus/models/version_3/images/test/green_kitchen.NM.033.jpg\n",
      "/happy-walrus/models/version_3/images/test/small_kitchen.EH.048.jpg\n",
      "/happy-walrus/models/version_3/images/test/ADE_train_00010719.jpg\n",
      "/happy-walrus/models/version_3/images/test/small_kitchen.EH.068.jpg\n",
      "/happy-walrus/models/version_3/images/test/pintrest_messy_kitchen.EH.024.jpg\n",
      "/happy-walrus/models/version_3/images/test/ADE_train_00010493.jpg\n",
      "/happy-walrus/models/version_3/images/test/ADE_train_00010526.jpg\n",
      "/happy-walrus/models/version_3/images/test/big_kitchen.NM.032.jpg\n",
      "/happy-walrus/models/version_3/images/test/white_kitchen.EH.007.jpg\n",
      "/happy-walrus/models/version_3/images/test/tiny_kitchen.EH.016.jpg\n",
      "/happy-walrus/models/version_3/images/test/blue_kitchen.NM.033.jpg\n",
      "/happy-walrus/models/version_3/images/test/linoleum_kitchen.EH.042.jpg\n",
      "/happy-walrus/models/version_3/images/test/kitchen_appliances.NM.015.jpg\n",
      "/happy-walrus/models/version_3/images/test/green_kitchen.NM.007.jpg\n",
      "/happy-walrus/models/version_3/images/test/blue_kitchen.NM.036.jpg\n",
      "/happy-walrus/models/version_3/images/test/clean_kitchen.NM.015.jpg\n",
      "/happy-walrus/models/version_3/images/test/ADE_train_00010521.jpg\n",
      "/happy-walrus/models/version_3/images/test/ADE_train_00010260.jpg\n",
      "/happy-walrus/models/version_3/images/test/blue_kitchen.NM.025.jpg\n",
      "/happy-walrus/models/version_3/images/test/tiny_kitchen.EH.029.jpg\n",
      "/happy-walrus/models/version_3/images/test/white_kitchen.EH.011.jpg\n",
      "/happy-walrus/models/version_3/images/test/boiling_water.NM.009.jpg\n",
      "/happy-walrus/models/version_3/images/test/boiling_water.NM.020.jpg\n",
      "/happy-walrus/models/version_3/images/test/ADE_val_00000477.jpg\n",
      "/happy-walrus/models/version_3/images/test/ADE_train_00010178.jpg\n",
      "/happy-walrus/models/version_3/images/test/ADE_train_00000613.jpg\n",
      "/happy-walrus/models/version_3/images/test/European_kitchen.NM.031.jpg\n",
      "/happy-walrus/models/version_3/images/test/ADE_train_00010173.jpg\n",
      "/happy-walrus/models/version_3/images/test/red_kitchen.EH.028.jpg\n",
      "/happy-walrus/models/version_3/images/test/blue_kitchen.NM.085.jpg\n",
      "/happy-walrus/models/version_3/images/test/messy_kitchen.EH.025.jpg\n",
      "/happy-walrus/models/version_3/images/test/red_kitchen.EH.029.jpg\n",
      "/happy-walrus/models/version_3/images/test/blue_kitchen.NM.006.jpg\n",
      "/happy-walrus/models/version_3/images/test/Indian_kitchen.NM.003.jpg\n",
      "/happy-walrus/models/version_3/images/test/purple_kitchen.EH.005.jpg\n",
      "/happy-walrus/models/version_3/images/test/ADE_train_00010566.jpg\n",
      "/happy-walrus/models/version_3/images/test/kitchen_corners.NM.086.jpg\n",
      "/happy-walrus/models/version_3/images/test/green_kitchen.NM.018.jpg\n",
      "/happy-walrus/models/version_3/images/test/orange_kitchen.EH.043.jpg\n",
      "/happy-walrus/models/version_3/images/test/red_kitchen.EH.007.jpg\n",
      "/happy-walrus/models/version_3/images/test/kitchen_corners.NM.025.jpg\n",
      "/happy-walrus/models/version_3/images/test/kitchen_apartment.NM.085.jpg\n",
      "/happy-walrus/models/version_3/images/test/orange_kitchen.EH.069.jpg\n",
      "/happy-walrus/models/version_3/images/test/linoleum_kitchen.EH.030.jpg\n",
      "/happy-walrus/models/version_3/images/test/orange_kitchen.EH.070.jpg\n",
      "/happy-walrus/models/version_3/images/test/linoleum_kitchen.EH.022.jpg\n",
      "/happy-walrus/models/version_3/images/test/old_kitchen.EH.008.jpg\n",
      "/happy-walrus/models/version_3/images/test/pintrest_cluttered_kitchen.EH.076.jpg\n",
      "/happy-walrus/models/version_3/images/test/large_kitchen.EH.010.jpg\n",
      "/happy-walrus/models/version_3/images/test/ADE_val_00001472.jpg\n",
      "/happy-walrus/models/version_3/images/test/black_kitchen.NM.060.jpg\n",
      "/happy-walrus/models/version_3/images/test/large_kitchen.EH.038.jpg\n",
      "/happy-walrus/models/version_3/images/test/red_kitchen.EH.045.jpg\n",
      "/happy-walrus/models/version_3/images/test/ADE_train_00010411.jpg\n",
      "/happy-walrus/models/version_3/images/test/ADE_train_00010564.jpg\n",
      "/happy-walrus/models/version_3/images/test/black_kitchen.NM.007.jpg\n",
      "/happy-walrus/models/version_3/images/test/grey_kitchen.NM.071.jpg\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python {MAIN_PATH}Object_detection_image.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -rq {EVAL_PATH}/bboxes.zip {EVAL_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make inferences on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:96: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:57: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W1204 19:12:04.728284 140639233492800 module_wrapper.py:139] From /models/research/object_detection/inference/infer_detections.py:57: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:57: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W1204 19:12:04.728508 140639233492800 module_wrapper.py:139] From /models/research/object_detection/inference/infer_detections.py:57: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W1204 19:12:04.728677 140639233492800 module_wrapper.py:139] From /models/research/object_detection/inference/infer_detections.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2019-12-04 19:12:04.729591: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2019-12-04 19:12:04.729635: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2019-12-04 19:12:04.729671: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (5df86dfc3c25): /proc/driver/nvidia/version does not exist\n",
      "2019-12-04 19:12:04.731082: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-04 19:12:04.746868: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100060000 Hz\n",
      "2019-12-04 19:12:04.747903: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x50a3d50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2019-12-04 19:12:04.747974: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:68: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W1204 19:12:04.752456 140639233492800 module_wrapper.py:139] From /models/research/object_detection/inference/infer_detections.py:68: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Reading input from 1 files\n",
      "I1204 19:12:04.752749 140639233492800 infer_detections.py:68] Reading input from 1 files\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/detection_inference.py:35: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W1204 19:12:04.753671 140639233492800 deprecation.py:323] From /models/research/object_detection/inference/detection_inference.py:35: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W1204 19:12:04.762289 140639233492800 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "W1204 19:12:04.762788 140639233492800 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:112: RefVariable.count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "W1204 19:12:04.766592 140639233492800 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:112: RefVariable.count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py:2522: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "W1204 19:12:04.766808 140639233492800 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py:2522: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W1204 19:12:04.770560 140639233492800 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W1204 19:12:04.772415 140639233492800 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/detection_inference.py:37: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "W1204 19:12:04.778451 140639233492800 deprecation.py:323] From /models/research/object_detection/inference/detection_inference.py:37: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/detection_inference.py:39: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "W1204 19:12:04.779968 140639233492800 module_wrapper.py:139] From /models/research/object_detection/inference/detection_inference.py:39: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/detection_inference.py:43: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "W1204 19:12:04.780199 140639233492800 module_wrapper.py:139] From /models/research/object_detection/inference/detection_inference.py:43: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading graph and building model...\n",
      "I1204 19:12:04.844368 140639233492800 infer_detections.py:71] Reading graph and building model...\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/detection_inference.py:68: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1204 19:12:04.844743 140639233492800 module_wrapper.py:139] From /models/research/object_detection/inference/detection_inference.py:68: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/detection_inference.py:70: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "W1204 19:12:05.210982 140639233492800 module_wrapper.py:139] From /models/research/object_detection/inference/detection_inference.py:70: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/detection_inference.py:76: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1204 19:12:06.713640 140639233492800 module_wrapper.py:139] From /models/research/object_detection/inference/detection_inference.py:76: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "INFO:tensorflow:Running inference and writing output to /happy-walrus/models/version_3/evaluation/custaugm_resnet101/test_detections.tfrecord-00000-of-00001\n",
      "I1204 19:12:06.748491 140639233492800 infer_detections.py:77] Running inference and writing output to /happy-walrus/models/version_3/evaluation/custaugm_resnet101/test_detections.tfrecord-00000-of-00001\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:78: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "W1204 19:12:06.748872 140639233492800 module_wrapper.py:139] From /models/research/object_detection/inference/infer_detections.py:78: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:79: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W1204 19:12:06.898931 140639233492800 deprecation.py:323] From /models/research/object_detection/inference/infer_detections.py:79: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:80: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W1204 19:12:06.899948 140639233492800 module_wrapper.py:139] From /models/research/object_detection/inference/infer_detections.py:80: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/infer_detections.py:84: The name tf.logging.log_every_n is deprecated. Please use tf.compat.v1.logging.log_every_n instead.\n",
      "\n",
      "W1204 19:12:06.900798 140639233492800 module_wrapper.py:139] From /models/research/object_detection/inference/infer_detections.py:84: The name tf.logging.log_every_n is deprecated. Please use tf.compat.v1.logging.log_every_n instead.\n",
      "\n",
      "INFO:tensorflow:Processed 0 images...\n",
      "I1204 19:12:06.900961 140639233492800 infer_detections.py:85] Processed 0 images...\n",
      "WARNING:tensorflow:From /models/research/object_detection/inference/detection_inference.py:117: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1204 19:12:06.901186 140639233492800 module_wrapper.py:139] From /models/research/object_detection/inference/detection_inference.py:117: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "INFO:tensorflow:Processed 10 images...\n",
      "I1204 19:12:23.655367 140639233492800 infer_detections.py:85] Processed 10 images...\n",
      "INFO:tensorflow:Processed 20 images...\n",
      "I1204 19:12:39.335134 140639233492800 infer_detections.py:85] Processed 20 images...\n",
      "INFO:tensorflow:Processed 30 images...\n",
      "I1204 19:12:54.995661 140639233492800 infer_detections.py:85] Processed 30 images...\n",
      "INFO:tensorflow:Processed 40 images...\n",
      "I1204 19:13:10.292232 140639233492800 infer_detections.py:85] Processed 40 images...\n",
      "INFO:tensorflow:Processed 50 images...\n",
      "I1204 19:13:24.498015 140639233492800 infer_detections.py:85] Processed 50 images...\n",
      "INFO:tensorflow:Processed 60 images...\n",
      "I1204 19:13:40.048566 140639233492800 infer_detections.py:85] Processed 60 images...\n",
      "^C\n",
      "Seconds per image 0.40194459532348203\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "!python {OD_PATH}inference/infer_detections.py \\\n",
    "  --input_tfrecord_paths={MAIN_PATH}test.record \\\n",
    "  --output_tfrecord_path={EVAL_PATH}/test_detections.tfrecord-00000-of-00001 \\\n",
    "  --inference_graph={GRAPH_PATH}/frozen_inference_graph.pb \\\n",
    "  --discard_image_pixels\n",
    "\n",
    "total_mins = (time.time() - start)\n",
    "!echo Seconds per image {total_mins / 284} > {EVAL_PATH}/inference_time.txt\n",
    "!cat {EVAL_PATH}/inference_time.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate performance metrics.\n",
    "- There are two documented bugs, solved implementing [this solution](https://github.com/tensorflow/models/issues/3252#issuecomment-363669586) and [this one](https://github.com/tensorflow/models/issues/5924#issuecomment-455081147).\n",
    "    - Replace line 162 in `metrics/offline_eval_map_corloc.py` for `input_config = configs['eval_input_configs'][0]`.\n",
    "    - Replace lines 47 to 49 in `metrics/tf_example_parser.py` with:\n",
    "        ```python\n",
    "            if tf_example.features.feature[self.field_name].HasField(\"bytes_list\"):\n",
    "                result = tf_example.features.feature[self.field_name].bytes_list.value\n",
    "                result = \"\".join([x if type(x)=='str' else x.decode('utf-8') for x in result])\n",
    "            else:\n",
    "                result = None\n",
    "            return result\n",
    "        ```\n",
    "\n",
    "- Update MODEL_NAME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custaugm_resnet101'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.71s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.782\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.928\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.860\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.782\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.525\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.812\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.816\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.816\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:46: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:46: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:172: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/utils/config_util.py:236: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1204 19:14:08.698583 139694358464320 module_wrapper.py:139] From /models/research/object_detection/utils/config_util.py:236: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:105: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W1204 19:14:08.701287 139694358464320 module_wrapper.py:139] From /models/research/object_detection/metrics/offline_eval_map_corloc.py:105: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Processing file: /happy-walrus/models/version_3/evaluation/custaugm_resnet101/test_detections.tfrecord-00000-of-00001\n",
      "I1204 19:14:08.701472 139694358464320 offline_eval_map_corloc.py:105] Processing file: /happy-walrus/models/version_3/evaluation/custaugm_resnet101/test_detections.tfrecord-00000-of-00001\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:107: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "W1204 19:14:08.701652 139694358464320 deprecation.py:323] From /models/research/object_detection/metrics/offline_eval_map_corloc.py:107: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:111: The name tf.logging.log_every_n is deprecated. Please use tf.compat.v1.logging.log_every_n instead.\n",
      "\n",
      "W1204 19:14:08.712713 139694358464320 module_wrapper.py:139] From /models/research/object_detection/metrics/offline_eval_map_corloc.py:111: The name tf.logging.log_every_n is deprecated. Please use tf.compat.v1.logging.log_every_n instead.\n",
      "\n",
      "INFO:tensorflow:Processed 0 images...\n",
      "I1204 19:14:08.713000 139694358464320 offline_eval_map_corloc.py:112] Processed 0 images...\n",
      "I1204 19:14:09.263889 139694358464320 object_detection_evaluation.py:1311] average_precision: 0.941302\n",
      "I1204 19:14:09.274115 139694358464320 object_detection_evaluation.py:1311] average_precision: 0.969516\n",
      "I1204 19:14:09.286080 139694358464320 object_detection_evaluation.py:1311] average_precision: 0.917776\n",
      "I1204 19:14:09.292230 139694358464320 object_detection_evaluation.py:1311] average_precision: 0.899560\n",
      "I1204 19:14:09.301716 139694358464320 object_detection_evaluation.py:1311] average_precision: 0.772049\n",
      "I1204 19:14:09.307607 139694358464320 object_detection_evaluation.py:1311] average_precision: 0.956522\n",
      "I1204 19:14:09.311362 139694358464320 object_detection_evaluation.py:1311] average_precision: 1.000000\n",
      "I1204 19:14:09.316110 139694358464320 object_detection_evaluation.py:1311] average_precision: 1.000000\n",
      "I1204 19:14:09.322997 139694358464320 object_detection_evaluation.py:1311] average_precision: 0.934462\n",
      "I1204 19:14:09.330526 139694358464320 object_detection_evaluation.py:1311] average_precision: 0.917195\n",
      "INFO:tensorflow:Writing metrics.\n",
      "I1204 19:14:09.331907 139694358464320 offline_eval_map_corloc.py:142] Writing metrics.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:46: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:46: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:172: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/utils/config_util.py:236: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1204 19:14:13.382131 139726489483072 module_wrapper.py:139] From /models/research/object_detection/utils/config_util.py:236: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:105: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W1204 19:14:13.384691 139726489483072 module_wrapper.py:139] From /models/research/object_detection/metrics/offline_eval_map_corloc.py:105: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Processing file: /happy-walrus/models/version_3/evaluation/custaugm_resnet101/test_detections.tfrecord-00000-of-00001\n",
      "I1204 19:14:13.384838 139726489483072 offline_eval_map_corloc.py:105] Processing file: /happy-walrus/models/version_3/evaluation/custaugm_resnet101/test_detections.tfrecord-00000-of-00001\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:107: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "W1204 19:14:13.385022 139726489483072 deprecation.py:323] From /models/research/object_detection/metrics/offline_eval_map_corloc.py:107: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:tensorflow:From /models/research/object_detection/metrics/offline_eval_map_corloc.py:111: The name tf.logging.log_every_n is deprecated. Please use tf.compat.v1.logging.log_every_n instead.\n",
      "\n",
      "W1204 19:14:13.396044 139726489483072 module_wrapper.py:139] From /models/research/object_detection/metrics/offline_eval_map_corloc.py:111: The name tf.logging.log_every_n is deprecated. Please use tf.compat.v1.logging.log_every_n instead.\n",
      "\n",
      "INFO:tensorflow:Processed 0 images...\n",
      "I1204 19:14:13.396321 139726489483072 offline_eval_map_corloc.py:112] Processed 0 images...\n",
      "INFO:tensorflow:Performing evaluation on 69 images.\n",
      "I1204 19:14:13.665048 139726489483072 coco_evaluation.py:205] Performing evaluation on 69 images.\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I1204 19:14:13.666074 139726489483072 coco_tools.py:115] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.01s)\n",
      "I1204 19:14:13.678948 139726489483072 coco_tools.py:137] DONE (t=0.01s)\n",
      "INFO:tensorflow:Writing metrics.\n",
      "I1204 19:14:15.639024 139726489483072 offline_eval_map_corloc.py:142] Writing metrics.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OD_PATH='/models/research/object_detection/'\n",
    "MAIN_PATH='/happy-walrus/models/version_3/'\n",
    "IMG_PATH=${MAIN_PATH}images/\n",
    "MODEL_NAME=custaugm_resnet101/\n",
    "TRAIN_PATH=${MAIN_PATH}training/${MODEL_NAME}\n",
    "EVAL_PATH=${MAIN_PATH}evaluation/${MODEL_NAME}\n",
    "GRAPH_PATH=${MAIN_PATH}inference_graph${MODEL_NAME}\n",
    "METRICS_PATH=${EVAL_PATH}eval_metrics/\n",
    "# Choose metrics set from:\n",
    "#   - coco_detection_metrics (multiple IoUs)\n",
    "#   - pascal_voc_detection_metrics (per-class)\n",
    "METRICS_SET='pascal_voc_detection_metrics'\n",
    "\n",
    "mkdir -p ${METRICS_PATH}\n",
    "\n",
    "echo \"\n",
    "label_map_path: '/happy-walrus/models/version_3/training/labelmap.pbtxt'\n",
    "tf_record_input_reader: { input_path: '${EVAL_PATH}test_detections.tfrecord-00000-of-00001' }\n",
    "\" > ${METRICS_PATH}test_input_config.pbtxt\n",
    "\n",
    "echo \"\n",
    "metrics_set: 'pascal_voc_detection_metrics'\n",
    "\" > ${METRICS_PATH}test_eval_pascal_config.pbtxt\n",
    "\n",
    "echo \"\n",
    "metrics_set: 'coco_detection_metrics'\n",
    "\" > ${METRICS_PATH}test_eval_coco_config.pbtxt\n",
    "\n",
    "python ${OD_PATH}metrics/offline_eval_map_corloc.py \\\n",
    "  --eval_dir=${METRICS_PATH} \\\n",
    "  --eval_config_path=${METRICS_PATH}test_eval_pascal_config.pbtxt \\\n",
    "  --input_config_path=${METRICS_PATH}test_input_config.pbtxt\n",
    "  \n",
    "mv ${METRICS_PATH}metrics.csv ${METRICS_PATH}metrics_pascal.csv\n",
    "\n",
    "python ${OD_PATH}metrics/offline_eval_map_corloc.py \\\n",
    "  --eval_dir=${METRICS_PATH} \\\n",
    "  --eval_config_path=${METRICS_PATH}test_eval_coco_config.pbtxt \\\n",
    "  --input_config_path=${METRICS_PATH}test_input_config.pbtxt\n",
    "  \n",
    "mv ${METRICS_PATH}metrics.csv ${METRICS_PATH}metrics_coco.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DetectionBoxes_Precision/mAP          0.781845304420996  \r\n",
      "DetectionBoxes_Precision/mAP@.50IOU   0.9281821269210555 \r\n",
      "DetectionBoxes_Precision/mAP@.75IOU   0.86005819378099   \r\n",
      "DetectionBoxes_Precision/mAP (small)  0.781845304420996  \r\n",
      "DetectionBoxes_Precision/mAP (medium) -1.0               \r\n",
      "DetectionBoxes_Precision/mAP (large)  -1.0               \r\n",
      "DetectionBoxes_Recall/AR@1            0.52452294682995   \r\n",
      "DetectionBoxes_Recall/AR@10           0.8121432697120007 \r\n",
      "DetectionBoxes_Recall/AR@100          0.8160867167193131 \r\n",
      "DetectionBoxes_Recall/AR@100 (small)  0.8160867167193131 \r\n",
      "DetectionBoxes_Recall/AR@100 (medium) -1.0               \r\n",
      "DetectionBoxes_Recall/AR@100 (large)  -1.0               \r\n"
     ]
    }
   ],
   "source": [
    "# coco_detection_metrics\n",
    "!csvtool readable {EVAL_PATH}/eval_metrics/metrics_coco.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PascalBoxes_Precision/mAP@0.5IOU                       0.9308382437764923 \r\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/cabinet    0.9413022870491587 \r\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/chair      0.9695155715949667 \r\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/countertop 0.9177758880168616 \r\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/dishwasher 0.8995604395604395 \r\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/outlet     0.7720489201175028 \r\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/oven       0.9565217391304348 \r\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/sofa       1.0                \r\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/stool      1.0                \r\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/stove      0.934462170015391  \r\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/utensil    0.9171954222801681 \r\n"
     ]
    }
   ],
   "source": [
    "# pascal_voc_detection_metrics\n",
    "!csvtool readable {EVAL_PATH}/eval_metrics/metrics_pascal.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [State of the Art Object Detection - Medium](https://medium.com/@lessw/state-of-the-art-object-detection-use-these-top-3-data-augmentations-and-google-brains-optimal-57ac6d8d1de5)\n",
    "- [Learning Data Augmentation Strategies for Object Detection](https://arxiv.org/abs/1906.11172v1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
